<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">























  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link rel="stylesheet" href="https://fonts.cat.net/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext">
  






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.0.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.0.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.0.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.0.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.0.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.0.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false,"dimmer":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="&amp;emsp;&amp;emsp;In this post I will cover a partial re-implementation of a recent paper on manifold regularization (Lecouat et al., 2018) for semi-supervised learning with Generative Adversarial Networks">
<meta property="og:type" content="article">
<meta property="og:title" content="Semi-supervised learning with GANs">
<meta property="og:url" content="http://imjunjie.github.io/semi-supervised-learning-with-gans.html">
<meta property="og:site_name" content="Imjunjie">
<meta property="og:description" content="&amp;emsp;&amp;emsp;In this post I will cover a partial re-implementation of a recent paper on manifold regularization (Lecouat et al., 2018) for semi-supervised learning with Generative Adversarial Networks">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://imjunjie.github.io/images/Semi-supervised-learning-with-GANs/png1-1.png">
<meta property="og:image" content="http://imjunjie.github.io/images/Semi-supervised-learning-with-GANs/png1-2.png">
<meta property="og:image" content="http://imjunjie.github.io/images/Semi-supervised-learning-with-GANs/jpeg1-1.jpeg">
<meta property="og:updated_time" content="2019-05-09T07:50:55.424Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Semi-supervised learning with GANs">
<meta name="twitter:description" content="&amp;emsp;&amp;emsp;In this post I will cover a partial re-implementation of a recent paper on manifold regularization (Lecouat et al., 2018) for semi-supervised learning with Generative Adversarial Networks">
<meta name="twitter:image" content="http://imjunjie.github.io/images/Semi-supervised-learning-with-GANs/png1-1.png">



  <link rel="alternate" href="/atom.xml" title="Imjunjie" type="application/atom+xml">




  <link rel="canonical" href="http://imjunjie.github.io/semi-supervised-learning-with-gans.html">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Semi-supervised learning with GANs | Imjunjie</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Imjunjie</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">蜻蜓雨荷</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/semi-supervised-learning-with-gans.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Semi-supervised learning with GANs

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-09 11:47:15 / 修改时间：15:50:55" itemprop="dateCreated datePublished" datetime="2019-05-09T11:47:15+08:00">2019-05-09</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="post-meta-item-icon">
            <i class="fa fa-eye"></i>
             阅读次数： 
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">23k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">21 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><br>&emsp;&emsp;In this post I will cover a partial re-implementation of a <a href="https://arxiv.org/abs/1805.08957" target="_blank" rel="noopener">recent paper</a> on manifold regularization (Lecouat et al., 2018) for semi-supervised learning with <a href="http://papers.nips.cc/paper/5423-generative-adversarial-nets" target="_blank" rel="noopener">Generative Adversarial Networks</a> (Goodfellow et al., 2014). I will attempt to re-implement their main contribution, rather than getting all the hyperparameter details just right. Also, for the sake of demonstration, time constraints and simplicity, I will consider the MNIST dataset rather than the CIFAR10 or SVHN datasets as done in <a href="https://arxiv.org/abs/1805.08957" target="_blank" rel="noopener">the paper</a>. Ultimately, this post aims at bridging the gap between the theory and implementation for GANs in the semi-supervised learning setting. The code that comes with this post can be found <a href="https://github.com/jostosh/gan/blob/master/dcganmnist/mnist_ssl.py" target="_blank" rel="noopener">here</a>.</p>
<h1 id="Generative-Adversarial-Networks"><a href="#Generative-Adversarial-Networks" class="headerlink" title="Generative Adversarial Networks"></a>Generative Adversarial Networks</h1><p>&emsp;&emsp;Let’s quickly go over Generative Adversarial Networks (GAN). In terms of the current pace within the AI/ML community, they have been around for a while (just about 4 years), so you might already be familiar with them. The ‘vanilla’ GAN procedure is to train a generator to generate images that are realistic and capable of fooling a discriminator. The generator generates the images by means of a deep neural network that takes in a noise vector z.<br>&emsp;&emsp;The discriminator (which is a deep neural network as well) is fed with the generated images, but also with some real data. Its job is to say whether each image is either real (coming from the dataset) or fake (coming from the generator), which in terms of implementation comes down to binary classification. The image below summarizes the vanilla GAN setup.<br><img src="/images/Semi-supervised-learning-with-GANs/png1-1.png" alt="Vanilla GAN setup"></p>
<h1 id="Semi-supervised-learning"><a href="#Semi-supervised-learning" class="headerlink" title="Semi-supervised learning"></a>Semi-supervised learning</h1><p>&emsp;&emsp;Semi-supervised learning problems concern a mix of labeled and unlabeled data. Leveraging the information in both the labeled and unlabeled data to eventually improve the performance on unseen labeled data is an interesting and more challenging problem than merely doing supervised learning on a large labeled dataset. In this case we might be limited to having only about 200 samples per class. So what should we do when only a small portion of the data is labeled?<br>&emsp;&emsp;Note that adversarial training of vanilla GANs doesn’t require labeled data. At the same time, the deep neural network of the discriminator is able to learn powerful and robust abstractions of images by gradually becoming better at discriminating fake from real. Whatever it’s learning about unlabeled images will presumably also yield useful feature descriptors of labeled images. So how do we use the discriminator for both labeled and unlabeled data? Well, the discriminator is not necessarily limited to just telling fake from real. We could decide to train it to also classify the real data.<br>&emsp;&emsp;A GAN with a classifying discriminator would be able to exploit both the unlabeled as well as the labeled data. The unlabeled data will be used to merely tell fake from real. The labeled data would be used to optimize the classification performance. In practice, this just means that the discriminator has a softmax output distribution for which we minimize the cross-entropy. Indeed, part of the training procedure is just doing supervised learning. The other part is about adversarial training. The image below summarizes the semi-supervised learning setup with a GAN.<br><img src="/images/Semi-supervised-learning-with-GANs/png1-2.png" alt="Vanilla GAN setup"></p>
<h1 id="The-implementation"><a href="#The-implementation" class="headerlink" title="The implementation"></a>The implementation</h1><p>&emsp;&emsp;Let’s just head over to the implementation, since that might be the best way of understanding what’s happening. The snippet below prepares the data. It doesn’t really contain anything sophisticated. Basically, we take 400 samples per class and concatenate the resulting arrays as being our actual supervised subset. The unlabeled dataset consists of all train data (it also includes the labeled data, since we might as well use it anyway). As is customary for training GANs now, the output of the generator uses a hyperbolic tangent function, meaning its output is between -1 and +1. Therefore, we rescale the data to be in that range as well. Then, we create TensorFlow iterators so that we can efficiently go through the data later without having to struggle with feed dicts later on.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prepare_input_pipeline</span><span class="params">(flags_obj)</span>:</span></span><br><span class="line">    (train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data(</span><br><span class="line">        <span class="string">"/home/jos/datasets/mnist/mnist.npz"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reshape_and_scale</span><span class="params">(x, img_shape=<span class="params">(<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span>)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> x.reshape(img_shape).astype(np.float32) / <span class="number">255.</span> * <span class="number">2.0</span> - <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Reshape data and rescale to [-1, 1]</span></span><br><span class="line">    train_x = reshape_and_scale(train_x)</span><br><span class="line">    test_x = reshape_and_scale(test_x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Shuffle train data</span></span><br><span class="line">    train_x_unlabeled, train_y_unlabeled = shuffle(train_x, train_y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Select subset as supervised</span></span><br><span class="line">    train_x_labeled, train_y_labeled = [], []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(flags_obj.num_classes):</span><br><span class="line">        train_x_labeled.append(</span><br><span class="line">            train_x_unlabeled[train_y_unlabeled == i][:flags_obj.num_labeled_examples])</span><br><span class="line">        train_y_labeled.append(</span><br><span class="line">            train_y_unlabeled[train_y_unlabeled == i][:flags_obj.num_labeled_examples])</span><br><span class="line">    train_x_labeled = np.concatenate(train_x_labeled)</span><br><span class="line">    train_y_labeled = np.concatenate(train_y_labeled)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">"InputPipeline"</span>):</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">train_pipeline</span><span class="params">(data, shuffle_buffer_size)</span>:</span></span><br><span class="line">            <span class="keyword">return</span> tf.data.Dataset.from_tensor_slices(data)\</span><br><span class="line">                .cache()\</span><br><span class="line">                .shuffle(buffer_size=shuffle_buffer_size)\</span><br><span class="line">                .batch(flags_obj.batch_size)\</span><br><span class="line">                .repeat()\</span><br><span class="line">                .make_one_shot_iterator()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Setup pipeline for labeled data</span></span><br><span class="line">        train_ds_lab = train_pipeline(</span><br><span class="line">            (train_x_labeled, train_y_labeled.astype(np.int64)),</span><br><span class="line">            flags_obj.num_labeled_examples * flags_obj.num_classes)</span><br><span class="line">        images_lab, labels_lab = train_ds_lab.get_next()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Setup pipeline for unlabeled data</span></span><br><span class="line">        train_ds_unl = train_pipeline(</span><br><span class="line">            (train_x_unlabeled, train_y_unlabeled.astype(np.int64)), len(train_x_labeled))</span><br><span class="line">        images_unl, labels_unl = train_ds_unl.get_next()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Setup another pipeline that also uses the unlabeled data, so that we use a different</span></span><br><span class="line">        <span class="comment"># batch for computing the discriminator loss and the generator loss</span></span><br><span class="line">        train_x_unlabeled, train_y_unlabeled = shuffle(train_x_unlabeled, train_y_unlabeled)</span><br><span class="line">        train_ds_unl2 = train_pipeline(</span><br><span class="line">            (train_x_unlabeled, train_y_unlabeled.astype(np.int64)), len(train_x_labeled))</span><br><span class="line">        images_unl2, labels_unl2 = train_ds_unl2.get_next()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Setup pipeline for test data</span></span><br><span class="line">        test_ds = tf.data.Dataset.from_tensor_slices((test_x, test_y.astype(np.int64)))\</span><br><span class="line">            .cache()\</span><br><span class="line">            .batch(flags_obj.batch_size)\</span><br><span class="line">            .repeat()\</span><br><span class="line">            .make_one_shot_iterator()</span><br><span class="line">        images_test, labels_test = test_ds.get_next()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (images_lab, labels_lab), (images_unl, labels_unl), (images_unl2, labels_unl2), \</span><br><span class="line">           (images_test, labels_test)</span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;Next up is to define the discriminator network. I have deviated quite a bit from the architecture in the <a href="https://arxiv.org/abs/1805.08957" target="_blank" rel="noopener">paper</a>. I’m going to play safe here and just use Keras layers to construct the model. Actually, this enables us to very conveniently reuse all weights for different input tensors, which will prove to be useful later on. In short, the discriminator’s architecture uses 3 convolutions with 5x5 kernels and strides of 2x2, 2x2 and 1x1 respectively. Each convolution is followed by a leaky ReLU activation and a dropout layer with a dropout rate of 0.3. The flattened output of this stack of convolutions will be used as the feature layer.<br>&emsp;&emsp;The feature layer can be used for a <a href="https://arxiv.org/abs/1606.03498" target="_blank" rel="noopener">feature matching loss</a> (rather than a sigmoid cross-entropy loss as in vanilla GANs), which has proven to yield a more reliable training process. The part of the network up to this feature layer is defined in <code>_define_tail</code> in the snippet below. The <code>_define_head</code> method defines the rest of the network. The ‘head’ of the network introduces only one additional fully connected layer with 10 outputs, that correspond to the logits of the class labels. Other than that, there are some methods to make the interface of a <code>Discriminator</code> instance behave similar to that of a <code>tf.keras.models.Sequential</code> instance.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""The discriminator network. Split up in a 'tail' and 'head' network, so that we can</span></span><br><span class="line"><span class="string">        easily get the """</span></span><br><span class="line">        self.tail = self._define_tail()</span><br><span class="line">        self.head = self._define_head()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_define_tail</span><span class="params">(self, name=<span class="string">"Discriminator"</span>)</span>:</span></span><br><span class="line">        <span class="string">"""Defines the network until the intermediate layer that can be used for feature-matching</span></span><br><span class="line"><span class="string">        loss."""</span></span><br><span class="line">        feature_model = models.Sequential(name=name)</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">conv2d_dropout</span><span class="params">(filters, strides, index=<span class="number">0</span>)</span>:</span></span><br><span class="line">            <span class="comment"># Adds a convolution followed by a Dropout layer</span></span><br><span class="line">            suffix = str(index)</span><br><span class="line">            feature_model.add(layers.Conv2D(</span><br><span class="line">                filters=filters, strides=strides, name=<span class="string">"Conv&#123;&#125;"</span>.format(suffix), padding=<span class="string">'same'</span>,</span><br><span class="line">                kernel_size=<span class="number">5</span>, activation=tf.nn.leaky_relu))</span><br><span class="line">            feature_model.add(layers.Dropout(name=<span class="string">"Dropout&#123;&#125;"</span>.format(suffix), rate=<span class="number">0.3</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Three blocks of convs and dropouts. They all have 5x5 kernels, leaky ReLU and 0.3</span></span><br><span class="line">        <span class="comment"># dropout rate.</span></span><br><span class="line">        conv2d_dropout(filters=<span class="number">32</span>, strides=<span class="number">2</span>, index=<span class="number">0</span>)</span><br><span class="line">        conv2d_dropout(filters=<span class="number">64</span>, strides=<span class="number">2</span>, index=<span class="number">1</span>)</span><br><span class="line">        conv2d_dropout(filters=<span class="number">64</span>, strides=<span class="number">1</span>, index=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Flatten it and build logits layer</span></span><br><span class="line">        feature_model.add(layers.Flatten(name=<span class="string">"Flatten"</span>))</span><br><span class="line">        <span class="keyword">return</span> feature_model</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_define_head</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># Defines the remaining layers after the 'tail'</span></span><br><span class="line">        head_model = models.Sequential(name=<span class="string">"DiscriminatorHead"</span>)</span><br><span class="line">        head_model.add(layers.Dense(units=<span class="number">10</span>, activation=<span class="literal">None</span>, name=<span class="string">"Logits"</span>))</span><br><span class="line">        <span class="keyword">return</span> head_model</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">trainable_variables</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># Return both tail's parameters a well as those of the head</span></span><br><span class="line">        <span class="keyword">return</span> self.tail.trainable_variables + self.head.trainable_variables</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, x, *args, **kwargs)</span>:</span></span><br><span class="line">        <span class="comment"># By adding this, the code below can treat a Discriminator instance as a</span></span><br><span class="line">        <span class="comment"># tf.keras.models.Sequential instance</span></span><br><span class="line">        features = self.tail(x, *args, **kwargs)</span><br><span class="line">        <span class="keyword">return</span> self.head(features, *args, **kwargs), features</span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;The generator’s architecture also uses <code>5x5</code> kernels. Many implementations of DCGAN-like architectures use transposed convolutions (sometimes wrongfully referred to as ‘deconvolutions’). I have decided to give the upsampling-convolution alternative a try. This should alleviate the issue of the <u>checkerboard pattern</u> that sometimes appears in generated images. Other than that, there are ReLU nonlinearities, and a first layer to go from the 100-dimensional noise to a (rather awkwardly shaped) <code>7x7x64</code> spatial representation.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">define_generator</span><span class="params">()</span>:</span></span><br><span class="line">    model = models.Sequential(name=<span class="string">"Generator"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">conv2d_block</span><span class="params">(filters, upsample=True, activation=tf.nn.relu, index=<span class="number">0</span>)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> upsample:</span><br><span class="line">            model.add(layers.UpSampling2D(name=<span class="string">"UpSampling"</span> + str(index), size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">        model.add(layers.Conv2D(</span><br><span class="line">            filters=filters, kernel_size=<span class="number">5</span>, padding=<span class="string">'same'</span>, name=<span class="string">"Conv2D"</span> + str(index),</span><br><span class="line">            activation=activation))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># From flat noise to spatial</span></span><br><span class="line">    model.add(layers.Dense(<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>, activation=tf.nn.relu, name=<span class="string">"NoiseToSpatial"</span>))</span><br><span class="line">    model.add(layers.Reshape((<span class="number">7</span>, <span class="number">7</span>, <span class="number">64</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Four blocks of convolutions, 2 that upsample and convolve, and 2 more that</span></span><br><span class="line">    <span class="comment"># just convolve</span></span><br><span class="line">    conv2d_block(filters=<span class="number">128</span>, upsample=<span class="literal">True</span>, index=<span class="number">0</span>)</span><br><span class="line">    conv2d_block(filters=<span class="number">64</span>, upsample=<span class="literal">True</span>, index=<span class="number">1</span>)</span><br><span class="line">    conv2d_block(filters=<span class="number">64</span>, upsample=<span class="literal">False</span>, index=<span class="number">2</span>)</span><br><span class="line">    conv2d_block(filters=<span class="number">1</span>, upsample=<span class="literal">False</span>, activation=tf.nn.tanh, index=<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;I have tried to make this model work with what TensorFlow’s Keras layers have to offer so that the code would be easy to digest (and to implement of course). This also means that I have deviated from the architectures in <a href="https://arxiv.org/abs/1805.08957" target="_blank" rel="noopener">the paper</a> (e.g. I’m not using weight normalization). Because of this experimental approach, I have also experienced just how sensitive the training setup is to small variations in network architectures and parameters. There are plenty of neat GAN ‘hacks’ listed <a href="https://github.com/soumith/ganhacks" target="_blank" rel="noopener">here</a> which I definitely found insightful.     </p>
<h1 id="Putting-it-together"><a href="#Putting-it-together" class="headerlink" title="Putting it together"></a>Putting it together</h1><p>&emsp;&emsp;Let’s do the forward computations now so that we see how all of the above comes together. This consists of setting up the input pipeline, noise vector, generator and discriminator. The snippet below does all of this. Note that when <code>define_generator</code> returns the <code>Sequential</code> instance, we can just use it as a functor to obtain the output of it for the noise tensor given by z.<br>&emsp;&emsp;The discriminator will do a lot more. It will take (i) the ‘fake’ images coming from the generator, (ii) a batch of unlabeled images and finally (iii) a batch of labeled images (both with and without dropout to also report the train accuracy). We can just repetitively call the <code>Discriminator</code> instance to build the graph for each of those outputs. Keras will make sure that the variables are reused in all cases. To turn off dropout for the labeled training data, we have to pass <code>training=False</code> explicitly.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">(images_lab, labels_lab), (images_unl, labels_unl), (images_unl2, labels_unl2), \</span><br><span class="line">            (images_test, labels_test) = prepare_input_pipeline(flags_obj)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"BatchSize"</span>):</span><br><span class="line">    batch_size_tensor = tf.shape(images_lab)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the noise vectors</span></span><br><span class="line">z, z_perturbed = define_noise(batch_size_tensor, flags_obj)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate images from noise vector</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"Generator"</span>):</span><br><span class="line">    g_model = define_generator()</span><br><span class="line">    images_fake = g_model(z)</span><br><span class="line">    images_fake_perturbed = g_model(z_perturbed)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Discriminate between real and fake, and try to classify the labeled data</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"Discriminator"</span>) <span class="keyword">as</span> discriminator_scope:</span><br><span class="line">    d_model = Discriminator()</span><br><span class="line">    logits_fake, features_fake          = d_model(images_fake, training=<span class="literal">True</span>)</span><br><span class="line">    logits_fake_perturbed, _            = d_model(images_fake_perturbed, training=<span class="literal">True</span>)</span><br><span class="line">    logits_real_unl, features_real_unl  = d_model(images_unl, training=<span class="literal">True</span>)</span><br><span class="line">    logits_real_lab, features_real_lab  = d_model(images_lab, training=<span class="literal">True</span>)</span><br><span class="line">    logits_train, _                     = d_model(images_lab, training=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="The-discriminator’s-loss"><a href="#The-discriminator’s-loss" class="headerlink" title="The discriminator’s loss"></a>The discriminator’s loss</h1><p>&emsp;&emsp;Recall that the discriminator will be doing more than just separating fake from real. It also classifies the labeled data. For this, we define a supervised loss which takes the softmax output. In terms of implementation, this means that we feed the unnormalized logits to <code>tf.nn.sparse_cross_entropy_with_logits</code>.<br>&emsp;&emsp;Defining the loss for the unsupervised part is where things get a little bit more involved. Because the softmax distribution is overparameterized, we can fix the unnormalized logit at 0 for an image to be fake (i.e. coming from the generator). If we do so, the probability of it being real just turns into:</p>
<script type="math/tex; mode=display">p(x)=\frac{Z(x)}{Z(x)+exp(l_{fake})} = \frac{Z(x)}{Z(x)+1}</script><p>&emsp;&emsp;where Z(x) is the sum of the unnormalized probabilities. Note that we currently only have the logits. Ultimately, we want to use the log-probability of the fake class to define our loss function. This can now be achieved by computing the whole expression in log-space:</p>
<script type="math/tex; mode=display">log(p(x)) = log(Z(x)) - log(1+Z(x)) = logsumexp(l_1,...,l_K) - softplus(logsumexp(l_1,...,l_K))</script><p>&emsp;&emsp;Where the lower case l with subscripts denote the individual logits. Divisions become subtractions and sums can be computed by the logsumexp function. Finally, we have used the definition of the softplus function:</p>
<script type="math/tex; mode=display">softplus(x) = log(1+x)</script><p>&emsp;&emsp;In general, if you have the log-representation of a probability, it is numerically safer to keep things in log-space for as long as you can, since we are able to represent much smaller numbers in that case.<br>&emsp;&emsp;We’re not there yet. Generative adversarial training asks us to ascend the gradient of:</p>
<script type="math/tex; mode=display">log(D(x)) + log(1-D(G(z)))</script><p>&emsp;&emsp;So whenever we call <code>tf.train.AdamOptimizer.minimize</code> we should descent:</p>
<script type="math/tex; mode=display">-log(D(x)) - log(1-D(G(z))) = -log(\frac{Z(x)}{1+Z(x)})-log(1-\frac{Z(G(z))}{1+Z(G(z))})</script><p>&emsp;&emsp;The first term on the right-hand side of the equation can be written:</p>
<script type="math/tex; mode=display">softplus(logsumexp(l^{(x)}_1,...,l^{(x)}_K)) - logsumexp(l^{(x)}_1,...,l^{(x)}_K)</script><p>&emsp;&emsp;The second term of the right-hand side can be written as:</p>
<script type="math/tex; mode=display">-log(1-\frac{Z(G(z))}{1+Z(G(z))}) = -log(\frac{1}{1+Z(G(z))}) = softplus(logsumexp(l^{G(z)}_1,...,l^{G(z)}_K))</script><p>&emsp;&emsp;So that finally, we arrive at the following loss:</p>
<script type="math/tex; mode=display">softplus(logsumexp(l^{(x)}_1,...,l^{(x)}_K)) - logsumexp(l^{(x)}_1,...,l^{(x)}_K) + softplus(logsumexp(l^{G(z)}_1,...,l^{G(z)}_K))</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Set the discriminator losses</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"DiscriminatorLoss"</span>):</span><br><span class="line">    <span class="comment"># Supervised loss, just cross-entropy. This normalizes p(y|x) where 1 &lt;= y &lt;= K</span></span><br><span class="line">    loss_supervised = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(</span><br><span class="line">        labels=labels_lab, logits=logits_real_lab))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Sum of unnormalized log probabilities</span></span><br><span class="line">    logits_sum_real = tf.reduce_logsumexp(logits_real_unl, axis=<span class="number">1</span>)</span><br><span class="line">    logits_sum_fake = tf.reduce_logsumexp(logits_fake, axis=<span class="number">1</span>)</span><br><span class="line">    loss_unsupervised = <span class="number">0.5</span> * (</span><br><span class="line">        tf.negative(tf.reduce_mean(logits_sum_real)) +</span><br><span class="line">        tf.reduce_mean(tf.nn.softplus(logits_sum_real)) +</span><br><span class="line">        tf.reduce_mean(tf.nn.softplus(logits_sum_fake)))</span><br><span class="line">    loss_d = loss_supervised + loss_unsupervised</span><br></pre></td></tr></table></figure>
<h1 id="Optimizing-the-discriminator"><a href="#Optimizing-the-discriminator" class="headerlink" title="Optimizing the discriminator"></a>Optimizing the discriminator</h1><p>&emsp;&emsp;Let’s setup the operations for actually updating the parameters of the discriminator. We will just reside to the Adam optimizer. While tweaking the parameters before I wrote this post, I figured I might slow down the discriminator by setting its learning rate at 0.1 times that of the generator. After that my results got much better, so I decided to leave it there for now. Notice also that we can very easily select the subset of variables corresponding to the discriminator by exploiting the encapsulation offered by Keras.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Configure discriminator training ops</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"Train"</span>) <span class="keyword">as</span> train_scope:</span><br><span class="line">    optimizer = tf.train.AdamOptimizer(flags_obj.lr * <span class="number">0.1</span>)</span><br><span class="line">    optimize_d = optimizer.minimize(loss_d, var_list=d_model.trainable_variables)</span><br><span class="line">    train_accuracy_op = accuracy(logits_train, labels_lab)</span><br></pre></td></tr></table></figure></p>
<h1 id="Adding-some-control-flow-to-the-graph"><a href="#Adding-some-control-flow-to-the-graph" class="headerlink" title="Adding some control flow to the graph"></a>Adding some control flow to the graph</h1><p>&emsp;&emsp;After we have the new weights for the discriminator, we want the generator’s update to be aware of the updated weights. TensorFlow will not guarantee that the updated weights will actually be used even if we were to redeclare the forward computation after defining the minimization operations for the discriminator. We can still force this by using <code>tf.control_dependencies</code>. Any operation defined in the scope of this context manager will depend on the evaluation of the ones that are passed to context manager at instantiation. In other words, our generator’s update that we define later on will be guaranteed to compute the gradients using the updated weights of the discriminator.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(discriminator_scope):</span><br><span class="line">    <span class="keyword">with</span> tf.control_dependencies([optimize_d]):</span><br><span class="line">        <span class="comment"># Build a second time, so that new variables are used</span></span><br><span class="line">        logits_fake, features_fake = d_model(images_fake, training=<span class="literal">True</span>)</span><br><span class="line">        logits_real_unl, features_real_unl = d_model(images_unl2, training=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="The-generator’s-loss-and-updates"><a href="#The-generator’s-loss-and-updates" class="headerlink" title="The generator’s loss and updates"></a>The generator’s loss and updates</h1><p>&emsp;&emsp;In this implementation, the generator tries to minimize the L2 distance of the average features of the generated images vs. the average features of the real images. This <a href="https://arxiv.org/abs/1606.03498" target="_blank" rel="noopener">feature-matching loss</a> (Salimans et al., 2016) has proven to be more stable for training GANs than directly trying to optimize the discriminator’s probability for observing real data. It is straightforward to implement. While we’re at it, let’s also define the update operations for the generator. Notice that the learning rate of this optimizer is 10 times that of the discriminator.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Set the generator loss and the actual train op</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"GeneratorLoss"</span>):</span><br><span class="line">    feature_mean_real = tf.reduce_mean(features_real_unl, axis=<span class="number">0</span>)</span><br><span class="line">    feature_mean_fake = tf.reduce_mean(features_fake, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># L1 distance of features is the loss for the generator</span></span><br><span class="line">    loss_g = tf.reduce_mean(tf.abs(feature_mean_real - feature_mean_fake))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(train_scope):</span><br><span class="line">    optimizer = tf.train.AdamOptimizer(flags_obj.lr, beta1=<span class="number">0.5</span>)</span><br><span class="line">    train_op = optimizer.minimize(loss_g, var_list=g_model.trainable_variables)</span><br></pre></td></tr></table></figure></p>
<h1 id="Adding-manifold-regularization"><a href="#Adding-manifold-regularization" class="headerlink" title="Adding manifold regularization"></a>Adding manifold regularization</h1><p>&emsp;&emsp;<a href="https://arxiv.org/abs/1805.08957" target="_blank" rel="noopener">Lecouat et. al</a> (2018) propose to add manifold regularization to the feature-matching GAN training procedure of <a href="https://arxiv.org/abs/1606.03498" target="_blank" rel="noopener">Salimans et al. (2016)</a>. The regularization forces the discriminator to yield similar logits (unnormalized log probabilities) for nearby points in the latent space in which z resides. It can be implemented by generating a second perturbed version of z and computing the generator’s and discriminator’s outputs once more with this slightly altered vector.    </p>
<p>&emsp;&emsp;This means that the noise generation code looks as follows:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">define_noise</span><span class="params">(batch_size_tensor, flags_obj)</span>:</span></span><br><span class="line">    <span class="comment"># Setup noise vector</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">"LatentNoiseVector"</span>):</span><br><span class="line">        z = tfd.Normal(loc=<span class="number">0.0</span>, scale=flags_obj.stddev).sample(</span><br><span class="line">            sample_shape=(batch_size_tensor, flags_obj.z_dim_size))</span><br><span class="line">        z_perturbed = z + tfd.Normal(loc=<span class="number">0.0</span>, scale=flags_obj.stddev).sample(</span><br><span class="line">            sample_shape=(batch_size_tensor, flags_obj.z_dim_size)) * <span class="number">1e-5</span></span><br><span class="line">    <span class="keyword">return</span> z, z_perturbed</span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;The discriminator’s loss will be updated as follows (note the 3 extra lines at the bottom):<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set the discriminator losses</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"DiscriminatorLoss"</span>):</span><br><span class="line">    <span class="comment"># Supervised loss, just cross-entropy. This normalizes p(y|x) where 1 &lt;= y &lt;= K</span></span><br><span class="line">    loss_supervised = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(</span><br><span class="line">        labels=labels_lab, logits=logits_real_lab))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Sum of unnormalized log probabilities</span></span><br><span class="line">    logits_sum_real = tf.reduce_logsumexp(logits_real_unl, axis=<span class="number">1</span>)</span><br><span class="line">    logits_sum_fake = tf.reduce_logsumexp(logits_fake, axis=<span class="number">1</span>)</span><br><span class="line">    loss_unsupervised = <span class="number">0.5</span> * (</span><br><span class="line">        tf.negative(tf.reduce_mean(logits_sum_real)) +</span><br><span class="line">        tf.reduce_mean(tf.nn.softplus(logits_sum_real)) +</span><br><span class="line">        tf.reduce_mean(tf.nn.softplus(logits_sum_fake)))</span><br><span class="line">    loss_d = loss_supervised + loss_unsupervised</span><br><span class="line">    <span class="keyword">if</span> flags_obj.man_reg:</span><br><span class="line">        loss_d += <span class="number">1e-3</span> * tf.nn.l2_loss(logits_fake - logits_fake_perturbed) \</span><br><span class="line">            / tf.to_float(batch_size_tensor)</span><br></pre></td></tr></table></figure></p>
<h1 id="Classification-performance"><a href="#Classification-performance" class="headerlink" title="Classification performance"></a>Classification performance</h1><p>&emsp;&emsp;So how does it really perform? I have provided a few plots below. There are many things I might try to squeeze out additional performance (for instance, just training for longer, using a learning rate schedule, implementing weight normalization), but the main purpose of writing this post was to get to know a relatively simple yet powerful semi-supervised learning approach. After 100 epochs of training, the mean test accuracy approaches 98.9 percent.<br>&emsp;&emsp;The full script can be found <a href="https://github.com/jostosh/gan" target="_blank" rel="noopener">here</a>. Thanks for reading!<br><img src="/images/Semi-supervised-learning-with-GANs/jpeg1-1.jpeg" alt></p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a href="https://medium.com/@jos.vandewolfshaar/semi-supervised-learning-with-gans-23255865d0a4" target="_blank" rel="noopener">Semi-supervised learning with GANs</a></li>
</ul>

      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/semi-supervised-learning-and-gans.html" rel="next" title="Semi-Supervised Learning and GANs">
                <i class="fa fa-chevron-left"></i> Semi-Supervised Learning and GANs
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/win10-ru-he-zi-ding-yi-you-jian-cai-dan-xiu-gai-zhu-ce-biao-tu-wen.html" rel="prev" title="Win10如何自定义右键菜单-修改注册表（图文）">
                Win10如何自定义右键菜单-修改注册表（图文） <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif" alt="Junjie Jia">
            
              <p class="site-author-name" itemprop="name">Junjie Jia</p>
              <p class="site-description motion-element" itemprop="description">生命中的每一步都必须认真对待，把握今天，成就明天！</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">56</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">23</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">30</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                  
                    
                  
                  <a href="https://github.com/imjunjie" title="GitHub &rarr; https://github.com/imjunjie" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i></a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                  
                    
                  
                  <a href="mailto:junjie017@gmail.com" title="E-Mail &rarr; mailto:junjie017@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i></a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Generative-Adversarial-Networks"><span class="nav-number">1.</span> <span class="nav-text">Generative Adversarial Networks</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Semi-supervised-learning"><span class="nav-number">2.</span> <span class="nav-text">Semi-supervised learning</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#The-implementation"><span class="nav-number">3.</span> <span class="nav-text">The implementation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Putting-it-together"><span class="nav-number">4.</span> <span class="nav-text">Putting it together</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#The-discriminator’s-loss"><span class="nav-number">5.</span> <span class="nav-text">The discriminator’s loss</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Optimizing-the-discriminator"><span class="nav-number">6.</span> <span class="nav-text">Optimizing the discriminator</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Adding-some-control-flow-to-the-graph"><span class="nav-number">7.</span> <span class="nav-text">Adding some control flow to the graph</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#The-generator’s-loss-and-updates"><span class="nav-number">8.</span> <span class="nav-text">The generator’s loss and updates</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Adding-manifold-regularization"><span class="nav-number">9.</span> <span class="nav-text">Adding manifold regularization</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Classification-performance"><span class="nav-number">10.</span> <span class="nav-text">Classification performance</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Reference"><span class="nav-number">11.</span> <span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Junjie Jia</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
    <span title="站点总字数">458k</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
    <span title="站点阅读时长">6:57</span>
  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.0.0</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=7.0.0"></script>

  <script src="/js/src/motion.js?v=7.0.0"></script>



  
  


  <script src="/js/src/affix.js?v=7.0.0"></script>

  <script src="/js/src/schemes/pisces.js?v=7.0.0"></script>




  
  <script src="/js/src/scrollspy.js?v=7.0.0"></script>
<script src="/js/src/post-details.js?v=7.0.0"></script>



  


  <script src="/js/src/bootstrap.js?v=7.0.0"></script>


  
  


  


  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  

  
  

  


  

  

  

  

  

  

  

  

  

  


  <!-- 代码块复制功能 -->
<script type="text/javascript" src="/js/src/clipboard.min.js"></script>  
<script type="text/javascript" src="/js/src/clipboard-use.js"></script>

</body>
</html>

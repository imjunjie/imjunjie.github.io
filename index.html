<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">























  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link rel="stylesheet" href="https://fonts.cat.net/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext">
  






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.0.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.0.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.0.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.0.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.0.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.0.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false,"dimmer":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
<meta property="og:type" content="website">
<meta property="og:title" content="Imjunjie">
<meta property="og:url" content="http://imjunjie.github.io/index.html">
<meta property="og:site_name" content="Imjunjie">
<meta property="og:description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Imjunjie">
<meta name="twitter:description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">



  <link rel="alternate" href="/atom.xml" title="Imjunjie" type="application/atom+xml">




  <link rel="canonical" href="http://imjunjie.github.io/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Imjunjie</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Imjunjie</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">蜻蜓雨荷</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/win10-ubuntu-shuang-xi-tong-an-zhuang.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/win10-ubuntu-shuang-xi-tong-an-zhuang.html" class="post-title-link" itemprop="url">win10+ubuntu双系统安装</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-24 18:14:15" itemprop="dateCreated datePublished" datetime="2019-05-24T18:14:15+08:00">2019-05-24</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-25 14:46:31" itemprop="dateModified" datetime="2019-05-25T14:46:31+08:00">2019-05-25</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/TensorFlow/" itemprop="url" rel="index"><span itemprop="name">TensorFlow</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">255k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">3:52</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          The article has been encrypted, please enter your password to view.<br>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/win10-ubuntu-shuang-xi-tong-an-zhuang.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/ultraiso-ruan-die-tong-zhi-zuo-u-pan-qi-dong-pan.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/ultraiso-ruan-die-tong-zhi-zuo-u-pan-qi-dong-pan.html" class="post-title-link" itemprop="url">UltraISO软碟通制作U盘启动盘</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-22 23:32:18 / 修改时间：23:53:25" itemprop="dateCreated datePublished" datetime="2019-05-22T23:32:18+08:00">2019-05-22</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">2.7k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">2 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="基本简介"><a href="#基本简介" class="headerlink" title="基本简介"></a>基本简介</h1><p>UltraISO软碟通是一个类似于WinISO的ISO文件编辑工具，UltraISO软碟通操作简单，界面简洁，用户可以用来制作启动光盘映像。不仅如此，UltraISO软碟通还可以用来处理ISO文件的启动信息，随心所欲烧录光碟。华军软件园为您提供UltraISO软碟通破解版下载，还提供免费的注册码哦。有需要的小伙伴赶紧来下载使用吧。<br><img src="/images/UltraISO软碟通制作U盘启动盘/jpg1-1.jpg" alt></p>
<h1 id="UltraISO软碟通软件简介"><a href="#UltraISO软碟通软件简介" class="headerlink" title="UltraISO软碟通软件简介"></a>UltraISO软碟通软件简介</h1><p>&emsp;&emsp;UltraISO软碟通是一款功能强大而又方便实用的软碟文件制作/编辑/转换工具，UltraISO软碟通可以直接编辑软碟文件和从软碟中提取文件，也可以从CD-ROM直接制作软碟或者将硬盘上的文件制作成ISO文件。同时，你也可以处理ISO文件的启动信息，从而制作可引导光盘。使用UltraISO，你可以随心所欲地制作/编辑软碟文件，配合光盘刻录软件烧录出自己所需要的光碟。</p>
<h1 id="UltraISO软碟通功能介绍"><a href="#UltraISO软碟通功能介绍" class="headerlink" title="UltraISO软碟通功能介绍"></a>UltraISO软碟通功能介绍</h1><p>UltraISO软碟通可以图形化地从光盘、硬盘制作和编辑ISO文件UltraISO软碟通可以做到：<br><img src="/images/UltraISO软碟通制作U盘启动盘/jpg1-2.jpg" alt><br>　　1.从CD-ROM制作光盘的映像文件。</p>
<p>　　2.将硬盘、光盘、网络磁盘文件制作成各种映像文件。</p>
<p>　　3.从ISO文件中提取文件或文件夹。</p>
<p>　　4.编辑各种映像文件(如Nero Burning ROM、Easy CD Creator、Clone CD 制作的光盘映像文件)。</p>
<p>　　5.UltraISO软碟通可以制作可启动ISO文件。</p>
<p>　　+ ) 新ISO文件处理内核，更稳定、高效</p>
<p>　　+)超强还原功能，可以准确还原被编辑文件，确保ISO文件不被损坏</p>
<p>　　+)可制作1.2M/1.44M/2.88M软盘仿真启动光盘</p>
<p>　　+)完整的帮助文件(CHM格式)</p>
<p>　　+)实现重新打开文件列表功能</p>
<p>　　+)支持Windows 2000下制作光盘映像文件</p>
<p>　　+)修正刻盘后有时出现目录不能打开错误。使用UltraISO，你可以随心所欲地制作/编辑光盘映像文件，配合光盘刻录软件烧录出自己所需要的光碟。</p>
<p>　　6.制作和编辑音乐CD文件 </p>
<h1 id="UltraISO软碟通软件特色"><a href="#UltraISO软碟通软件特色" class="headerlink" title="UltraISO软碟通软件特色"></a>UltraISO软碟通软件特色</h1><p>　　可以写入硬盘映像，从而可以制作启动U盘(新版本，如9.2、9.3)，制作的启动U盘启动类型有USB-HDD、USB-HDD+、USB-ZIP、USB-ZIP+，推荐选择USB-HDD。<br>　　● UltraISO软碟通可以直接编辑ISO文件<br>　　● 可以从光盘映像中直接提取文件和目录<br>　　● UltraISO软碟通支持对ISO文件任意添加/删除/新建目录/重命名<br>　　● 可以将硬盘上的文件制作成ISO文件<br>　　● 可以逐扇区复制光盘，制作包含引导信息的完整映像文件<br>　　● 可以处理光盘启动信息，你可以在 ISO 文件中直接添加/删除/获取启动信息<br>　　● UltraISO软碟通支持几乎所有已知的光盘映像文件格式(.ISO,..BIN,.CUE,.IMG,.CCD,.CIF,.NRG,.BWT,BWI,.CDI等)，并且将它们保存为标准的ISO格式文件<br>　　● 可直接设置光盘映像中文件的隐藏属性<br>　　● UltraISO软碟通支持ISO 9660 Level1/2/3和Joliet扩展<br>　　● 自动优化ISO文件存储结构，节省空间<br>　　● UltraISO软碟通支持shell文件类型关联，可在Windows资源管理器中通过双击或鼠标右键菜单打开ISO文件<br>　　● 双窗口操作，使用十分方便<br>　　● 配合选购插件，可实现N合1启动光盘制作、光盘映像文件管理，甚至软光驱，功能更强大</p>
<h1 id="UltraISO软碟通安装步骤"><a href="#UltraISO软碟通安装步骤" class="headerlink" title="UltraISO软碟通安装步骤"></a>UltraISO软碟通安装步骤</h1><p>1、首先在本站下载UltraISO软碟通软件包，下载完成后得到zip格式的压缩包，鼠标右键点击压缩包在弹出的菜单栏中选择解压到当前文件夹，得到exe安装文件，鼠标左键双击exe文件进入UltraISO软碟通安装向导界面，如下图所示，点击下一步继续安装。<br><img src="/images/UltraISO软碟通制作U盘启动盘/png1-1.png" alt><br>2、进入UltraISO软碟通许可协议界面，用户需要先阅读协议后点击界面左下角的我接受协议，才可以进行下一步，如果用户选择不接受协议，则无法进行安装。所以勾选“我接受”后，点击界面右下方的下一步选项。<br><img src="/images/UltraISO软碟通制作U盘启动盘/png1-2.png" alt><br>3、进入UltraISO软碟通安装位置选择界面，用户可以选择默认安装，直接点击下一步，软件会默认安装到系统C盘中，或者点击浏览选择自定义安装，选择合适的安装位置后再点击下一步。（小编建议用户选择自定义安装，将软件安装到其他盘中，C盘为系统盘，软件过多会导致电脑运行变慢。）<br><img src="/images/UltraISO软碟通制作U盘启动盘/png1-3.png" alt><br>4、进入UltraISO软碟通开始菜单文件夹选择界面，用户可以选择默认的文件夹，或者点击浏览选择其他的文件夹，选择完成后点击界面下方的下一步。<br><img src="/images/UltraISO软碟通制作U盘启动盘/png1-4.png" alt><br>5、进入UltraISO软碟通附加任务选择界面，附加任务有在桌面创建图标、建立UltraISO 与.iso 文件关联和安装虚拟iOS驱动器三个选项，用户可以根据自己的需要选择勾选后在点击界面下方的下一步选项。<br><img src="/images/UltraISO软碟通制作U盘启动盘/png1-5.png" alt><br>6、进入UltraISO软碟通准备安装界面，如下图所示，用户需要查看界面选框中的内容是否有问题，如果跟自己设置的都一样就可以点击界面下方的安装选项进行安装了。如果有问题可以点击上一步返回修改后再回到该界面点击安装。<br><img src="/images/UltraISO软碟通制作U盘启动盘/png1-6.png" alt><br>　7、UltraISO软碟通软件正在安装中，用户需要耐心等待安装进度条完成就可以完成安装了。小编亲测安装速度是很快的，用户只需等一下会就可以了。<br><img src="/images/UltraISO软碟通制作U盘启动盘/png1-7.png" alt><br>8、出现下图中的界面就表明UltraISO软碟通已经安装成功到用户的电脑上了，在界面还有查看README文件和运行UltraISO两个选项，用户可以取消勾选第一个，然后点击完成就可以关闭安装界面打开软件使用了。<br><img src="/images/UltraISO软碟通制作U盘启动盘/png1-8.png" alt></p>
<h1 id="UltraISO软碟通制作u盘启动盘"><a href="#UltraISO软碟通制作u盘启动盘" class="headerlink" title="UltraISO软碟通制作u盘启动盘"></a>UltraISO软碟通制作u盘启动盘</h1><p>　步骤一、首先在本站下载安装好UltraISO软碟通软件后，在桌面找到快捷方式鼠标左键双击运行软件进入主界面，接下来点击界面左上角的菜单【文件】，然后进入打开iOS文件界面，选择你的ISO路径，选定后点击界面下方的打开选项;<br><img src="/images/UltraISO软碟通制作U盘启动盘/png2-1.png" alt><br>　步骤二、将ISO文件添加进来以后，用户再点击软件界面的启动光盘选项，然后在弹出的下拉选项中找到写入硬盘映像选项并点击，进入下一个界面。<br><img src="/images/UltraISO软碟通制作U盘启动盘/png2-2.png" alt><br>　步骤三、进入到写入硬盘映像界面，在界面下方选择硬盘驱动器(就是你的U盘盘符);选择完成后再点击界面下方的格式化，将U盘格式化一下。等待格式化完成后会提示用户格式化完毕，用户点击确定就可以了。<br><img src="/images/UltraISO软碟通制作U盘启动盘/png2-3.png" alt><br><img src="/images/UltraISO软碟通制作U盘启动盘/png2-4.png" alt><br>　步骤四、U盘格式化完成后，用户在写入硬盘映像界面还需要在选择写入方式，可选择：USB-HDD/USB-ZIP/USB-HDD+/USB-ZIP+ (小编选的是HDD+,选择完成后点击写入);然后等待程序提示刻录成功的信息后，就表示制作成功了<br><img src="/images/UltraISO软碟通制作U盘启动盘/png2-5.png" alt></p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="http://www.onlinedown.net/soft/614.htm" target="_blank" rel="noopener">UltraISO软碟通 9.6.5.3237 破解版含注册码</a></p>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/windows-xia-lei-si-linux-xia-de-ming-ling.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/windows-xia-lei-si-linux-xia-de-ming-ling.html" class="post-title-link" itemprop="url">Windows下类似Linux下的命令</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-22 19:12:46 / 修改时间：23:32:37" itemprop="dateCreated datePublished" datetime="2019-05-22T19:12:46+08:00">2019-05-22</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">410</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">1 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Windows下类似Linux下的命令</p>
<h1 id="cmd下"><a href="#cmd下" class="headerlink" title="cmd下"></a>cmd下</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">c:\Users\Jack&gt;for %x in (powershell.exe) do @echo %~$PATH:x</span><br><span class="line">c:\Windows/System32\WindowPowerShell/v1.0\powershell.exe</span><br></pre></td></tr></table></figure>
<h1 id="powershell-下"><a href="#powershell-下" class="headerlink" title="powershell 下"></a>powershell 下</h1><p>``` PS C:\Users\Jack&gt;Get-Command powershell.exe<br>CommandType     Name                                               Version    Source</p>
<hr>
<p>Application     powershell.exe                                     10.0.17… C:\WINDOWS\System32\WindowsPowerShell...</p>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/win10-xi-tong-win-e-zen-yang-gai-hui-da-kai-wo-de-dian-nao.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/win10-xi-tong-win-e-zen-yang-gai-hui-da-kai-wo-de-dian-nao.html" class="post-title-link" itemprop="url">win10系统Win+E怎样改回打开我的电脑</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-22 18:38:49 / 修改时间：18:49:18" itemprop="dateCreated datePublished" datetime="2019-05-22T18:38:49+08:00">2019-05-22</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">243</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">1 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Win10各种版本放出有一段时间了，而win10每次使用快捷键Win+E打开我的电脑（这台电脑）时，就变成了打开“快速访问”的文件夹，使用起来很不便，现在我们改回去以前windows的模式。</p>
<h1 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a>操作步骤</h1><p>1.打开“这台电脑”<br><img src="/images/win10系统Win-E怎样改回打开我的电脑/png1-1.png" alt></p>
<p>2.点击左上方菜单“查看”<br><img src="/images/win10系统Win-E怎样改回打开我的电脑/png1-2.png" alt></p>
<p>3.在下拉菜单右边打开“选项”<br><img src="/images/win10系统Win-E怎样改回打开我的电脑/png1-3.png" alt></p>
<p>4.打开文件资源管理器以完成以下操作中选“这台电脑”，再点“应用”、“确定”即可<br><img src="/images/win10系统Win-E怎样改回打开我的电脑/png1-4.png" alt></p>
<p>5.看看修改前使用WIN+E快捷键的样子：<br><img src="/images/win10系统Win-E怎样改回打开我的电脑/png1-5.png" alt></p>
<p>6.修改后的样子：<br><img src="/images/win10系统Win-E怎样改回打开我的电脑/png1-6.png" alt></p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://jingyan.baidu.com/article/fea4511a180942f7bb912501.html" target="_blank" rel="noopener">win10系统Win+E怎样改回打开我的电脑</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/tensorflow-du-qu-xun-lian-shu-ju-fang-fa.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/tensorflow-du-qu-xun-lian-shu-ju-fang-fa.html" class="post-title-link" itemprop="url">tensorflow读取训练数据方法</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-22 08:44:00 / 修改时间：20:08:39" itemprop="dateCreated datePublished" datetime="2019-05-22T08:44:00+08:00">2019-05-22</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/数据集处理/" itemprop="url" rel="index"><span itemprop="name">数据集处理</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">6.9k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">6 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="tensorflow读取训练数据方法"><a href="#tensorflow读取训练数据方法" class="headerlink" title="tensorflow读取训练数据方法"></a>tensorflow读取训练数据方法</h1><h2 id="预加载数据-Preloaded-data"><a href="#预加载数据-Preloaded-data" class="headerlink" title="预加载数据 Preloaded data"></a>预加载数据 Preloaded data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 设计Graph</span></span><br><span class="line">x1 = tf.constant([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">x2 = tf.constant([<span class="number">4</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">y = tf.add(x1, x2)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  <span class="keyword">print</span> sess.run(y)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line"><span class="comment"># [6 3 5]</span></span><br></pre></td></tr></table></figure>
<p>预加载数据方式是将训练数据直接内嵌到tf的图中，需要提前将数据加载到内存里，在数据量比较大，或者说在实际训练中，基本不可行。</p>
<h2 id="声明占位符，运行时Feeding数据"><a href="#声明占位符，运行时Feeding数据" class="headerlink" title="声明占位符，运行时Feeding数据"></a>声明占位符，运行时Feeding数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 设计Graph</span></span><br><span class="line">x1 = tf.placeholder(tf.int16)</span><br><span class="line">x2 = tf.placeholder(tf.int16)</span><br><span class="line"> </span><br><span class="line">epoch_num = <span class="number">0</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 用Python产生数据</span></span><br><span class="line">data = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">label= [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"> </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  <span class="keyword">while</span> epoch_num &lt;len(data):</span><br><span class="line">    <span class="keyword">print</span> sess.run((x1,x2), feed_dict=&#123;x1: data[epoch_num], x2: label[epoch_num]&#125;)</span><br><span class="line">    epoch_num+=<span class="number">1</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line"><span class="comment"># (array(2, dtype=int16), array(1, dtype=int16))</span></span><br><span class="line"><span class="comment"># (array(3, dtype=int16), array(0, dtype=int16))</span></span><br><span class="line"><span class="comment"># (array(4, dtype=int16), array(1, dtype=int16))</span></span><br></pre></td></tr></table></figure>
<p>声明占位符是在训练过程中Feeding填充数据，可以选择把所有数据一次性加载到内存，每次取一个batch的数据出来训练，也可以选择把数据通过python建立一个生成器，每次加载一个batch的数据出来训练，加载方式比较灵活但是效率相对比较低。</p>
<h2 id="从文件直接读取数据"><a href="#从文件直接读取数据" class="headerlink" title="从文件直接读取数据"></a>从文件直接读取数据</h2><p>从文件读取数据的方式是在Graph图中定义好文件读取的方式，在Session会话中启动（一个或多个）线程，把训练数据异步加载到内存（样本）队列中（先加载到文件名队列中，tf自动读取到内存队列中），通过队列管理器进行管理，执行效率较高，工作流程示意图：<br><img src="/images/tensorflow读取训练数据方法/png1-1.png" alt><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 样本个数</span></span><br><span class="line">sample_num = <span class="number">5</span></span><br><span class="line"><span class="comment"># 设置迭代次数</span></span><br><span class="line">epoch_num = <span class="number">2</span></span><br><span class="line"><span class="comment"># 设置一个批次中包含样本个数</span></span><br><span class="line">batch_size = <span class="number">3</span></span><br><span class="line"><span class="comment"># 计算每一轮epoch中含有的batch个数</span></span><br><span class="line">batch_total = int(sample_num / batch_size) + <span class="number">1</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 生成4个数据和标签</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_data</span><span class="params">(sample_num=sample_num)</span>:</span></span><br><span class="line">    labels = np.asarray(range(<span class="number">0</span>, sample_num))</span><br><span class="line">    images = np.random.random([sample_num, <span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>])</span><br><span class="line">    print(<span class="string">'image size &#123;&#125;,label size :&#123;&#125;'</span>.format(images.shape, labels.shape))</span><br><span class="line">    <span class="keyword">return</span> images, labels</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_batch_data</span><span class="params">(batch_size=batch_size)</span>:</span></span><br><span class="line">    images, label = generate_data()</span><br><span class="line">    <span class="comment"># 数据类型转换为tf.float32</span></span><br><span class="line">    images = tf.cast(images, tf.float32)</span><br><span class="line">    label = tf.cast(label, tf.int32)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># 从tensor列表中按顺序或随机抽取一个tensor准备放入文件名称队列</span></span><br><span class="line">    input_queue = tf.train.slice_input_producer([images, label], num_epochs=epoch_num, shuffle=<span class="literal">False</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># 从文件名称队列中读取文件准备放入文件队列</span></span><br><span class="line">    image_batch, label_batch = tf.train.batch(input_queue, batch_size=batch_size, num_threads=<span class="number">2</span>, capacity=<span class="number">64</span>,</span><br><span class="line">                                              allow_smaller_final_batch=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> image_batch, label_batch</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">image_batch, label_batch = get_batch_data(batch_size=batch_size)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 先执行初始化工作</span></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    sess.run(tf.local_variables_initializer())</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># 开启一个协调器</span></span><br><span class="line">    coord = tf.train.Coordinator()</span><br><span class="line">    <span class="comment"># 使用start_queue_runners 启动队列填充</span></span><br><span class="line">    threads = tf.train.start_queue_runners(sess, coord)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> coord.should_stop():</span><br><span class="line">            <span class="keyword">print</span> <span class="string">'************'</span></span><br><span class="line">            <span class="comment"># 获取每一个batch中batch_size个样本和标签</span></span><br><span class="line">            image_batch_v, label_batch_v = sess.run([image_batch, label_batch])</span><br><span class="line">            print(image_batch_v.shape, label_batch_v)</span><br><span class="line">    <span class="keyword">except</span> tf.errors.OutOfRangeError:  <span class="comment"># 如果读取到文件队列末尾会抛出此异常</span></span><br><span class="line">        print(<span class="string">"done! now lets kill all the threads……"</span>)</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        <span class="comment"># 协调器coord发出所有线程终止信号</span></span><br><span class="line">        coord.request_stop()</span><br><span class="line">        print(<span class="string">'all threads are asked to stop!'</span>)</span><br><span class="line">    coord.join(threads)  <span class="comment"># 把开启的线程加入主线程，等待threads结束</span></span><br><span class="line">    print(<span class="string">'all threads are stopped!'</span>)  </span><br><span class="line">    </span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line"><span class="comment"># image size (5, 224, 224, 3),label size :(5,)</span></span><br><span class="line"><span class="comment"># ************</span></span><br><span class="line"><span class="comment"># ((3, 224, 224, 3), array([0, 1, 2], dtype=int32))</span></span><br><span class="line"><span class="comment"># ************</span></span><br><span class="line"><span class="comment"># ((3, 224, 224, 3), array([3, 0, 4], dtype=int32))</span></span><br><span class="line"><span class="comment"># ************</span></span><br><span class="line"><span class="comment"># ((3, 224, 224, 3), array([1, 2, 3], dtype=int32))</span></span><br><span class="line"><span class="comment"># ************</span></span><br><span class="line"><span class="comment"># done! now lets kill all the threads……</span></span><br><span class="line"><span class="comment"># all threads are asked to stop!</span></span><br><span class="line"><span class="comment"># all threads are stopped!</span></span><br></pre></td></tr></table></figure></p>
<p>与从文件直接读取训练数据对应的还有一种方式是<font color="red">先把数据写入TFRecords二进制文件，再从队列中读取</font>。</p>
<p>TFRecords方式相比直接读取训练文件，效率更高，特别是在训练文件比较多的情况下，缺点是需要额外编码处理TFRecords，不够直观。</p>
<h2 id="Tensorflow-动态图机制（Eager-Execution）下的Dataset数据读取"><a href="#Tensorflow-动态图机制（Eager-Execution）下的Dataset数据读取" class="headerlink" title="Tensorflow 动态图机制（Eager Execution）下的Dataset数据读取"></a>Tensorflow 动态图机制（Eager Execution）下的Dataset数据读取</h2><p><font color="red">Tensorflow动态图机制支持图上的运算动态执行，更方便网络模型搭建和程序调试</font>，不再需要通过sess.run()才能执行所定义的运算，调试时可以直接查看变量的值，做到了“所见即所得”，动态图运算应该是未来tensorflow发展的方向。<br><strong>动图模式下就必须使用Dataset API来读取数据。</strong><br>tensorflow 1.3 版本中，Dataset API是在contrib包的，1.4以后版本中，Dataset 放到了data中：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tf.contrib.data.Dataset  <span class="comment">#1.3</span></span><br><span class="line">tf.data.Dataset  <span class="comment"># 1.4</span></span><br></pre></td></tr></table></figure></p>
<p>Dataset 读取数据示例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"> </span><br><span class="line">dataset = tf.contrib.data.Dataset.from_tensor_slices(np.array([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]))</span><br><span class="line"> </span><br><span class="line">iterator = dataset.make_one_shot_iterator()</span><br><span class="line"> </span><br><span class="line">one_element = iterator.get_next()</span><br><span class="line"> </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    print(sess.run(one_element))</span><br><span class="line"> </span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line"><span class="comment"># 0</span></span><br><span class="line"><span class="comment"># 1</span></span><br><span class="line"><span class="comment"># 2</span></span><br><span class="line"><span class="comment"># 3</span></span><br><span class="line"><span class="comment"># 4</span></span><br></pre></td></tr></table></figure></p>
<p>Dataset 读取训练图片文件示例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将图片文件名列表中的图片文件读入，缩放到指定的size大小</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_parse_function</span><span class="params">(filename, label, size=[<span class="number">128</span>,<span class="number">128</span>])</span>:</span></span><br><span class="line">  image_string = tf.read_file(filename)</span><br><span class="line">  image_decoded = tf.image.decode_image(image_string)</span><br><span class="line">  image_resized = tf.image.resize_images(image_decoded, size)</span><br><span class="line">  <span class="keyword">return</span> image_resized, label</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 图片文件名列表</span></span><br><span class="line">filenames = tf.constant([<span class="string">"/var/data/image1.jpg"</span>, <span class="string">"/var/data/image2.jpg"</span>, ...])</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 图片文件标签</span></span><br><span class="line">labels = tf.constant([<span class="number">0</span>, <span class="number">37</span>, ...])</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 建立一个数据集，它的每一个元素是文件列表的一个切片</span></span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))</span><br><span class="line"><span class="comment"># 对数据集中的图片文件resize</span></span><br><span class="line">dataset = dataset.map(_parse_function)</span><br><span class="line"><span class="comment"># 对数据集中的图片文件组成一个一个batch，并对数据集扩展10次，相当于可以训练10轮</span></span><br><span class="line">dataset = dataset.shuffle(buffersize=<span class="number">1000</span>).batch(<span class="number">32</span>).repeat(<span class="number">10</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://blog.csdn.net/dcrmg/article/details/80041389" target="_blank" rel="noopener">tensorflow读取训练数据方法</a></p>
<h1 id="TensorFlow-数据读取方法总结"><a href="#TensorFlow-数据读取方法总结" class="headerlink" title="TensorFlow 数据读取方法总结"></a>TensorFlow 数据读取方法总结</h1><h2 id="读取数据（Reading-data）"><a href="#读取数据（Reading-data）" class="headerlink" title="读取数据（Reading data）"></a>读取数据（Reading data）</h2><p>TensorFlow输入数据的方法有四种：</p>
<ul>
<li>tf.data API：可以很容易的构建一个复杂的输入通道(pipeline)（首选数据输入方式）（Eager模式必须使用该API来构建输入通道）</li>
<li>Feeding：使用Python代码提供数据，然后将数据feeding到计算图中。</li>
<li>QueueRunner：基于队列的输入通道（在计算图计算前从队列中读取数据）</li>
<li>Preloaded data：用一个constant常量将数据集加载到计算图中（主要用于小数据集） </li>
</ul>
<h2 id="文章目录"><a href="#文章目录" class="headerlink" title="文章目录"></a>文章目录</h2><p>&emsp;&emsp;读取数据（Reading data）</p>
<ol>
<li>tf.data API</li>
<li>Feeding</li>
<li>QueueRunner<br>&emsp;&emsp;3.1 Filenames, shuffling, and epoch limits<br>&emsp;&emsp;3.2 File formats<br>&emsp;&emsp;&emsp;&emsp;3.2.1 CSV file<br>&emsp;&emsp;&emsp;&emsp;3.2.2 Fixed length records<br>&emsp;&emsp;&emsp;&emsp;3.2.3 Standard TensorFlow format<br>&emsp;&emsp;3.3 Preprocessing<br>&emsp;&emsp;3.4 Batching<br>&emsp;&emsp;3.5 Creating threads to prefetch using QueueRunner objects<br>&emsp;&emsp;3.6 Filtering records or producing multiple examples per record<br>&emsp;&emsp;3.7 Sparse input data</li>
<li>Preloaded data</li>
<li><p>Multiple input pipelines </p>
</li>
<li><p>tf.data API<br>关于tf.data.Dataset的更详尽解释请看《programmer’s guide》。tf.data API能够从不同的输入或文件格式中读取、预处理数据，并且对数据应用一些变换（例如，batching、shuffling、mapping function over the dataset），tf.data API 是旧的 feeding、QueueRunner的升级。 </p>
</li>
</ol>
<p>参考文献<br><a href="https://blog.csdn.net/s2010241013/article/details/79650856" target="_blank" rel="noopener">tensorflow之从文件中读取数据（适用场景：大规模数据集，亲测有效~）</a></p>
<p><a href="https://blog.csdn.net/u014061630/article/details/80712635" target="_blank" rel="noopener">TensorFlow 数据读取方法总结</a></p>
<p><a href="http://www.twistedwg.com/2019/01/23/GAN_image_generation.html" target="_blank" rel="noopener">GAN在图像生成应用综述（论文解读）</a></p>
<p>提示 “Unzip trin-images-idx3-ubyte.gz”，因此考虑安装gzip<br>search target1:<a href="http://www.dlldownloader.com/gzip-dll/" target="_blank" rel="noopener">Download Gzip.dll for Windows 10, 8.1, 8, 7, Vista and XP</a><br>Gzip.dll download. The Gzip.dll file is a dynamic link library for Windows 10, 8.1, 8, 7, Vista and XP. You can fix “The file Gzip.dll is missing.” and “Gzip.dll not found.” errors by downloading and installing this file from our site.</p>
<p><a href="http://zgserver.com/gzipwindows-cmd.html" target="_blank" rel="noopener">如何将gzip命令添加到Windows CMD？</a></p>
<p><a href="https://www.cygwin.com/" target="_blank" rel="noopener">Cygwin</a></p>
<p><a href="https://www.pythonforbeginners.com/os/subprocess-for-system-administrators" target="_blank" rel="noopener">Subprocess and Shell Commands in Python</a></p>
<p><a href="https://www.lifewire.com/example-uses-of-the-linux-gzip-command-4078675" target="_blank" rel="noopener">Example Uses of the Linux gzip Command</a></p>
<p><a href="https://blog.csdn.net/yuxisanno139/article/details/83016520" target="_blank" rel="noopener">windows 命令行使用 gzip</a></p>
<p><a href="https://linux.cn/article-6679-1.html" target="_blank" rel="noopener">基础：tar 命令使用介绍</a></p>
<p><a href="https://gaianote.github.io/" target="_blank" rel="noopener">李云鹏个人博客</a></p>
<p><a href="https://www.gnu.org/server/select-language.html?callback=/software/gzip/" target="_blank" rel="noopener">GNU Operating System</a></p>
<p><a href="https://cygwin.com/install.html" target="_blank" rel="noopener">Cygwin</a></p>
<p><a href="https://www.cnblogs.com/wangshuyi/p/9679700.html" target="_blank" rel="noopener">Cygwin安装配置</a></p>
<p><a href="https://www.cnblogs.com/geaozhang/p/6679904.html" target="_blank" rel="noopener">zip-gzip-bzip2_压缩文件</a></p>
<p><a href="http://www.o-bible.com/gb/gzip.html" target="_blank" rel="noopener">GZIP简介</a></p>
<p><a href="http://unxutils.sourceforge.net/" target="_blank" rel="noopener">GNU utilities for Win32</a></p>
<p><a href="http://kb.winzip.com/kb/entry/124/" target="_blank" rel="noopener">如何在命令行中提取gzip和tar文件</a></p>
<p><a href="https://www.gnu.org/software/gzip/manual/gzip.html" target="_blank" rel="noopener">GNU Gzip</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/56521586" target="_blank" rel="noopener">既香又贵的小飞跃：RTX2060替换了GTX1060</a></p>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/java-zai-windows-huan-jing-xia-an-zhuang-jdk-bing-she-zhi-huan-jing-bian-liang.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/java-zai-windows-huan-jing-xia-an-zhuang-jdk-bing-she-zhi-huan-jing-bian-liang.html" class="post-title-link" itemprop="url">Java - 在Windows环境下安装JDK并设置环境变量</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-21 20:51:53 / 修改时间：21:45:40" itemprop="dateCreated datePublished" datetime="2019-05-21T20:51:53+08:00">2019-05-21</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">2k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">2 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="什么是JDK"><a href="#什么是JDK" class="headerlink" title="什么是JDK"></a>什么是JDK</h1><p>&emsp;&emsp;JDK是Java Development Kit的首字母缩写，意为Java开发工具包，是整个Java的核心。其不提供具体的开发软件，仅向程序员提供编写Java程序所必须的类库和Java语言规范。其包含以下三个版本：</p>
<ul>
<li>Java SE：Java标准环境</li>
<li>Java EE：Java企业级环境</li>
<li>Java ME：用于移动设备、嵌入式设备的Java环境</li>
</ul>
<h1 id="JDK包含哪些东西"><a href="#JDK包含哪些东西" class="headerlink" title="JDK包含哪些东西"></a>JDK包含哪些东西</h1><p>JDK包含Java运行时环境(Java Runtime Environment,JRE)、Java工具集（如JConsole监控台）和Java的基础类库（如java.util包）。</p>
<h1 id="在Windows10中怎么安装JDK"><a href="#在Windows10中怎么安装JDK" class="headerlink" title="在Windows10中怎么安装JDK"></a>在Windows10中怎么安装JDK</h1><p>编者的电脑为Windows10 64位，因此以Windows10为例向大家展示JDK的安装过程。如有不懂的地方，请直接通过公众号向我提问哦！<br>第一步、下载JDK<br>一般开发者使用的是标准Java开发环境Java SE，因此我们打开以下网址：<br><a href="https://www.oracle.com/technetwork/java/javase/overview/index.html" target="_blank" rel="noopener">https://www.oracle.com/technetwork/java/javase/overview/index.html</a>, 所得界面如下：<br><img src="/images/Java-在Windows环境下安装JDK并设置环境变量/png1-1.png" alt><br>请注意途中红框的位置，我们要下载Java SE就得点这里。进去后是如下界面：<br><img src="/images/Java-在Windows环境下安装JDK并设置环境变量/png1-2.png" alt><br>点进去后，我们发现有很多版本的JDK，这次我们安装使用人数比较多、比较稳定的JDK8，页面如下：<br><img src="/images/Java-在Windows环境下安装JDK并设置环境变量/png1-3.png" alt><br>我们看到，其提供了三种下载的内容，JDK、Server JRE和JRE，这里我们是在本机开发使用，因此选择JDK，点击DOWNLOAD进入下载页：<br><img src="/images/Java-在Windows环境下安装JDK并设置环境变量/png1-4.png" alt><br>这个页面中提供了多个版本的JDK，这里我们选择第一个就好。先点击Accept License Agreement同意Oracle的开源协议，然后选择Windows x64位进行下载（记得一定要先同意协议哦）</p>
<p>第二步、开始安装<br>下载完成后，双击进行安装，界面如下：<br><img src="/images/Java-在Windows环境下安装JDK并设置环境变量/png1-5.png" alt><br>点下一步，在这一步中要选择安装路径，这个路径一定要记住，待会儿有大用处：<br><img src="/images/Java-在Windows环境下安装JDK并设置环境变量/png1-6.png" alt><br>然后点下一步进行安装，这个过程可能会持续几分钟，之后会出现如下这个界面：<br><img src="/images/Java-在Windows环境下安装JDK并设置环境变量/png1-7.png" alt><br>这里需要选择的是JRE的安装路径，这个路径也请记住了，点下一步就开始安装了：<br><img src="/images/Java-在Windows环境下安装JDK并设置环境变量/png1-8.png" alt><br><img src="/images/Java-在Windows环境下安装JDK并设置环境变量/png1-9.png" alt><br>安装完毕了，直接点关闭即可。</p>
<p>第三步、设置环境变量<br>&emsp;&emspp;一般JDK安装完成后，都会进行环境变量设置，目的是让系统能够找到java和javac命令。不过现在程序的傻瓜式安装，一般情况下会自动给你配置好，但是为了安全起见，我们还是要检查下：<br>请按以下步骤点击：鼠标选中我的电脑 -&gt; 右键 -&gt; 属性，出现如下界面：<br><img src="/images/Java-在Windows环境下安装JDK并设置环境变量/png1-10.png" alt><br>点击高级系统设置 -&gt; 环境变量，出现如下界面：<br><img src="/images/Java-在Windows环境下安装JDK并设置环境变量/png1-11.png" alt><br>我们在下方系统变量栏目中，点击新建，新建类目如下：<br><img src="/images/Java-在Windows环境下安装JDK并设置环境变量/png1-12.png" alt></p>
<ul>
<li>变量名：JAVA_HOME</li>
<li>变量值：你的JDK的安装路径，记住，是JDK，不是JRE，比如我的JDK路径是：C:\SoftwareInstall\Java\jdk-12.0.1</li>
</ul>
<p>设置完成后，点击确定；然后我们再点新建，设置另一个环境变量：<br><img src="/images/Java-在Windows环境下安装JDK并设置环境变量/png1-13.png" alt></p>
<ul>
<li>变量名：CLASSPATH</li>
<li>变量值：.;%JAVA_HOME%libdt.jar;%JAVA_HOME%libtools.jar,一定要记住前面的.;哦！</li>
</ul>
<p>&emsp;&emsp;最后，我们还需要在一个名为Path的变量中加入Java的环境信息。首先找到Path变量（大小写请忽略，系统可能不同），然后点击编辑，紧接着前面的环境变量后面加上%JAVA_HOME%\bin;%JAVA_HOME%\jre\bin;，在你添加的环境和原环境之间，记得用;隔开哦！</p>
<p>到这里，环境变量就设置完成啦！</p>
<p>第四步、验证安装<br>现在请按下Windows+R，就是那个四叶窗图标+R，然后输入cmd并回车，在命令行中键入java -version，如果出现了如下界面，显示了Java的版本信息，就是配置成功啦！<br><img src="/images/Java-在Windows环境下安装JDK并设置环境变量/png1-14.png" alt><br>恭喜你，迈出了成功的第一步！</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>&emsp;&emsp;本文讲述了在Windows10环境中安装JDK的过程。在其他版本的Windows中也大同小异。如果读者遇到其他问题，欢迎在公众号中向我提问，或者在我的博客中留言！下一节的番外篇2中，将会向大家讲述Java中比较重要的几个关键字及编码规范。<br>&emsp;&emsp;于20190521，安装jdk-12.0.1的过程中，发现安装过程中并没有提示要安装jre，故此次安装仅仅安装了jdk文件。</p>
<h1 id="JDK下载网站"><a href="#JDK下载网站" class="headerlink" title="JDK下载网站"></a>JDK下载网站</h1><p><a href="https://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank" rel="noopener">https://www.oracle.com/technetwork/java/javase/downloads/index.html</a> </p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://segmentfault.com/a/1190000018132781" target="_blank" rel="noopener">番外篇1：在Windows环境下安装JDK</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/51228073" target="_blank" rel="noopener">jdk版本的选择（推荐1.8）</a></li>
<li><a href="https://blog.csdn.net/lewky_liu/article/details/84112696" target="_blank" rel="noopener">Java - 安装jdk并设置环境变量</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/python-de-tqdm-mo-kuai.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/python-de-tqdm-mo-kuai.html" class="post-title-link" itemprop="url">python的Tqdm模块</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-21 19:14:49 / 修改时间：19:56:55" itemprop="dateCreated datePublished" datetime="2019-05-21T19:14:49+08:00">2019-05-21</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/TensorFlow/" itemprop="url" rel="index"><span itemprop="name">TensorFlow</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">571</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">1 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Tqdm 是一个快速，可扩展的Python进度条，可以在 Python 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器 tqdm(iterator)。<br>基本用法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> tqdm(range(<span class="number">10000</span>)):</span><br><span class="line">     sleep(<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure></p>
<p>当然除了tqdm，还有trange,使用方式完全相同<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> trange(<span class="number">100</span>):</span><br><span class="line">        sleep(<span class="number">0.1</span>)</span><br><span class="line">```        </span><br><span class="line"></span><br><span class="line">只要传入list都可以：</span><br><span class="line">``` python </span><br><span class="line">pbar = tqdm([<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>, <span class="string">"d"</span>])</span><br><span class="line"><span class="keyword">for</span> char <span class="keyword">in</span> pbar:</span><br><span class="line">    pbar.set_description(<span class="string">"Processing %s"</span> % char)</span><br></pre></td></tr></table></figure></p>
<p>也可以手动控制更新<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tqdm(total=<span class="number">100</span>) <span class="keyword">as</span> pbar:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        pbar.update(<span class="number">10</span>)</span><br></pre></td></tr></table></figure></p>
<p>也可以这样：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pbar = tqdm(total=100)</span><br><span class="line">for i in range(10):</span><br><span class="line">    pbar.update(10)</span><br><span class="line">pbar.close()</span><br></pre></td></tr></table></figure></p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://blog.csdn.net/langb2014/article/details/54798823" target="_blank" rel="noopener">【CSDN】(2017年01月31日)python的Tqdm模块</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/gan-xue-xi-xi-lie-jiao-cheng.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/gan-xue-xi-xi-lie-jiao-cheng.html" class="post-title-link" itemprop="url">GAN学习系列教程</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-21 14:15:06" itemprop="dateCreated datePublished" datetime="2019-05-21T14:15:06+08:00">2019-05-21</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-22 23:55:23" itemprop="dateModified" datetime="2019-05-22T23:55:23+08:00">2019-05-22</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/TensorFlow/" itemprop="url" rel="index"><span itemprop="name">TensorFlow</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">427</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">1 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Github站点：</p>
<ul>
<li><a href="https://github.com/greenfishflying/wzx-Paper-notes/blob/master/GAN%20note.md" target="_blank" rel="noopener">各种GAN的介绍-GAN note.md</a></li>
<li><a href="https://github.com/PerfXLab/embedded_ai/blob/master/bi-weekly-reports/2018-01-31.md" target="_blank" rel="noopener">嵌入式AI 双周简报 (2018-01-31)</a></li>
</ul>
<p>博文站点：</p>
<ul>
<li><p><a href="https://www.atyun.com/18356.html" target="_blank" rel="noopener">(Keras)动手实现会写数字的神经网络—半监督学习和生成式对抗网络介绍</a><br><a href="https://towardsdatascience.com/semi-supervised-learning-and-gans-f23bbf4ac683" target="_blank" rel="noopener">Semi-Supervised Learning and GANs</a></p>
</li>
<li><p><a href="https://medium.com/@jos.vandewolfshaar/semi-supervised-learning-with-gans-23255865d0a4" target="_blank" rel="noopener">(code)Semi-supervised learning with GANs</a></p>
</li>
</ul>
<p><a href="https://www.kdd.org/kdd2018/accepted-papers/view/semi-supervised-generative-adversarial-network-for-gene-expression-inferenc" target="_blank" rel="noopener">(KDD2018)Semi-Supervised Generative Adversarial Network for Gene Expression Inference</a></p>
<p><a href="https://akiraaptx.blog/2019/02/21/semi-supervised-gan/2/" target="_blank" rel="noopener">(developer-mayuan)Semi-Supervised GAN</a><br><a href="https://akiraaptx.blog/" target="_blank" rel="noopener">(GAN系列)developer-mayuan</a></p>
<p><a href="http://pwp.gatech.edu/hrl/mr-gan/" target="_blank" rel="noopener">Semi-Supervised Haptic Material Recognition using GANs</a></p>
<p>生成对抗网络 半监督分类</p>
<p><a href="http://pwp.gatech.edu/hrl/mr-gan/" target="_blank" rel="noopener">http://pwp.gatech.edu/hrl/mr-gan/</a></p>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/win10-rtx-2060-tensorflow-gpu.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/win10-rtx-2060-tensorflow-gpu.html" class="post-title-link" itemprop="url">Win10 + RTX 2060 + tensorflow GPU</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-21 08:31:43 / 修改时间：09:21:15" itemprop="dateCreated datePublished" datetime="2019-05-21T08:31:43+08:00">2019-05-21</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/TensorFlow/" itemprop="url" rel="index"><span itemprop="name">TensorFlow</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">1.8k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">2 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>买了新的笔电并成功配置了Win10上面的tensorflow的GPU版</p>
<p>毕竟稍微大一点的神经网路CPU跑起来实在慢的要人命!</p>
<p>纪录了一些流程希望帮助也在安装的朋友省一点时间</p>
<p>可以赶快开始利用新买的显卡来工作或做程式学习</p>
<h1 id="配置流程"><a href="#配置流程" class="headerlink" title="配置流程"></a>配置流程</h1><h2 id="首先下载并安装Anaconda-Python3-7的版本"><a href="#首先下载并安装Anaconda-Python3-7的版本" class="headerlink" title="首先下载并安装Anaconda+Python3.7的版本"></a>首先下载并安装Anaconda+Python3.7的版本</h2><p><a href="https://www.anaconda.com/distribution/" target="_blank" rel="noopener">https://www.anaconda.com/distribution/</a><br><img src="/images/Win10-RTX-2060-tensorflow-GPU/png1-1.png" alt></p>
<h2 id="下载后直接参考tensorflow官网的说明"><a href="#下载后直接参考tensorflow官网的说明" class="headerlink" title="下载后直接参考tensorflow官网的说明"></a>下载后直接参考tensorflow官网的说明</h2><p>不要相信来路不明的教学啦QQ乖乖照着<a href="https://www.tensorflow.org/install/gpu" target="_blank" rel="noopener">TensorFlow-gpu官网</a>做才是最准的!!!<br>我们需要做的事情有:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span> 确认GPU驱动有更新</span><br><span class="line"><span class="number">2.</span> CUDA@Tookit <span class="number">10.0</span>安装</span><br><span class="line"><span class="number">3.</span> cuDNN SDK <span class="number">7.5</span>(forCUDA <span class="number">10.0</span>)安装</span><br></pre></td></tr></table></figure></p>
<p>官方网址：<a href="https://www.tensorflow.org/install/gpu" target="_blank" rel="noopener">https://www.tensorflow.org/install/gpu</a><br><img src="/images/Win10-RTX-2060-tensorflow-GPU/png1-2.png" alt="tensorflow官网的GPU配置要求"><br>配置方案，可以<a href="https://github.com/fo40225/tensorflow-windows-wheel" target="_blank" rel="noopener">参考</a>下图<br><img src="/images/Win10-RTX-2060-tensorflow-GPU/png1-3.png" alt="tensorflow官网的GPU配置要求"><br>照着上面的标示安装必要程序<br>1.显卡驱动因为刚买来还满新的进Geforce Experience更新一下不用重载<br>根据<a href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html" target="_blank" rel="noopener">显卡驱动</a>，选择对应的CUDA版本号<br><img src="/images/Win10-RTX-2060-tensorflow-GPU/png1-4.png" alt="tensorflow官网的GPU配置要求"></p>
<p>查看本机的显卡驱动版本号，方法如下：<br>&emsp;&emsp;WIN+R，输入CMD，然后输入”nvidia-smi”，即可显示对应的显卡驱动版本号，有些还会显示对应的支持CUDA的版本号，本机验证CUDA支持10.0。</p>
<p>2.下载CUDA 10.0 + CUDNN7.5 for 10.0 (版本记得要一样喔不然会错误)</p>
<ul>
<li>1.下载CUDA 10.0, <a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">CUDA Toolkit Archive</a><br><img src="/images/Win10-RTX-2060-tensorflow-GPU/png1-5.png" alt="tensorflow官网的GPU配置要求"></li>
</ul>
<p>如想了解是否正确安装可以<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc - V</span><br></pre></td></tr></table></figure></p>
<p>如果成功应该是如下图所示：<br><img src="/images/Win10-RTX-2060-tensorflow-GPU/png1-6.png" alt="测试cuda是否安装成功-别人的图"></p>
<ul>
<li>2.下载CUDNN<br>&emsp;&emspp;直接去NVDIA官网去下载就好啦~大家想要下载，还需要注册NVDIA账户，很麻烦，不过下载好像可以直接微信登录了，我没试过，大家就直接微信登录就好啦,下面附上链接：<a href="https://developer.nvidia.com/rdp/cudnn-archive" target="_blank" rel="noopener">下载链接</a><br><code>这里面有好几个for CUDA10.0的，大家一定要注意，因为关系到我们后面tensorflow的版本，这里出错了，后面就会报错！！！
这里我们选择cuDNN v7.5的版本</code><br>到这里下载完成！完成后咱们开始解压，然后将相应的包，放到cuda相应包底下。<br><img src="/images/Win10-RTX-2060-tensorflow-GPU/png1-7.png" alt="测试cuda是否安装成功-别人的图"><br>咱们只需要拿出这些文件夹里面文件放到想要cuda文件夹即可，我的cuda文件夹地址为：<br><code>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0</code><br>供大家参考。</li>
</ul>
<ol>
<li>TensorFlow-GPU下载和安装<br><img src="/images/Win10-RTX-2060-tensorflow-GPU/png1-8.png" alt="测试cuda是否安装成功-别人的图"><br>我们可以通过进入英伟达控制面板，点击帮助，选择系统信息，再点组件，看到我们的RTX 2060显卡是支持CUDA10。<br>前面我让大家下载了CUDA9.2,没坑大家哦，CUDA9.2也是支持RTX 2060的。tensoeflow官方现在无论哪个版本都不支持，所以我们还是去求助<a href="https://github.com/fo40225/tensorflow-windows-wheel" target="_blank" rel="noopener">Github</a>！！！ </li>
</ol>
<p>安装<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// An highlighted block</span><br><span class="line">pip install tensorflow_gpu</span><br></pre></td></tr></table></figure></p>
<h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// An highlighted block</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">hello = tf.constant(<span class="string">'Hello, TensorFlow!'</span>)</span><br><span class="line">sess = tf.Session()</span><br><span class="line">print(sess.run(hello))</span><br></pre></td></tr></table></figure>
<h1 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h1><p><img src="/images/Win10-RTX-2060-tensorflow-GPU/png1-9.png" alt="测试cuda是否安装成功-别人的图"><br><img src="/images/Win10-RTX-2060-tensorflow-GPU/png1-10.png" alt="测试cuda是否安装成功-别人的图"><br>已经能够识别出RTX2060显卡了，并成功输出！到这里也算完成了，大家安装遇到的坑也欢迎来交流！</p>
<h1 id="常用网址"><a href="#常用网址" class="headerlink" title="常用网址"></a>常用网址</h1><ol>
<li><a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">CUDA Toolkit Archive</a></li>
<li><a href="https://developer.nvidia.com/rdp/cudnn-archive" target="_blank" rel="noopener">cuDNN Archive</a></li>
<li><a href="https://github.com/fo40225/tensorflow-windows-wheel" target="_blank" rel="noopener">Tensorflow prebuilt binary for Windows</a></li>
<li><a href="https://www.tensorflow.org/install/gpu" target="_blank" rel="noopener">TensorFlow-gpu官网</a></li>
</ol>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://blog.csdn.net/weixin_38525326/article/details/86687885" target="_blank" rel="noopener">【CSDN】(2019年01月29日 11:48:14)RTX2060+win10+Tensorflow GPU+CUDA 9.2+CUDNN7.2+python 3.65</a></li>
<li><a href="https://www.gongyesheji.org/?p=951" target="_blank" rel="noopener">【Blog】(2019年3月24日)WIN10+CUDA10 +CUDNN7.5+ TENSORFLOW-GPU1.13.1 + python3.7 运行NVIDIA STYLEGAN 的安装过程和踩坑实录</a></li>
<li><a href="https://medium.com/%E5%B0%8F%E7%86%8A%E8%B1%AC%E7%9A%84%E7%A8%8B%E5%BC%8F%E4%B8%96%E7%95%8C/win10-rtx-2060-tensorflow-gpu-10b1c656ac0e" target="_blank" rel="noopener">【Medium】(2019年4月27日)Win10 + RTX 2060 + tensorflow GPU</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/importerror-tensorflow-chang-jian-mo-kuai-bao-cuo-chu-li.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/importerror-tensorflow-chang-jian-mo-kuai-bao-cuo-chu-li.html" class="post-title-link" itemprop="url">ImportError:TensorFlow常见模块报错处理</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-21 08:22:11 / 修改时间：08:27:16" itemprop="dateCreated datePublished" datetime="2019-05-21T08:22:11+08:00">2019-05-21</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/TensorFlow/" itemprop="url" rel="index"><span itemprop="name">TensorFlow</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">184</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">1 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="ImportError-No-module-named-cv2-报错处理"><a href="#ImportError-No-module-named-cv2-报错处理" class="headerlink" title="ImportError: No module named cv2 报错处理"></a>ImportError: No module named cv2 报错处理</h1><h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><ul>
<li>在安装opevncv时会出现 ImportError: No module named cv2 的错误，找不到cv2的包。</li>
<li>这时候安装扩展包即可：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install opencv-python</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="参考地址"><a href="#参考地址" class="headerlink" title="参考地址"></a>参考地址</h2><p><a href="https://blog.csdn.net/chao2016/article/details/78071392" target="_blank" rel="noopener">ImportError: No module named cv2 报错处理</a></p>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/win10-anaconda-xia-tensorflow-gpu-huan-jing-da-jian-xiang-xi-jiao-cheng-bao-han-cuda-cudnn-an-zhuang-guo-cheng.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/win10-anaconda-xia-tensorflow-gpu-huan-jing-da-jian-xiang-xi-jiao-cheng-bao-han-cuda-cudnn-an-zhuang-guo-cheng.html" class="post-title-link" itemprop="url">Win10 Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA+cuDNN安装过程）</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-20 17:57:22 / 修改时间：18:35:22" itemprop="dateCreated datePublished" datetime="2019-05-20T17:57:22+08:00">2019-05-20</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/TensorFlow/" itemprop="url" rel="index"><span itemprop="name">TensorFlow</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">3.7k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">3 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前沿"><a href="#前沿" class="headerlink" title="前沿"></a>前沿</h1><p>配置环境，研究了一整天，踩了很多坑，在网上找了很多资料，发现基本上都没非常明确的教程，所以今天想分享一下配置tensorflow GPU版本的经验，希望能让各位朋友少走些弯路。（PS：一切的前提，你需要有一张Nvidia显卡。我的显卡是 GT940MX）</p>
<p>Tensorflow有两个版本：GPU和CPU版本，CPU的很好安装；GPU 版本需要 CUDA 和 cuDNN 的支持，如果你是独显+集显，那么推荐你用GPU版本的，因为GPU对矩阵运算有很好的支持，会加速程序执行！并且CUDA是Nvidia下属的程序，所以你的GPU最好是Nvidia的，AMD的显卡没有CUDA加速！满足以上条件之后，你需要查看一下你的英伟达GPU是否支持CUDA，以下是Geforce支持的目录：<br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-1.png" alt><br>你也可以<a href="https://developer.nvidia.com/cuda-gpus" target="_blank" rel="noopener">点击查看你的GPU是否支持CUDA</a></p>
<p>满足以上条件之后，你就可以安装Tensorflow了！</p>
<h1 id="第一步：安装Anaconda"><a href="#第一步：安装Anaconda" class="headerlink" title="第一步：安装Anaconda"></a>第一步：安装Anaconda</h1><p>1.下载和安装<br>下载地址：<a href="https://www.anaconda.com/download/" target="_blank" rel="noopener">https://www.anaconda.com/download/</a><br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-2.png" alt><br>我系统是64位，所以下载<a href="https://repo.anaconda.com/archive/Anaconda3-5.2.0-Windows-x86_64.exe" target="_blank" rel="noopener"> 64-Bit Graphical Installer (631 MB)</a>，之后就是进行安装了。<br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-3.png" alt><br>和安装其他软件没有什么区别，需要注意的是这一步，不要勾选<strong>“Add Anaconda to my PATH enviroment variable”</strong>，我们后面会手动加入。<br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-4.png" alt><br>接下来就是等待了，安装结束后需要测试是否能正常使用，打开CMD输入“conda”命令，发现提示“’conda’ is not recognized as an internal or external command, operable program or batch file.”<br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-5.png" alt><br>这是由于我们没有配置环境变量的原因。</p>
<p>2.配置Anaconda环境变量<br>我们点击左下角搜索栏搜索“环境变量”<br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-6.png" alt><br>点击环境变量<br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-7.png" alt><br>选择“Path”，点击“编辑”<br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-8.png" alt><br>将以下三个路径加入，注意这里要换成你自己的安装路径。</p>
<ul>
<li>C:\Users\t-yaoguo\AppData\Local\Continuum\anaconda3</li>
<li>C:\Users\t-yaoguo\AppData\Local\Continuum\anaconda3\Scripts</li>
<li>C:\Users\t-yaoguo\AppData\Local\Continuum\anaconda3\Library\bin<br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-9.png" alt><br>然后点击“确定”保存，这回再测试一下，再cmd中输入“conda -V”，能正常显示版本号，证明已经配置好了。<br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-10.png" alt></li>
</ul>
<h1 id="第二步：安装TensorFlow-GPU"><a href="#第二步：安装TensorFlow-GPU" class="headerlink" title="第二步：安装TensorFlow-GPU"></a>第二步：安装TensorFlow-GPU</h1><p>打开tensorflow官网：<a href="https://www.tensorflow.org/install/install_windows#installing_with_anaconda" target="_blank" rel="noopener">https://www.tensorflow.org/install/install_windows#installing_with_anaconda</a><br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-11.png" alt><br>跟着操作步骤走就可以了。</p>
<p>1.创建conda环境<br>通过调用下列命令，创建一个名为“tensorflow”的conda环境：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n tensorflow pip python=<span class="number">3.5</span></span><br></pre></td></tr></table></figure></p>
<p><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-12.png" alt><br>等待相应包的安装，如果国内网络太慢的话，可以为conda设置清华源，这样速度能快一点，具体配置过程，网上查一下吧，此处不再讲述。如果看到这样的提示，就证明conda环境创建成功。<br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-13.png" alt></p>
<p>2.激活环境<br>通过以下命令激活conda环境：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">activate tensorflow</span><br></pre></td></tr></table></figure></p>
<p><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-14.png" alt><br>这样就进入了刚创建的“tensorflow”环境。</p>
<p>3.安装tensorflow-gpu<br>安装GPU版本的tensorflow需要输入以下命令：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --ignore-installed --upgrade tensorflow-gpu</span><br></pre></td></tr></table></figure></p>
<p>如果只需要安装CPU版本的tensorflow则输入以下命令：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --ignore-installed --upgrade tensorflow</span><br></pre></td></tr></table></figure></p>
<p><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-15.png" alt><br>这样就安装成功了。</p>
<p>注意：务必注意一点，在安装完tensroflow后，由于我们是新创建的conda环境，该环境中基本上是空的，有很多包和IDE并没有安装进来，例如“Ipython”，“spyder”此时如果我们在该环境下打开spyder/Ipyton/jupyter notebook等，会发现其实IDE使用的kernel并不是新建立的这个环境的kernel，而是“base”这个环境的，而“base”环境中我们并没有安装tensorflow，所以一定无法import。这也就是为什么有很多人在安装好tensorflow后仍然在IDE里无法正常使用的原因了。</p>
<p>通过以下命令安装Anaconda基础包<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install anaconda</span><br></pre></td></tr></table></figure></p>
<p>这回，我们测试一下是否能import tensorflow<br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-16.png" alt><br>程序报错，这是由于我们虽然安装好了tensorflow-gpu，但是还需要安装CUDA Toolkit 和 cuDNN。</p>
<h1 id="第三步：安装CUDA-Toolkit-cuDNN"><a href="#第三步：安装CUDA-Toolkit-cuDNN" class="headerlink" title="第三步：安装CUDA Toolkit + cuDNN"></a>第三步：安装CUDA Toolkit + cuDNN</h1><p>1.查看需要安装的CUDA+cuDNN版本<br>注意，tensorflow是在持续更新的，具体安装的CUDA和cuDNN版本需要去官网查看，要与最新版本的tensorflow匹配。</p>
<p>点击查看最新tensorflow支持的CUDA版本：<br><a href="https://www.tensorflow.org/install/install_windows#requirements_to_run_tensorflow_with_gpu_support" target="_blank" rel="noopener">https://www.tensorflow.org/install/install_windows#requirements_to_run_tensorflow_with_gpu_support</a><br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-17.png" alt><br>现在（PS：此博客书写日期 2018年7月5日）最新版tensorflow支持的是 CUDA® Toolkit 9.0 + cuDNN v7.0，一定注意，安装的版本一定一定要正确，不要看NVIDIA官网推出CUDA® Toolkit 9.2了就感觉最新版的更好，而安装最新版，这样很可能会导致tensorflow无法正常使用，所以一定要跟着tensorflow 官网的提示来。</p>
<p>2.下载CUDA + cuDNN<br>在这个网址查找CUDA已发布版本：<a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-toolkit-archive</a><br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-18.png" alt><br>进入下载界面<br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-19.png" alt><br>下载好CUDA Toolkit 9.0 后，我们开始下载cuDnn 7.0，需要注意的是，下载cuDNN需要在nvidia上注册账号，使用邮箱注册就可以，免费的。登陆账号后才能下载。</p>
<p>cuDNN历史版本在该网址下载：<a href="https://developer.nvidia.com/rdp/cudnn-archive" target="_blank" rel="noopener">https://developer.nvidia.com/rdp/cudnn-archive</a><br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-20.png" alt><br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-21.png" alt><br>这样，我们就下载好了 CUDA Toolkit 9.0 和 cuDnn 7.0，下面我们开始安装。<br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-22.png" alt></p>
<p>3.安装 CUDA Toolkit 9.0 和 cuDnn 7.0<br>至关重要的一步：卸载显卡驱动<br>由于CUDA Toolkit需要在指定版本显卡驱动环境下才能正常使用的，所以如果我们已经安装了nvidia显卡驱动（很显然，大部分人都安装了），再安装CUDA Toolkit时，会因二者版本不兼容而导致CUDA无法正常使用，这也就是很多人安装失败的原因。而CUDA Toolkit安装包中自带与之匹配的显卡驱动，所以务必要删除电脑先前的显卡驱动。<br>安装<br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-23.png" alt><br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-24.png" alt><br>此处选择“自定义（高级）”<br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-25.png" alt><br>勾选所有<br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-26.png" alt><br>一路通过即可。</p>
<p>接下来，解压“cudnn-9.0-windows10-x64-v7.zip”，将一下三个文件夹，拷贝到CUDA安装的根目录下。<br><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-27.png" alt><br>这样CUDA Toolkit 9.0 和 cuDnn 7.0就已经安装了，下面要进行环境变量的配置。</p>
<p>配置环境变量<br>将下面四个路径加入到环境变量中，注意要换成自己的安装路径。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0</span><br><span class="line"></span><br><span class="line">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\bin</span><br><span class="line"></span><br><span class="line">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\lib\x64</span><br><span class="line"></span><br><span class="line">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\libnvvp</span><br></pre></td></tr></table></figure></p>
<p>到此，全部的安装步骤都已经完成，这回我们测试一下。</p>
<h1 id="第四步：测试"><a href="#第四步：测试" class="headerlink" title="第四步：测试"></a>第四步：测试</h1><p>1.查看是否使用GPU<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.test.gpu_device_name()</span><br></pre></td></tr></table></figure></p>
<p><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-28.png" alt></p>
<p>2.查看在使用哪个GPU<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.python.client <span class="keyword">import</span> device_lib</span><br><span class="line">device_lib.list_local_devices()</span><br></pre></td></tr></table></figure></p>
<p><img src="/images/Win10-Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA-cuDNN安装过程）/png1-29.png" alt><br>好了大功告成！</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://www.cnblogs.com/guoyaohua/p/9265268.html" target="_blank" rel="noopener">Win10 Anaconda下TensorFlow-GPU环境搭建详细教程（包含CUDA+cuDNN安装过程）</a></p>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/quan-ping-tai-zhong-wen-sublime-text-3207-ji-huo.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/quan-ping-tai-zhong-wen-sublime-text-3207-ji-huo.html" class="post-title-link" itemprop="url">（全平台）中文-Sublime Text 3207激活</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-20 15:30:02 / 修改时间：15:48:53" itemprop="dateCreated datePublished" datetime="2019-05-20T15:30:02+08:00">2019-05-20</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">3.3k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">3 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>有朋友反馈说安装不了Package Control<br>研究了一下，之前Host的列表把ST3的全都屏蔽了<br>仔细想了想有点智障，只用屏蔽license server就行<br>已更新，新的host就没问题了。<br>感谢@eui620的提醒</p>
<hr>
<p>我没在win下开发的习惯…<br>抱歉没发现WinHex不能保存超过200K的文件<br>用这个在线编辑器吧，啥平台都行。<br><a href="https://hexed.it" target="_blank" rel="noopener">https://hexed.it</a></p>
<hr>
<h1 id="1-下载软件"><a href="#1-下载软件" class="headerlink" title="1. 下载软件"></a>1. 下载软件</h1><p>官网: <a href="http://www.sublimetext.com/3/" target="_blank" rel="noopener">点我下载</a><br>网盘地址见底部</p>
<h1 id="2-安装软件"><a href="#2-安装软件" class="headerlink" title="2. 安装软件"></a>2. 安装软件</h1><p>这个我就不多BB了。<br>安装完请勿打开SublimeText3。<br>（若已打开关了就是）</p>
<h1 id="破解”-gt-3-破解"><a href="#破解”-gt-3-破解" class="headerlink" title="破解”&gt;3. 破解"></a>破解”&gt;3. 破解</h1><p>3207版本基本杜绝了共享license key的方法<br>所以我们要修改验证license时的trigger<br>因官方采用revoke illegal licenses的方式，即使当时显示激活成功，联网验证时便会凉凉。</p>
<p>所以我们还要采用hosts屏蔽法复制以下地址直接粘贴到相应系统的hosts文件内<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> license.sublimehq.com</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> www.sublimetext.com</span><br><span class="line"><span class="number">50.116</span><span class="number">.34</span><span class="number">.243</span> sublime.wbond.net</span><br><span class="line"><span class="number">50.116</span><span class="number">.34</span><span class="number">.243</span> packagecontrol.io</span><br></pre></td></tr></table></figure></p>
<h2 id="3-1-修改trigger"><a href="#3-1-修改trigger" class="headerlink" title="3.1 修改trigger"></a>3.1 修改trigger</h2><h3 id="3-1-1-Win"><a href="#3-1-1-Win" class="headerlink" title="3.1.1 Win"></a>3.1.1 Win</h3><ul>
<li>利用WinHex(网盘会有)或其他HexEditor打开软件根目录下的sublime_text.exe</li>
<li>搜索16进制 97 94 0D 00</li>
<li>改为  00 00 00 00</li>
<li>保存</li>
</ul>
<h3 id="3-1-2-Mac"><a href="#3-1-2-Mac" class="headerlink" title="3.1.2 Mac"></a>3.1.2 Mac</h3><ul>
<li><p>拷出/Applications/Sublime Text.app/Contents/MacOS/Sublime Text</p>
</li>
<li><p>其实就是 应用程序 文件夹下找到SublimeText应用，然后右键-&gt;显示包内容，然后打开/Contents/MacOS/ 然后找到 Sublime Text 这个文件 拷出来</p>
</li>
<li><p>利用0xED(网盘会有)或者其他HexEditor打开它</p>
</li>
<li>搜索16进制 97 94 0D 00</li>
<li>改为  00 00 00 00</li>
<li>如果实在不会修改网盘里有修改好的现成的</li>
<li>保存</li>
<li>打开终端，切换到当前目录</li>
<li>然后键入chmod 755 Sublime Text</li>
<li>替换掉/Applications/Sublime Text.app/Contents/MacOS/Sublime Text</li>
<li>完事儿</li>
</ul>
<h3 id="3-1-3-Linux"><a href="#3-1-3-Linux" class="headerlink" title="3.1.3 Linux"></a>3.1.3 Linux</h3><p>基本同Mac操作</p>
<ul>
<li>找个16进制编辑器打开软件根目录下的Sublime Text</li>
<li>搜索16进制 97 94 0D 00</li>
<li>改为  00 00 00 00</li>
<li>保存</li>
<li>打开终端，切换到当前目录</li>
<li>然后键入chmod 755 Sublime Text</li>
<li>完事儿</li>
</ul>
<h2 id="3-2-修改host"><a href="#3-2-修改host" class="headerlink" title="3.2 修改host"></a>3.2 修改host</h2><h3 id="3-2-1-Win"><a href="#3-2-1-Win" class="headerlink" title="3.2.1 Win"></a>3.2.1 Win</h3><p>Windows的hosts文件在：<br>系统盘:/windows/system32/drivers/etc/hosts<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Tips: Win下的权限获取可能有点复杂，不如先拷到桌面，编辑完替换回去。</span><br><span class="line">在最后一行插入</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> license.sublimehq.com</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> www.sublimetext.com</span><br><span class="line"><span class="number">50.116</span><span class="number">.34</span><span class="number">.243</span> sublime.wbond.net</span><br><span class="line"><span class="number">50.116</span><span class="number">.34</span><span class="number">.243</span> packagecontrol.io</span><br></pre></td></tr></table></figure>
<h3 id="3-2-2-Mac"><a href="#3-2-2-Mac" class="headerlink" title="3.2.2 Mac"></a>3.2.2 Mac</h3><ol>
<li>打开Terminal(终端)</li>
<li>输入 sudo nano /Private/etc/hosts 回车</li>
<li>输入密码后回车</li>
<li><p>在最后一行插入</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> license.sublimehq.com</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> www.sublimetext.com</span><br><span class="line"><span class="number">50.116</span><span class="number">.34</span><span class="number">.243</span> sublime.wbond.net</span><br><span class="line"><span class="number">50.116</span><span class="number">.34</span><span class="number">.243</span> packagecontrol.io</span><br></pre></td></tr></table></figure>
</li>
<li><p>按下Control + X，输入Y确定修改，确认保存路径后敲击回车</p>
</li>
</ol>
<h3 id="3-2-3-Linux"><a href="#3-2-3-Linux" class="headerlink" title="3.2.3 Linux"></a>3.2.3 Linux</h3><p>同Mac</p>
<h1 id="4-激活"><a href="#4-激活" class="headerlink" title="4. 激活"></a>4. 激活</h1><p>打开Sublime Text 3<br>选择Help -&gt; Enter License<br>输入<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">----- BEGIN LICENSE -----</span><br><span class="line">TwitterInc</span><br><span class="line"><span class="number">200</span> User License</span><br><span class="line">EA7E<span class="number">-890007</span></span><br><span class="line"><span class="number">1</span>D77F72E <span class="number">390</span>CDD93 <span class="number">4</span>DCBA022 FAF60790</span><br><span class="line"><span class="number">61</span>AA12C0 A37081C5 D0316412 <span class="number">4584</span>D136</span><br><span class="line"><span class="number">94</span>D7F7D4 <span class="number">95</span>BC8C1C <span class="number">527</span>DA828 <span class="number">560</span>BB037</span><br><span class="line">D1EDDD8C AE7B379F <span class="number">50</span>C9D69D B35179EF</span><br><span class="line"><span class="number">2</span>FE898C4 <span class="number">8E4277</span>A8 <span class="number">555</span>CE714 E1FB0E43</span><br><span class="line">D5D52613 C3D12E98 BC49967F <span class="number">7652</span>EED2</span><br><span class="line"><span class="number">9</span>D2D2E61 <span class="number">67610860</span> <span class="number">6</span>D338B72 <span class="number">5</span>CF95C69</span><br><span class="line">E36B85CC <span class="number">84991</span>F19 <span class="number">7575</span>D828 <span class="number">470</span>A92AB</span><br><span class="line">------ END LICENSE ------</span><br></pre></td></tr></table></figure></p>
<p>选择Use license </p>
<h1 id="5-大功告成"><a href="#5-大功告成" class="headerlink" title="5.大功告成"></a>5.大功告成</h1><p><img src="/images/（全平台）中文-Sublime-Text-3207激活/png1-1.png" alt></p>
<h1 id="6-中文化"><a href="#6-中文化" class="headerlink" title="6.中文化"></a>6.中文化</h1><p>不知道该不该写，好多人觉得哇人家破解版带个汉化猴赛雷<br>其实在Package Control就有 Rexdf 翻译的插件</p>
<ul>
<li>按下command + shift + p(win或linux为 ctrl + shift + p) 输入 install 选择 Install Package Control<br><img src="/images/（全平台）中文-Sublime-Text-3207激活/png1-2.png" alt></li>
<li>等待提示安装完成</li>
<li>完成后按下command + shift + p(win或linux为 ctrl + shift + p) 输入 install 选择 Package Control: Install Package<br><img src="/images/（全平台）中文-Sublime-Text-3207激活/png1-3.png" alt></li>
<li>输入 localization 选择 ChineseLocalizitions<br><img src="/images/（全平台）中文-Sublime-Text-3207激活/png1-4.png" alt></li>
<li>等待提示安装完成</li>
<li>大功告成，如需切换语言选择help -&gt; Languages<br><img src="/images/（全平台）中文-Sublime-Text-3207激活/png1-5.png" alt></li>
</ul>
<h1 id="7-附件"><a href="#7-附件" class="headerlink" title="7.附件"></a>7.附件</h1><p>附件什么附件？？<br>我这破等级还想发附件？？？<br>卑微，蚂蚁花卑，葡萄美酒夜光卑…..<br><a href="https://pan.baidu.com/s/14FCBvNuadVjsbkUSZD2JbQ" target="_blank" rel="noopener">百度网盘</a>  密码:lksz</p>
<h1 id="问答"><a href="#问答" class="headerlink" title="问答"></a>问答</h1><h2 id="（发表于-2019-4-16-08-08，by-hjner）"><a href="#（发表于-2019-4-16-08-08，by-hjner）" class="headerlink" title="（发表于 2019-4-16 08:08，by hjner）"></a>（发表于 2019-4-16 08:08，by hjner）</h2><p>我测试，说注册码不对…..XP 下测试的。</p>
<hr>
<p>第二次重装，同样出现  ：<br>plugin_host has exited unexpectedly,plugin functionality won’t be available until Sublime Text has been restarted</p>
<p>不关闭程序，先设置好HOST文件，屏蔽服务器，然后，直接 输入注册码，反而通过！<br>之前重启程序在输入注册码，则无效。</p>
<p>谢谢，成功！</p>
<hr>
<p>安装中文时候，出现<br>installing package control,出现提示，访问<br><a href="https://packagecontrol.io/installation" target="_blank" rel="noopener">https://packagecontrol.io/installation</a></p>
<p>手动安装，</p>
<p>但是网站进不去…只有以后再试试了。</p>
<h2 id="发表于-2019-5-7-16-36-by-花了19元"><a href="#发表于-2019-5-7-16-36-by-花了19元" class="headerlink" title="(发表于 2019-5-7 16:36 by 花了19元)"></a>(发表于 2019-5-7 16:36 by 花了19元)</h2><p>127.0.0.1 license.sublimehq.com<br>127.0.0.1 www.sublimetext.com<br>50.116.34.243 sublime.wbond.net<br>50.116.34.243 packagecontrol.io</p>
<p>激活成功，但是这样修改hosts，插件安装不了。</p>
<p>解决办法(<a href="https://www.jianshu.com/p/23b823d6e786)：" target="_blank" rel="noopener">https://www.jianshu.com/p/23b823d6e786)：</a><br>点击 Preferences &gt; Package Settings &gt; Package Control &gt; Settings - User<br>添加配置<br>“channels”: [“<a href="https://raw.githubusercontent.com/HBLong/channel_v3_daily/master/channe" target="_blank" rel="noopener">https://raw.githubusercontent.com/HBLong/channel_v3_daily/master/channe</a></p>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/win10-ru-he-zi-ding-yi-you-jian-cai-dan-xiu-gai-zhu-ce-biao-tu-wen.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/win10-ru-he-zi-ding-yi-you-jian-cai-dan-xiu-gai-zhu-ce-biao-tu-wen.html" class="post-title-link" itemprop="url">Win10如何自定义右键菜单-修改注册表（图文）</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-20 14:36:40 / 修改时间：15:19:07" itemprop="dateCreated datePublished" datetime="2019-05-20T14:36:40+08:00">2019-05-20</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">5.1k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">5 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="理论介绍"><a href="#理论介绍" class="headerlink" title="理论介绍"></a>理论介绍</h1><p>&emsp;&emsp;我研究这个是因为发现右键菜单在安装了一下软件后，越来越臃肿，有用的没用的菜单项都被塞进去了，于是自己动手给菜单瘦个身。</p>
<p>&emsp;&emsp;这里首先警告一句：<strong>下面操作全部涉及到修改注册表，看见不认识，不确定的注册表项，别手欠看见空项或者自以为无用的注册表项，就瞎乱删。最好是有一定操作注册表的基础在跟着本文操作，至少要知道怎么备份和恢复注册表。手欠的孩子都请自己准备好恢复或重装系统，本文的经过作者本人亲自实践无误，但不保证文中描述完全正确或适用于所有版本的win10操作系统。如果在按照本文说明操作时，发生了系统崩溃，死机，或其他任何可修复/不可修复的系统问题，你可以顺着网线来打我啊，然而我也救不了你。</strong></p>
<p>&emsp;&emsp;首先，所有的右键菜单项，几乎都可以在注册表中设置。按<font color="red"> Win + R </font>打开“ <code>运行…</code>”窗口，输入<font color="red"> regedit </font>，按回车键打开。注意：注册表编辑器是需要管理员权限的。<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/jpg1-1.jpg" alt></p>
<p>打开注册表，根项展开有5个子项，如上图所示。右键菜单的项目都包含在第一子项<font color="red"> HKEY_CALSS_ROOT </font>中。展开该项，第一个子项一般是<font color="red"> * </font>，这个统配符表示一切后缀的文件都通用。也就是说，这个子项中的一切右键菜单项，没有特别说明，会出现每一个文件的右键菜单中。</p>
<p>展开这一子项，在其内部，所有的右键菜单分为两部分存储（我也懒得去搞清楚这两块区域有什么不同），见下图：<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/jpg1-2.jpg" alt></p>
<p>用红线圈起来的两个注册表键，就是放置了右键菜单的地方，看看有哪些是自己安装的软件带来的，看名字挑着没用的就能删除了。<strong>这里特别提醒一句，看见键名称是一串序列号的，请仔细核对后，确认不是系统项再删除。用这种长串数字当名字的键，如果里面空空如也，那很有可能是系统项。</strong></p>
<p>然后是文件夹，文件夹分为两类菜单，一类是鼠标指向一个文件夹图标时，点击右键出来的菜单；第二类菜单时鼠标在已经打开的文件夹窗口的空白处，点击右键弹出的菜单。如下图所示，第一类菜单的注册表项直接在 Directory 下，shell和shellex\ContextMenuHandlers 里面；第二类菜单则在子项 Background 里面。<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/jpg1-3.jpg" alt></p>
<p>哦，对了，还有比较特殊的桌面菜单。在桌面空白处点击右键，弹出的菜单在 DesktopBackground 项里面：<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/jpg1-4.jpg" alt></p>
<p>是的，细心的人应该已经发现了，这里的菜单项不全。是的，不全，然而我也不知道其他的在哪里，懒得找……</p>
<p>然后还有一些，比如：<br>驱动器（就是C盘、光驱，之类那些，带着卷标的），在 Drive 项里面；<br>文件夹还有一些在 Folder 项里面；<br>字体文件的在 fontfile 项里面；<br>等等…… 英文好的同学可以自行发挥了。 </p>
<p>上面讲的是如何找到一些项，然后就能删除里面多余的菜单项。下面将一些添加项的方法：</p>
<p>以python文件为例（<code>*.py</code>），python如见有两个大分支：2.x系列和3.x系列。那么有时候我们的机器上会同时安装这两个python的运行环境，这时候想要快速的用python解释器打开某个<code>*.py</code>文件，要么就是命令行，要么就是频繁更改打开方式，要么就是来回挪动环境变量的前后顺序……好吧，我不废话了，下面开始动手添加右键菜单。</p>
<p>首先，还是找到包含python脚本文件的右键菜单项的注册表键，完整的路径是 Computer\HKEY_CLASSES_ROOT\pysFile ，如下图。这里可以看到，有3个子项。一眼可以看到右键菜单的藏身之处：<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/jpg1-5.jpg" alt></p>
<p>一般安装python时，附带的菜单项倒在 Shell 子键里面，展开，把一串什么 runwithidle 之类的统统干掉，然后我们来加入自己的项。<br>右键点击 Shell ，然后选择 新建 ，然后选择 键：<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/jpg1-6.jpg" alt></p>
<p>简单点的话，不做附加设置，这个键的名字就会是右键菜单项的显示名字，如下图所示：<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/jpg1-7.jpg" alt><br>之后，如果更改这个键的默认值，就会更改菜单的显示名字：<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/jpg1-8.jpg" alt><br>只有一个键，是不能让这个菜单项真正生效的，这时如果点击这个菜单项，就会收到系统发出的错误警告。下面来添加点击这个菜单项所触发的命令：<br>在新建的键里面（图里面的 MieHaHa键），再新建一个键，命名为 command，一般大小写都行，但是我还是建议全小写吧。然后更改这个键的默认值，双击(Default)（中文操作系统这里应该是默认），会弹出修改框，把值修改为你的python.exe所在完整路径+参数就可以了，比如我的python36安装在<code>D:\Environment\Python36\python.exe, 那么我这里就要输入 &quot;D:\Environment\Python36\python.exe&quot; &quot;%1&quot; %*</code>。这里简单解释一下，这里的值，就相当与是命令行里敲的命令。因为是点击文件弹出的菜单， %1 就是被点击的py文件的完整路径。</p>
<p>有了这个菜单项，就能使用这一项直接用python运行脚本文件了。然而，这也太简陋了，看好多程序都用dll文件，把自己的菜单项折叠成了一个子菜单组，简洁又方便。在WIN10里，其实不用dll，只用注册表，也能自己制作一个折叠的子菜单组，比如上图（图8）的 Run With 项就是我自己写的一个菜单组。下图直接上键的树：<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/jpg1-9.jpg" alt></p>
<p>除了最内层两个 command 和 最外层的 runwith 其余的键都没有值。 runwith 里需要新建两个 字符串的值：一个命名为 MUIVerb，值为 &amp;Run With，也就是这个菜单组的名称，注意要以 &amp; 开头，这个字符不会被显示；第二个值，命名为Subcommands，没有值。如下图：<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/jpg1-10.jpg" alt></p>
<h1 id="将-Sublime-Text-添加到系统右键菜单栏的方法"><a href="#将-Sublime-Text-添加到系统右键菜单栏的方法" class="headerlink" title="将 Sublime Text 添加到系统右键菜单栏的方法"></a>将 Sublime Text 添加到系统右键菜单栏的方法</h1><p>Sublime Text 是一个代码编辑器（Sublime Text 2是收费软件，但可以无限期试用），也是HTML和散文先进的文本编辑器。Sublime Text是由程序员Jon Skinner于2008年1月份所开发出来，它最初被设计为一个具有丰富扩展功能的Vim。<br>Sublime Text具有漂亮的用户界面和强大的功能，例如代码缩略图，Python的插件，代码段等。还可自定义键绑定，菜单和工具栏。Sublime Text 的主要功能包括：拼写检查，书签，完整的 Python API ， Goto 功能，即时项目切换，多选择，多窗口等等。Sublime Text 是一个跨平台的编辑器，同时支持Windows、Linux、Mac OS X等操作系统。（摘自百度百科）</p>
<p>咳咳，废话少说，切入正题：<br>这么好的编译器在打开需要编译的文件时却存在一个非常让人头疼的问题：不能右键菜单选择使用 Sublime text 打开！！！</p>
<p>下面为大家介绍一种通过修改系统注册表的方法将 Sublime text 添加到右键菜单中： </p>
<ol>
<li><p>首先使用 Win + R 打开运行，输入 regedit 按下回车键进入注册表；<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png1-1.png" alt><br>运行后进入注册表界面：<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png1-2.png" alt></p>
</li>
<li><p>依次展开 HKEY_CLASSES_ROOT -&gt; * -&gt; shell，右键 shell 新建一个项并命名为：Open With Sublime Text 如图：<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png1-3.png" alt></p>
</li>
<li><p>双击选中新建项 Open With Sublime Text ，在右边展示栏空白处右键新建字符串值，数值名称填 lcon ，数值数据填 E:\Sublime Text3\sublime_text.exe,0 （注意：路径请改成你安装Sublime Text 的路径喔）<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png1-4.png" alt><br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png1-5.png" alt></p>
</li>
<li><p>右键新建的 Open With Sublime Text 新建一个项，命名为 Command （注意：请必须命名为 Command 喔），并双击选中 Command ，在右边的展示栏中将默认项的数值数据修改为：E:\Sublime Text 3\sublime_text.exe “%1” （注意：1、将我的路径改成你安装 Sublime Text 的路径，2、”必须要写喔）<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png1-6.png" alt><br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png1-7.png" alt><br>进行到这里，右键菜单的 Open With Sublime Text 选项就实现啦！！！</p>
</li>
</ol>
<h1 id="sublime-text-添加到鼠标右键功能"><a href="#sublime-text-添加到鼠标右键功能" class="headerlink" title="sublime text 添加到鼠标右键功能"></a>sublime text 添加到鼠标右键功能</h1><p>Sublime Text是一款具有代码高亮、语法提示、自动完成且反应快速的编辑器软件，不仅具有华丽的界面，还支持插件扩展机制，用她来写代码，绝对是一种享受。如何把sublime text添加到鼠标右键，以方便我们使用呢？</p>
<h2 id="方法与步骤"><a href="#方法与步骤" class="headerlink" title="方法与步骤"></a>方法与步骤</h2><p>1.在Windows系统中，下载并安装sublime text3 软件，（可以到sublime text3 的官方网站下载），如下图，可以按不同的系统选择下载安装包。<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png2-1.png" alt></p>
<p>2.下载完成后，双击安装包文件进行安装，安装比较简单，按照提示点击“下一步”，最后完成安装，如下图所示。<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png2-2.png" alt></p>
<p>3.sublime text 添加到鼠标右键功能：把以下内容复制并保存到文件，重命名为：sublime_addright.reg，然后双击就可以了。<br>（注意：需要把下面代码中的Sublime的安装目录（标粗部分），替换成自已实际的Sublime安装目录）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Windows Registry Editor Version <span class="number">5.00</span></span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\*\shell\SublimeText3]</span><br><span class="line"></span><br><span class="line"><span class="meta">@="用 SublimeText3 打开"</span></span><br><span class="line"></span><br><span class="line"><span class="string">"Icon"</span>=<span class="string">"C:\\Program Files\\Sublime Text 3\\sublime_text.exe,0"</span></span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\*\shell\SublimeText3\command]</span><br><span class="line"></span><br><span class="line"><span class="meta">@="C:\\Program Files\\Sublime Text 3\\sublime_text.exe %1"</span></span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\Directory\shell\SublimeText3]</span><br><span class="line"></span><br><span class="line"><span class="meta">@="用 SublimeText3 打开"</span></span><br><span class="line"></span><br><span class="line"><span class="string">"Icon"</span>=<span class="string">"C:\\Program Files\\Sublime Text 3\\sublime_text.exe,0"</span></span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\Directory\shell\SublimeText3\command]</span><br><span class="line"></span><br><span class="line"><span class="meta">@="C:\\Program Files\\Sublime Text 3\\sublime_text.exe %1"</span></span><br></pre></td></tr></table></figure></p>
<p>其中，@=”用 SublimeText3 打开” 引号中的内容为出现在鼠标右键菜单中的文字内容。<br>4.双击文件sublime_addright.reg 完成后，鼠标选中要编辑的文件，点击鼠标右键，弹出菜单，其中就会出现刚才添加的“用 SublimeText3 打开”选项，如下图所示。<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png2-3.png" alt></p>
<h1 id="将Sublime-Text-添加到鼠标右键的方法"><a href="#将Sublime-Text-添加到鼠标右键的方法" class="headerlink" title="将Sublime Text 添加到鼠标右键的方法"></a>将Sublime Text 添加到鼠标右键的方法</h1><p><strong>步骤:</strong></p>
<ol>
<li>win+R 打开运行，并输入regedit。</li>
<li>在左侧依次打开HKEY_CLASSES_ROOT*\shell</li>
<li><p>在shell下新建“Sublime Text”项，在右侧窗口的“默认”键值栏内输入“用Sublime Text打开”。项的名称和键值可以任意，最好是和程序关联起来。其中键值将显示在右键菜单中。</p>
</li>
<li><p>在“用Sublime Text打开”下再新建Command项，在右侧窗口的“默认”键值栏内输入Sublime Text程序所在的路径,在路径后添加 %1。%1表示要打开的文件参数。</p>
</li>
<li>关闭注册表窗口，立即生效。（如图）<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png3-1.png" alt></li>
</ol>
<p><strong>注意事项：</strong></p>
<pre><code>    1. 第四步时的Command无法自定义。必须输入Command才可以。
    2. 输入程序路径时注意为以下格式：例. d:\sub\sub.exe %1
</code></pre><p>&emsp;&emsp;万事不要太依赖别人，自己动手才能丰衣足食。这个鼠标右键也可以使用第三方程序来调用添加，而且这个改注册表不止方便，还可以举一反三，做的更多。<br>&emsp;&emsp;附上下载链接这个中文不会乱码: 链接：<a href="https://pan.baidu.com/s/1jH9KD8a" target="_blank" rel="noopener">https://pan.baidu.com/s/1jH9KD8a</a> 密码：p6du</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://blog.csdn.net/CrowNAir/article/details/78128566" target="_blank" rel="noopener">Win10如何自定义右键菜单-修改注册表（图文</a></li>
<li><a href="https://blog.csdn.net/MariaGit/article/details/79016807" target="_blank" rel="noopener">将 Sublime Text 添加到系统右键菜单栏的方法</a></li>
<li><a href="https://jingyan.baidu.com/article/cdddd41c99d07653ca00e147.html" target="_blank" rel="noopener">sublime text 添加到鼠标右键功能</a></li>
<li><a href="https://blog.csdn.net/a_piaoyouareminemine/article/details/49969299" target="_blank" rel="noopener">将Sublime Text 添加到鼠标右键的方法</a></li>
<li><a href="https://blog.csdn.net/linysuccess/article/details/79179799" target="_blank" rel="noopener">win10右键菜单修改，任意位置打开cmd命令行程序</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/semi-supervised-learning-with-gans.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/semi-supervised-learning-with-gans.html" class="post-title-link" itemprop="url">Semi-supervised learning with GANs</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-09 11:47:15 / 修改时间：15:50:55" itemprop="dateCreated datePublished" datetime="2019-05-09T11:47:15+08:00">2019-05-09</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">23k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">21 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><br>&emsp;&emsp;In this post I will cover a partial re-implementation of a <a href="https://arxiv.org/abs/1805.08957" target="_blank" rel="noopener">recent paper</a> on manifold regularization (Lecouat et al., 2018) for semi-supervised learning with <a href="http://papers.nips.cc/paper/5423-generative-adversarial-nets" target="_blank" rel="noopener">Generative Adversarial Networks</a> (Goodfellow et al., 2014). I will attempt to re-implement their main contribution, rather than getting all the hyperparameter details just right. Also, for the sake of demonstration, time constraints and simplicity, I will consider the MNIST dataset rather than the CIFAR10 or SVHN datasets as done in <a href="https://arxiv.org/abs/1805.08957" target="_blank" rel="noopener">the paper</a>. Ultimately, this post aims at bridging the gap between the theory and implementation for GANs in the semi-supervised learning setting. The code that comes with this post can be found <a href="https://github.com/jostosh/gan/blob/master/dcganmnist/mnist_ssl.py" target="_blank" rel="noopener">here</a>.</p>
<h1 id="Generative-Adversarial-Networks"><a href="#Generative-Adversarial-Networks" class="headerlink" title="Generative Adversarial Networks"></a>Generative Adversarial Networks</h1><p>&emsp;&emsp;Let’s quickly go over Generative Adversarial Networks (GAN). In terms of the current pace within the AI/ML community, they have been around for a while (just about 4 years), so you might already be familiar with them. The ‘vanilla’ GAN procedure is to train a generator to generate images that are realistic and capable of fooling a discriminator. The generator generates the images by means of a deep neural network that takes in a noise vector z.<br>&emsp;&emsp;The discriminator (which is a deep neural network as well) is fed with the generated images, but also with some real data. Its job is to say whether each image is either real (coming from the dataset) or fake (coming from the generator), which in terms of implementation comes down to binary classification. The image below summarizes the vanilla GAN setup.<br><img src="/images/Semi-supervised-learning-with-GANs/png1-1.png" alt="Vanilla GAN setup"></p>
<h1 id="Semi-supervised-learning"><a href="#Semi-supervised-learning" class="headerlink" title="Semi-supervised learning"></a>Semi-supervised learning</h1><p>&emsp;&emsp;Semi-supervised learning problems concern a mix of labeled and unlabeled data. Leveraging the information in both the labeled and unlabeled data to eventually improve the performance on unseen labeled data is an interesting and more challenging problem than merely doing supervised learning on a large labeled dataset. In this case we might be limited to having only about 200 samples per class. So what should we do when only a small portion of the data is labeled?<br>&emsp;&emsp;Note that adversarial training of vanilla GANs doesn’t require labeled data. At the same time, the deep neural network of the discriminator is able to learn powerful and robust abstractions of images by gradually becoming better at discriminating fake from real. Whatever it’s learning about unlabeled images will presumably also yield useful feature descriptors of labeled images. So how do we use the discriminator for both labeled and unlabeled data? Well, the discriminator is not necessarily limited to just telling fake from real. We could decide to train it to also classify the real data.<br>&emsp;&emsp;A GAN with a classifying discriminator would be able to exploit both the unlabeled as well as the labeled data. The unlabeled data will be used to merely tell fake from real. The labeled data would be used to optimize the classification performance. In practice, this just means that the discriminator has a softmax output distribution for which we minimize the cross-entropy. Indeed, part of the training procedure is just doing supervised learning. The other part is about adversarial training. The image below summarizes the semi-supervised learning setup with a GAN.<br><img src="/images/Semi-supervised-learning-with-GANs/png1-2.png" alt="Vanilla GAN setup"></p>
<h1 id="The-implementation"><a href="#The-implementation" class="headerlink" title="The implementation"></a>The implementation</h1><p>&emsp;&emsp;Let’s just head over to the implementation, since that might be the best way of understanding what’s happening. The snippet below prepares the data. It doesn’t really contain anything sophisticated. Basically, we take 400 samples per class and concatenate the resulting arrays as being our actual supervised subset. The unlabeled dataset consists of all train data (it also includes the labeled data, since we might as well use it anyway). As is customary for training GANs now, the output of the generator uses a hyperbolic tangent function, meaning its output is between -1 and +1. Therefore, we rescale the data to be in that range as well. Then, we create TensorFlow iterators so that we can efficiently go through the data later without having to struggle with feed dicts later on.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prepare_input_pipeline</span><span class="params">(flags_obj)</span>:</span></span><br><span class="line">    (train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data(</span><br><span class="line">        <span class="string">"/home/jos/datasets/mnist/mnist.npz"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reshape_and_scale</span><span class="params">(x, img_shape=<span class="params">(<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span>)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> x.reshape(img_shape).astype(np.float32) / <span class="number">255.</span> * <span class="number">2.0</span> - <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Reshape data and rescale to [-1, 1]</span></span><br><span class="line">    train_x = reshape_and_scale(train_x)</span><br><span class="line">    test_x = reshape_and_scale(test_x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Shuffle train data</span></span><br><span class="line">    train_x_unlabeled, train_y_unlabeled = shuffle(train_x, train_y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Select subset as supervised</span></span><br><span class="line">    train_x_labeled, train_y_labeled = [], []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(flags_obj.num_classes):</span><br><span class="line">        train_x_labeled.append(</span><br><span class="line">            train_x_unlabeled[train_y_unlabeled == i][:flags_obj.num_labeled_examples])</span><br><span class="line">        train_y_labeled.append(</span><br><span class="line">            train_y_unlabeled[train_y_unlabeled == i][:flags_obj.num_labeled_examples])</span><br><span class="line">    train_x_labeled = np.concatenate(train_x_labeled)</span><br><span class="line">    train_y_labeled = np.concatenate(train_y_labeled)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">"InputPipeline"</span>):</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">train_pipeline</span><span class="params">(data, shuffle_buffer_size)</span>:</span></span><br><span class="line">            <span class="keyword">return</span> tf.data.Dataset.from_tensor_slices(data)\</span><br><span class="line">                .cache()\</span><br><span class="line">                .shuffle(buffer_size=shuffle_buffer_size)\</span><br><span class="line">                .batch(flags_obj.batch_size)\</span><br><span class="line">                .repeat()\</span><br><span class="line">                .make_one_shot_iterator()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Setup pipeline for labeled data</span></span><br><span class="line">        train_ds_lab = train_pipeline(</span><br><span class="line">            (train_x_labeled, train_y_labeled.astype(np.int64)),</span><br><span class="line">            flags_obj.num_labeled_examples * flags_obj.num_classes)</span><br><span class="line">        images_lab, labels_lab = train_ds_lab.get_next()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Setup pipeline for unlabeled data</span></span><br><span class="line">        train_ds_unl = train_pipeline(</span><br><span class="line">            (train_x_unlabeled, train_y_unlabeled.astype(np.int64)), len(train_x_labeled))</span><br><span class="line">        images_unl, labels_unl = train_ds_unl.get_next()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Setup another pipeline that also uses the unlabeled data, so that we use a different</span></span><br><span class="line">        <span class="comment"># batch for computing the discriminator loss and the generator loss</span></span><br><span class="line">        train_x_unlabeled, train_y_unlabeled = shuffle(train_x_unlabeled, train_y_unlabeled)</span><br><span class="line">        train_ds_unl2 = train_pipeline(</span><br><span class="line">            (train_x_unlabeled, train_y_unlabeled.astype(np.int64)), len(train_x_labeled))</span><br><span class="line">        images_unl2, labels_unl2 = train_ds_unl2.get_next()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Setup pipeline for test data</span></span><br><span class="line">        test_ds = tf.data.Dataset.from_tensor_slices((test_x, test_y.astype(np.int64)))\</span><br><span class="line">            .cache()\</span><br><span class="line">            .batch(flags_obj.batch_size)\</span><br><span class="line">            .repeat()\</span><br><span class="line">            .make_one_shot_iterator()</span><br><span class="line">        images_test, labels_test = test_ds.get_next()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (images_lab, labels_lab), (images_unl, labels_unl), (images_unl2, labels_unl2), \</span><br><span class="line">           (images_test, labels_test)</span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;Next up is to define the discriminator network. I have deviated quite a bit from the architecture in the <a href="https://arxiv.org/abs/1805.08957" target="_blank" rel="noopener">paper</a>. I’m going to play safe here and just use Keras layers to construct the model. Actually, this enables us to very conveniently reuse all weights for different input tensors, which will prove to be useful later on. In short, the discriminator’s architecture uses 3 convolutions with 5x5 kernels and strides of 2x2, 2x2 and 1x1 respectively. Each convolution is followed by a leaky ReLU activation and a dropout layer with a dropout rate of 0.3. The flattened output of this stack of convolutions will be used as the feature layer.<br>&emsp;&emsp;The feature layer can be used for a <a href="https://arxiv.org/abs/1606.03498" target="_blank" rel="noopener">feature matching loss</a> (rather than a sigmoid cross-entropy loss as in vanilla GANs), which has proven to yield a more reliable training process. The part of the network up to this feature layer is defined in <code>_define_tail</code> in the snippet below. The <code>_define_head</code> method defines the rest of the network. The ‘head’ of the network introduces only one additional fully connected layer with 10 outputs, that correspond to the logits of the class labels. Other than that, there are some methods to make the interface of a <code>Discriminator</code> instance behave similar to that of a <code>tf.keras.models.Sequential</code> instance.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""The discriminator network. Split up in a 'tail' and 'head' network, so that we can</span></span><br><span class="line"><span class="string">        easily get the """</span></span><br><span class="line">        self.tail = self._define_tail()</span><br><span class="line">        self.head = self._define_head()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_define_tail</span><span class="params">(self, name=<span class="string">"Discriminator"</span>)</span>:</span></span><br><span class="line">        <span class="string">"""Defines the network until the intermediate layer that can be used for feature-matching</span></span><br><span class="line"><span class="string">        loss."""</span></span><br><span class="line">        feature_model = models.Sequential(name=name)</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">conv2d_dropout</span><span class="params">(filters, strides, index=<span class="number">0</span>)</span>:</span></span><br><span class="line">            <span class="comment"># Adds a convolution followed by a Dropout layer</span></span><br><span class="line">            suffix = str(index)</span><br><span class="line">            feature_model.add(layers.Conv2D(</span><br><span class="line">                filters=filters, strides=strides, name=<span class="string">"Conv&#123;&#125;"</span>.format(suffix), padding=<span class="string">'same'</span>,</span><br><span class="line">                kernel_size=<span class="number">5</span>, activation=tf.nn.leaky_relu))</span><br><span class="line">            feature_model.add(layers.Dropout(name=<span class="string">"Dropout&#123;&#125;"</span>.format(suffix), rate=<span class="number">0.3</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Three blocks of convs and dropouts. They all have 5x5 kernels, leaky ReLU and 0.3</span></span><br><span class="line">        <span class="comment"># dropout rate.</span></span><br><span class="line">        conv2d_dropout(filters=<span class="number">32</span>, strides=<span class="number">2</span>, index=<span class="number">0</span>)</span><br><span class="line">        conv2d_dropout(filters=<span class="number">64</span>, strides=<span class="number">2</span>, index=<span class="number">1</span>)</span><br><span class="line">        conv2d_dropout(filters=<span class="number">64</span>, strides=<span class="number">1</span>, index=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Flatten it and build logits layer</span></span><br><span class="line">        feature_model.add(layers.Flatten(name=<span class="string">"Flatten"</span>))</span><br><span class="line">        <span class="keyword">return</span> feature_model</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_define_head</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># Defines the remaining layers after the 'tail'</span></span><br><span class="line">        head_model = models.Sequential(name=<span class="string">"DiscriminatorHead"</span>)</span><br><span class="line">        head_model.add(layers.Dense(units=<span class="number">10</span>, activation=<span class="literal">None</span>, name=<span class="string">"Logits"</span>))</span><br><span class="line">        <span class="keyword">return</span> head_model</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">trainable_variables</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># Return both tail's parameters a well as those of the head</span></span><br><span class="line">        <span class="keyword">return</span> self.tail.trainable_variables + self.head.trainable_variables</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, x, *args, **kwargs)</span>:</span></span><br><span class="line">        <span class="comment"># By adding this, the code below can treat a Discriminator instance as a</span></span><br><span class="line">        <span class="comment"># tf.keras.models.Sequential instance</span></span><br><span class="line">        features = self.tail(x, *args, **kwargs)</span><br><span class="line">        <span class="keyword">return</span> self.head(features, *args, **kwargs), features</span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;The generator’s architecture also uses <code>5x5</code> kernels. Many implementations of DCGAN-like architectures use transposed convolutions (sometimes wrongfully referred to as ‘deconvolutions’). I have decided to give the upsampling-convolution alternative a try. This should alleviate the issue of the <u>checkerboard pattern</u> that sometimes appears in generated images. Other than that, there are ReLU nonlinearities, and a first layer to go from the 100-dimensional noise to a (rather awkwardly shaped) <code>7x7x64</code> spatial representation.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">define_generator</span><span class="params">()</span>:</span></span><br><span class="line">    model = models.Sequential(name=<span class="string">"Generator"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">conv2d_block</span><span class="params">(filters, upsample=True, activation=tf.nn.relu, index=<span class="number">0</span>)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> upsample:</span><br><span class="line">            model.add(layers.UpSampling2D(name=<span class="string">"UpSampling"</span> + str(index), size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">        model.add(layers.Conv2D(</span><br><span class="line">            filters=filters, kernel_size=<span class="number">5</span>, padding=<span class="string">'same'</span>, name=<span class="string">"Conv2D"</span> + str(index),</span><br><span class="line">            activation=activation))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># From flat noise to spatial</span></span><br><span class="line">    model.add(layers.Dense(<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>, activation=tf.nn.relu, name=<span class="string">"NoiseToSpatial"</span>))</span><br><span class="line">    model.add(layers.Reshape((<span class="number">7</span>, <span class="number">7</span>, <span class="number">64</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Four blocks of convolutions, 2 that upsample and convolve, and 2 more that</span></span><br><span class="line">    <span class="comment"># just convolve</span></span><br><span class="line">    conv2d_block(filters=<span class="number">128</span>, upsample=<span class="literal">True</span>, index=<span class="number">0</span>)</span><br><span class="line">    conv2d_block(filters=<span class="number">64</span>, upsample=<span class="literal">True</span>, index=<span class="number">1</span>)</span><br><span class="line">    conv2d_block(filters=<span class="number">64</span>, upsample=<span class="literal">False</span>, index=<span class="number">2</span>)</span><br><span class="line">    conv2d_block(filters=<span class="number">1</span>, upsample=<span class="literal">False</span>, activation=tf.nn.tanh, index=<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;I have tried to make this model work with what TensorFlow’s Keras layers have to offer so that the code would be easy to digest (and to implement of course). This also means that I have deviated from the architectures in <a href="https://arxiv.org/abs/1805.08957" target="_blank" rel="noopener">the paper</a> (e.g. I’m not using weight normalization). Because of this experimental approach, I have also experienced just how sensitive the training setup is to small variations in network architectures and parameters. There are plenty of neat GAN ‘hacks’ listed <a href="https://github.com/soumith/ganhacks" target="_blank" rel="noopener">here</a> which I definitely found insightful.     </p>
<h1 id="Putting-it-together"><a href="#Putting-it-together" class="headerlink" title="Putting it together"></a>Putting it together</h1><p>&emsp;&emsp;Let’s do the forward computations now so that we see how all of the above comes together. This consists of setting up the input pipeline, noise vector, generator and discriminator. The snippet below does all of this. Note that when <code>define_generator</code> returns the <code>Sequential</code> instance, we can just use it as a functor to obtain the output of it for the noise tensor given by z.<br>&emsp;&emsp;The discriminator will do a lot more. It will take (i) the ‘fake’ images coming from the generator, (ii) a batch of unlabeled images and finally (iii) a batch of labeled images (both with and without dropout to also report the train accuracy). We can just repetitively call the <code>Discriminator</code> instance to build the graph for each of those outputs. Keras will make sure that the variables are reused in all cases. To turn off dropout for the labeled training data, we have to pass <code>training=False</code> explicitly.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">(images_lab, labels_lab), (images_unl, labels_unl), (images_unl2, labels_unl2), \</span><br><span class="line">            (images_test, labels_test) = prepare_input_pipeline(flags_obj)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"BatchSize"</span>):</span><br><span class="line">    batch_size_tensor = tf.shape(images_lab)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the noise vectors</span></span><br><span class="line">z, z_perturbed = define_noise(batch_size_tensor, flags_obj)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate images from noise vector</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"Generator"</span>):</span><br><span class="line">    g_model = define_generator()</span><br><span class="line">    images_fake = g_model(z)</span><br><span class="line">    images_fake_perturbed = g_model(z_perturbed)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Discriminate between real and fake, and try to classify the labeled data</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"Discriminator"</span>) <span class="keyword">as</span> discriminator_scope:</span><br><span class="line">    d_model = Discriminator()</span><br><span class="line">    logits_fake, features_fake          = d_model(images_fake, training=<span class="literal">True</span>)</span><br><span class="line">    logits_fake_perturbed, _            = d_model(images_fake_perturbed, training=<span class="literal">True</span>)</span><br><span class="line">    logits_real_unl, features_real_unl  = d_model(images_unl, training=<span class="literal">True</span>)</span><br><span class="line">    logits_real_lab, features_real_lab  = d_model(images_lab, training=<span class="literal">True</span>)</span><br><span class="line">    logits_train, _                     = d_model(images_lab, training=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="The-discriminator’s-loss"><a href="#The-discriminator’s-loss" class="headerlink" title="The discriminator’s loss"></a>The discriminator’s loss</h1><p>&emsp;&emsp;Recall that the discriminator will be doing more than just separating fake from real. It also classifies the labeled data. For this, we define a supervised loss which takes the softmax output. In terms of implementation, this means that we feed the unnormalized logits to <code>tf.nn.sparse_cross_entropy_with_logits</code>.<br>&emsp;&emsp;Defining the loss for the unsupervised part is where things get a little bit more involved. Because the softmax distribution is overparameterized, we can fix the unnormalized logit at 0 for an image to be fake (i.e. coming from the generator). If we do so, the probability of it being real just turns into:</p>
<script type="math/tex; mode=display">p(x)=\frac{Z(x)}{Z(x)+exp(l_{fake})} = \frac{Z(x)}{Z(x)+1}</script><p>&emsp;&emsp;where Z(x) is the sum of the unnormalized probabilities. Note that we currently only have the logits. Ultimately, we want to use the log-probability of the fake class to define our loss function. This can now be achieved by computing the whole expression in log-space:</p>
<script type="math/tex; mode=display">log(p(x)) = log(Z(x)) - log(1+Z(x)) = logsumexp(l_1,...,l_K) - softplus(logsumexp(l_1,...,l_K))</script><p>&emsp;&emsp;Where the lower case l with subscripts denote the individual logits. Divisions become subtractions and sums can be computed by the logsumexp function. Finally, we have used the definition of the softplus function:</p>
<script type="math/tex; mode=display">softplus(x) = log(1+x)</script><p>&emsp;&emsp;In general, if you have the log-representation of a probability, it is numerically safer to keep things in log-space for as long as you can, since we are able to represent much smaller numbers in that case.<br>&emsp;&emsp;We’re not there yet. Generative adversarial training asks us to ascend the gradient of:</p>
<script type="math/tex; mode=display">log(D(x)) + log(1-D(G(z)))</script><p>&emsp;&emsp;So whenever we call <code>tf.train.AdamOptimizer.minimize</code> we should descent:</p>
<script type="math/tex; mode=display">-log(D(x)) - log(1-D(G(z))) = -log(\frac{Z(x)}{1+Z(x)})-log(1-\frac{Z(G(z))}{1+Z(G(z))})</script><p>&emsp;&emsp;The first term on the right-hand side of the equation can be written:</p>
<script type="math/tex; mode=display">softplus(logsumexp(l^{(x)}_1,...,l^{(x)}_K)) - logsumexp(l^{(x)}_1,...,l^{(x)}_K)</script><p>&emsp;&emsp;The second term of the right-hand side can be written as:</p>
<script type="math/tex; mode=display">-log(1-\frac{Z(G(z))}{1+Z(G(z))}) = -log(\frac{1}{1+Z(G(z))}) = softplus(logsumexp(l^{G(z)}_1,...,l^{G(z)}_K))</script><p>&emsp;&emsp;So that finally, we arrive at the following loss:</p>
<script type="math/tex; mode=display">softplus(logsumexp(l^{(x)}_1,...,l^{(x)}_K)) - logsumexp(l^{(x)}_1,...,l^{(x)}_K) + softplus(logsumexp(l^{G(z)}_1,...,l^{G(z)}_K))</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Set the discriminator losses</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"DiscriminatorLoss"</span>):</span><br><span class="line">    <span class="comment"># Supervised loss, just cross-entropy. This normalizes p(y|x) where 1 &lt;= y &lt;= K</span></span><br><span class="line">    loss_supervised = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(</span><br><span class="line">        labels=labels_lab, logits=logits_real_lab))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Sum of unnormalized log probabilities</span></span><br><span class="line">    logits_sum_real = tf.reduce_logsumexp(logits_real_unl, axis=<span class="number">1</span>)</span><br><span class="line">    logits_sum_fake = tf.reduce_logsumexp(logits_fake, axis=<span class="number">1</span>)</span><br><span class="line">    loss_unsupervised = <span class="number">0.5</span> * (</span><br><span class="line">        tf.negative(tf.reduce_mean(logits_sum_real)) +</span><br><span class="line">        tf.reduce_mean(tf.nn.softplus(logits_sum_real)) +</span><br><span class="line">        tf.reduce_mean(tf.nn.softplus(logits_sum_fake)))</span><br><span class="line">    loss_d = loss_supervised + loss_unsupervised</span><br></pre></td></tr></table></figure>
<h1 id="Optimizing-the-discriminator"><a href="#Optimizing-the-discriminator" class="headerlink" title="Optimizing the discriminator"></a>Optimizing the discriminator</h1><p>&emsp;&emsp;Let’s setup the operations for actually updating the parameters of the discriminator. We will just reside to the Adam optimizer. While tweaking the parameters before I wrote this post, I figured I might slow down the discriminator by setting its learning rate at 0.1 times that of the generator. After that my results got much better, so I decided to leave it there for now. Notice also that we can very easily select the subset of variables corresponding to the discriminator by exploiting the encapsulation offered by Keras.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Configure discriminator training ops</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"Train"</span>) <span class="keyword">as</span> train_scope:</span><br><span class="line">    optimizer = tf.train.AdamOptimizer(flags_obj.lr * <span class="number">0.1</span>)</span><br><span class="line">    optimize_d = optimizer.minimize(loss_d, var_list=d_model.trainable_variables)</span><br><span class="line">    train_accuracy_op = accuracy(logits_train, labels_lab)</span><br></pre></td></tr></table></figure></p>
<h1 id="Adding-some-control-flow-to-the-graph"><a href="#Adding-some-control-flow-to-the-graph" class="headerlink" title="Adding some control flow to the graph"></a>Adding some control flow to the graph</h1><p>&emsp;&emsp;After we have the new weights for the discriminator, we want the generator’s update to be aware of the updated weights. TensorFlow will not guarantee that the updated weights will actually be used even if we were to redeclare the forward computation after defining the minimization operations for the discriminator. We can still force this by using <code>tf.control_dependencies</code>. Any operation defined in the scope of this context manager will depend on the evaluation of the ones that are passed to context manager at instantiation. In other words, our generator’s update that we define later on will be guaranteed to compute the gradients using the updated weights of the discriminator.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(discriminator_scope):</span><br><span class="line">    <span class="keyword">with</span> tf.control_dependencies([optimize_d]):</span><br><span class="line">        <span class="comment"># Build a second time, so that new variables are used</span></span><br><span class="line">        logits_fake, features_fake = d_model(images_fake, training=<span class="literal">True</span>)</span><br><span class="line">        logits_real_unl, features_real_unl = d_model(images_unl2, training=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="The-generator’s-loss-and-updates"><a href="#The-generator’s-loss-and-updates" class="headerlink" title="The generator’s loss and updates"></a>The generator’s loss and updates</h1><p>&emsp;&emsp;In this implementation, the generator tries to minimize the L2 distance of the average features of the generated images vs. the average features of the real images. This <a href="https://arxiv.org/abs/1606.03498" target="_blank" rel="noopener">feature-matching loss</a> (Salimans et al., 2016) has proven to be more stable for training GANs than directly trying to optimize the discriminator’s probability for observing real data. It is straightforward to implement. While we’re at it, let’s also define the update operations for the generator. Notice that the learning rate of this optimizer is 10 times that of the discriminator.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Set the generator loss and the actual train op</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"GeneratorLoss"</span>):</span><br><span class="line">    feature_mean_real = tf.reduce_mean(features_real_unl, axis=<span class="number">0</span>)</span><br><span class="line">    feature_mean_fake = tf.reduce_mean(features_fake, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># L1 distance of features is the loss for the generator</span></span><br><span class="line">    loss_g = tf.reduce_mean(tf.abs(feature_mean_real - feature_mean_fake))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(train_scope):</span><br><span class="line">    optimizer = tf.train.AdamOptimizer(flags_obj.lr, beta1=<span class="number">0.5</span>)</span><br><span class="line">    train_op = optimizer.minimize(loss_g, var_list=g_model.trainable_variables)</span><br></pre></td></tr></table></figure></p>
<h1 id="Adding-manifold-regularization"><a href="#Adding-manifold-regularization" class="headerlink" title="Adding manifold regularization"></a>Adding manifold regularization</h1><p>&emsp;&emsp;<a href="https://arxiv.org/abs/1805.08957" target="_blank" rel="noopener">Lecouat et. al</a> (2018) propose to add manifold regularization to the feature-matching GAN training procedure of <a href="https://arxiv.org/abs/1606.03498" target="_blank" rel="noopener">Salimans et al. (2016)</a>. The regularization forces the discriminator to yield similar logits (unnormalized log probabilities) for nearby points in the latent space in which z resides. It can be implemented by generating a second perturbed version of z and computing the generator’s and discriminator’s outputs once more with this slightly altered vector.    </p>
<p>&emsp;&emsp;This means that the noise generation code looks as follows:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">define_noise</span><span class="params">(batch_size_tensor, flags_obj)</span>:</span></span><br><span class="line">    <span class="comment"># Setup noise vector</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">"LatentNoiseVector"</span>):</span><br><span class="line">        z = tfd.Normal(loc=<span class="number">0.0</span>, scale=flags_obj.stddev).sample(</span><br><span class="line">            sample_shape=(batch_size_tensor, flags_obj.z_dim_size))</span><br><span class="line">        z_perturbed = z + tfd.Normal(loc=<span class="number">0.0</span>, scale=flags_obj.stddev).sample(</span><br><span class="line">            sample_shape=(batch_size_tensor, flags_obj.z_dim_size)) * <span class="number">1e-5</span></span><br><span class="line">    <span class="keyword">return</span> z, z_perturbed</span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;The discriminator’s loss will be updated as follows (note the 3 extra lines at the bottom):<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set the discriminator losses</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"DiscriminatorLoss"</span>):</span><br><span class="line">    <span class="comment"># Supervised loss, just cross-entropy. This normalizes p(y|x) where 1 &lt;= y &lt;= K</span></span><br><span class="line">    loss_supervised = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(</span><br><span class="line">        labels=labels_lab, logits=logits_real_lab))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Sum of unnormalized log probabilities</span></span><br><span class="line">    logits_sum_real = tf.reduce_logsumexp(logits_real_unl, axis=<span class="number">1</span>)</span><br><span class="line">    logits_sum_fake = tf.reduce_logsumexp(logits_fake, axis=<span class="number">1</span>)</span><br><span class="line">    loss_unsupervised = <span class="number">0.5</span> * (</span><br><span class="line">        tf.negative(tf.reduce_mean(logits_sum_real)) +</span><br><span class="line">        tf.reduce_mean(tf.nn.softplus(logits_sum_real)) +</span><br><span class="line">        tf.reduce_mean(tf.nn.softplus(logits_sum_fake)))</span><br><span class="line">    loss_d = loss_supervised + loss_unsupervised</span><br><span class="line">    <span class="keyword">if</span> flags_obj.man_reg:</span><br><span class="line">        loss_d += <span class="number">1e-3</span> * tf.nn.l2_loss(logits_fake - logits_fake_perturbed) \</span><br><span class="line">            / tf.to_float(batch_size_tensor)</span><br></pre></td></tr></table></figure></p>
<h1 id="Classification-performance"><a href="#Classification-performance" class="headerlink" title="Classification performance"></a>Classification performance</h1><p>&emsp;&emsp;So how does it really perform? I have provided a few plots below. There are many things I might try to squeeze out additional performance (for instance, just training for longer, using a learning rate schedule, implementing weight normalization), but the main purpose of writing this post was to get to know a relatively simple yet powerful semi-supervised learning approach. After 100 epochs of training, the mean test accuracy approaches 98.9 percent.<br>&emsp;&emsp;The full script can be found <a href="https://github.com/jostosh/gan" target="_blank" rel="noopener">here</a>. Thanks for reading!<br><img src="/images/Semi-supervised-learning-with-GANs/jpeg1-1.jpeg" alt></p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a href="https://medium.com/@jos.vandewolfshaar/semi-supervised-learning-with-gans-23255865d0a4" target="_blank" rel="noopener">Semi-supervised learning with GANs</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/semi-supervised-learning-and-gans.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/semi-supervised-learning-and-gans.html" class="post-title-link" itemprop="url">Semi-Supervised Learning and GANs</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-09 09:50:06 / 修改时间：11:05:07" itemprop="dateCreated datePublished" datetime="2019-05-09T09:50:06+08:00">2019-05-09</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">13k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">12 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="/images/Semi-Supervised-Learning-and-GANs/jpeg1-1.jpeg" alt><br>&emsp;&emsp;Vincent Van Gogh painted this beautiful art: ‘The Starry Night’ in 1889 and today my GAN model (I like to call it GAN Gogh :P) painted some MNIST digits with only 20% labeled data!! How could it achieve this remarkable feat? … Let’s find out </p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p><strong><em>What is semi-supervised learning?</em></strong><br>&emsp;&emsp;Most deep learning classifiers require a large amount of labeled samples to generalize well, but getting such data is an expensive and difficult process. To deal with this limitation Semi-supervised learning is presented, which is a class of techniques that make use of a morsel of labeled data along with a large amount of unlabeled data.<code>Many machine-learning researchers have found that unlabeled data, when used in conjunction with a small amount of labeled data can produce considerable improvement in learning accuracy</code>. GANs have shown a lot of potential in semi-supervised learning where the classifier can obtain a good performance with very few labeled data.</p>
<p><strong><em>Background on GANs</em></strong><br>&emsp;&emsp;GANs are members of deep generative models. They are particularly interesting because they don’t explicitly represent a probability distribution over the space where the data lies. Instead, they provide some way of interacting less directly with this probability distribution by drawing samples from it.<br><img src="/images/Semi-Supervised-Learning-and-GANs/png1-1.png" alt="Architecture of a Vanilla GAN"><br>The basic idea of GAN is to set up a game between two players:</p>
<ul>
<li>A generator G: Takes random noise z as input and outputs an image x. Its parameters are tuned to get a high score from the discriminator on fake images that it generates.</li>
<li>A discriminator D: Takes an image x as input and outputs a score which reflects its confidence that it is a real image. Its parameters are tuned to have a high score when it is fed by a real image, and a low score when a fake image is fed from the generator.</li>
</ul>
<p>&emsp;&emsp;I suggest you to go through this and this for more details on their working and optimisation objectives. Now, let us turn the wheels a little and talk about one of the most prominent applications of GANs, semi-supervised learning.</p>
<h1 id="Intuition"><a href="#Intuition" class="headerlink" title="Intuition"></a>Intuition</h1><p>&emsp;&emsp;The vanilla architecture of discriminator has only one output neuron for classifying the R/F probabilities. We train both the networks simultaneously and discard the discriminator after the training as it was used only for improving the generator.<br><img src="/images/Semi-Supervised-Learning-and-GANs/png1-2.png" alt><br>&emsp;&emsp;For the semi-supervised task, in addition to R/F neuron, the discriminator will now have 10 more neurons for classification of MNIST digits. Also, this time their roles change and we can discard the generator after training, whose only objective was to generate unlabeled data to improve the discriminator’s performance.<br><strong><em>&emsp;&emsp;Now the discriminator is turned into an 11-class classifier with 1 neuron (R/F neuron) representing the fake data output and the other 10 representing real data with classes. The following has to be kept in mind:</em></strong></p>
<ul>
<li>To assert R/F neuron output label = 0, when real unsupervised data from dataset is fed </li>
<li>To assert R/F neuron output label= 1, when fake unsupervised data from generator is fed </li>
<li>To assert R/F output label = 0 and corresponding label output = 1, when real supervised data is fed </li>
</ul>
<p>This combination of different sources of data will help the discriminator classify more accurately than, if it had been only provided with a portion of labeled data.</p>
<h1 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h1><p>Now it’s time to get our hands dirty with some code :D<br><strong><em>The Discriminator</em></strong><br>&emsp;&emsp;The architecture followed is similar to the one proposed in <a href="https://arxiv.org/pdf/1511.06434.pdf" target="_blank" rel="noopener">DCGAN paper</a>. We use strided convolutions for reducing the dimensions of the feature-vectors rather than any pooling layers and apply a series of leaky_relu, dropout and BN for all layers to stabilize the learning. BN is dropped for input layer and last layer (for the purpose of feature matching). In the end, we perform Global Average Pooling to take the average over the spatial dimensions of the feature vectors. This squashes the tensor dimensions to a single value. After flattening the features, a dense layer of 11 classes is added with softmax activation for multi-class output.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discriminator</span><span class="params">(x, dropout_rate = <span class="number">0.</span>, is_training = True, reuse = False)</span>:</span></span><br><span class="line">   <span class="comment"># input x -&gt; n+1 classes</span></span><br><span class="line">   <span class="keyword">with</span> tf.variable_scope(<span class="string">'Discriminator'</span>, reuse = reuse): </span><br><span class="line">     <span class="comment"># x = ?*64*64*1</span></span><br><span class="line">     </span><br><span class="line">     <span class="comment">#Layer 1</span></span><br><span class="line">     conv1 = tf.layers.conv2d(x, <span class="number">128</span>, kernel_size = [<span class="number">4</span>,<span class="number">4</span>], strides = [<span class="number">2</span>,<span class="number">2</span>],</span><br><span class="line">                             padding = <span class="string">'same'</span>, activation = tf.nn.leaky_relu, name = <span class="string">'conv1'</span>) <span class="comment"># ?*32*32*128</span></span><br><span class="line">     <span class="comment">#No batch-norm for input layer</span></span><br><span class="line">     dropout1 = tf.nn.dropout(conv1, dropout_rate)</span><br><span class="line">     </span><br><span class="line">     <span class="comment">#Layer2</span></span><br><span class="line">     conv2 = tf.layers.conv2d(dropout1, <span class="number">256</span>, kernel_size = [<span class="number">4</span>,<span class="number">4</span>], strides = [<span class="number">2</span>,<span class="number">2</span>],</span><br><span class="line">                             padding = <span class="string">'same'</span>, activation = tf.nn.leaky_relu, name = <span class="string">'conv2'</span>) <span class="comment"># ?*16*16*256</span></span><br><span class="line">     batch2 = tf.layers.batch_normalization(conv2, training = is_training)</span><br><span class="line">     dropout2 = tf.nn.dropout(batch2, dropout_rate)</span><br><span class="line">     </span><br><span class="line">     <span class="comment">#Layer3</span></span><br><span class="line">     conv3 = tf.layers.conv2d(dropout2, <span class="number">512</span>, kernel_size = [<span class="number">4</span>,<span class="number">4</span>], strides = [<span class="number">4</span>,<span class="number">4</span>],</span><br><span class="line">                             padding = <span class="string">'same'</span>, activation = tf.nn.leaky_relu, name = <span class="string">'conv3'</span>) <span class="comment"># ?*4*4*512</span></span><br><span class="line">     batch3 = tf.layers.batch_normalization(conv3, training = is_training)</span><br><span class="line">     dropout3 = tf.nn.dropout(batch3, dropout_rate)</span><br><span class="line">       </span><br><span class="line">     <span class="comment"># Layer 4</span></span><br><span class="line">     conv4 = tf.layers.conv2d(dropout3, <span class="number">1024</span>, kernel_size=[<span class="number">3</span>,<span class="number">3</span>], strides=[<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">                              padding=<span class="string">'valid'</span>,activation = tf.nn.leaky_relu, name=<span class="string">'conv4'</span>) <span class="comment"># ?*2*2*1024</span></span><br><span class="line">     <span class="comment"># No batch-norm as this layer's op will be used in feature matching loss</span></span><br><span class="line">     <span class="comment"># No dropout as feature matching needs to be definite on logits</span></span><br><span class="line"></span><br><span class="line">     <span class="comment"># Layer 5</span></span><br><span class="line">     <span class="comment"># Note: Applying Global average pooling        </span></span><br><span class="line">     flatten = tf.reduce_mean(conv4, axis = [<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">     logits_D = tf.layers.dense(flatten, (<span class="number">1</span> + num_classes))</span><br><span class="line">     out_D = tf.nn.softmax(logits_D)     </span><br><span class="line">   <span class="keyword">return</span> flatten,logits_D,out_D</span><br></pre></td></tr></table></figure></p>
<p><strong><em>The Generator</em></strong><br>&emsp;&emsp;The generator architecture is designed to mirror the discriminator’s spatial outputs. Fractional strided convolutions are used to increase the spatial dimension of the representation. An input of 4-D tensor of noise z is fed which undergoes a series of transposed convolutions, relu, BN(except at output layer) and dropout operations. Finally tanh activation maps the output image in range (-1,1).<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">(z, dropout_rate = <span class="number">0.</span>, is_training = True, reuse = False)</span>:</span></span><br><span class="line">    <span class="comment"># input latent z -&gt; image x</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'Generator'</span>, reuse = reuse):</span><br><span class="line">      <span class="comment">#Layer 1</span></span><br><span class="line">      deconv1 = tf.layers.conv2d_transpose(z, <span class="number">512</span>, kernel_size = [<span class="number">4</span>,<span class="number">4</span>],</span><br><span class="line">                                         strides = [<span class="number">1</span>,<span class="number">1</span>], padding = <span class="string">'valid'</span>,</span><br><span class="line">                                        activation = tf.nn.relu, name = <span class="string">'deconv1'</span>) <span class="comment"># ?*4*4*512</span></span><br><span class="line">      batch1 = tf.layers.batch_normalization(deconv1, training = is_training)</span><br><span class="line">      dropout1 = tf.nn.dropout(batch1, dropout_rate)</span><br><span class="line">      </span><br><span class="line">      <span class="comment">#Layer 2</span></span><br><span class="line">      deconv2 = tf.layers.conv2d_transpose(dropout1, <span class="number">256</span>, kernel_size = [<span class="number">4</span>,<span class="number">4</span>],</span><br><span class="line">                                         strides = [<span class="number">4</span>,<span class="number">4</span>], padding = <span class="string">'same'</span>,</span><br><span class="line">                                        activation = tf.nn.relu, name = <span class="string">'deconv2'</span>)<span class="comment"># ?*16*16*256</span></span><br><span class="line">      batch2 = tf.layers.batch_normalization(deconv2, training = is_training)</span><br><span class="line">      dropout2 = tf.nn.dropout(batch2, dropout_rate)</span><br><span class="line">        </span><br><span class="line">      <span class="comment">#Layer 3</span></span><br><span class="line">      deconv3 = tf.layers.conv2d_transpose(dropout2, <span class="number">128</span>, kernel_size = [<span class="number">4</span>,<span class="number">4</span>],</span><br><span class="line">                                         strides = [<span class="number">2</span>,<span class="number">2</span>], padding = <span class="string">'same'</span>,</span><br><span class="line">                                        activation = tf.nn.relu, name = <span class="string">'deconv3'</span>)<span class="comment"># ?*32*32*256</span></span><br><span class="line">      batch3 = tf.layers.batch_normalization(deconv3, training = is_training)</span><br><span class="line">      dropout3 = tf.nn.dropout(batch3, dropout_rate)</span><br><span class="line">      </span><br><span class="line">      <span class="comment">#Output layer</span></span><br><span class="line">      deconv4 = tf.layers.conv2d_transpose(dropout3, <span class="number">1</span>, kernel_size = [<span class="number">4</span>,<span class="number">4</span>],</span><br><span class="line">                                        strides = [<span class="number">2</span>,<span class="number">2</span>], padding = <span class="string">'same'</span>,</span><br><span class="line">                                        activation = <span class="literal">None</span>, name = <span class="string">'deconv4'</span>)<span class="comment"># ?*64*64*1</span></span><br><span class="line">      out = tf.nn.tanh(deconv4)</span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure></p>
<h1 id="Model-Loss"><a href="#Model-Loss" class="headerlink" title="Model Loss"></a>Model Loss</h1><p>&emsp;&emsp;We start by preparing an extended label for the whole batch by appending actual label to zeros. This is done to assert the R/F neuron output to 0 when the labeled data is fed. The discriminator loss for unlabeled data can be thought of as a binary sigmoid loss by asserting R/F neuron output to 1 for fake images and 0 for real images.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">             <span class="comment">### Discriminator loss ###</span></span><br><span class="line"><span class="comment"># Supervised loss -&gt; which class the real data belongs to    </span></span><br><span class="line">temp = tf.nn.softmax_cross_entropy_with_logits_v2(logits = D_real_logit,</span><br><span class="line">                                              labels = extended_label) </span><br><span class="line"><span class="comment"># Labeled_mask and temp are of same size = batch_size where temp is softmax cross_entropy calculated over whole batch</span></span><br><span class="line"></span><br><span class="line">D_L_Supervised = tf.reduce_sum(tf.multiply(temp,labeled_mask)) / tf.reduce_sum(labeled_mask)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Multiplying temp with labeled_mask gives supervised loss on labeled_mask</span></span><br><span class="line"><span class="comment"># data only, calculating mean by dividing by no of labeled samples</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Unsupervised loss -&gt; R/F    </span></span><br><span class="line">D_L_RealUnsupervised = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(</span><br><span class="line">        logits = D_real_logit[:, <span class="number">0</span>], labels = tf.zeros_like(D_real_logit[:, <span class="number">0</span>], dtype=tf.float32)))</span><br><span class="line"></span><br><span class="line">D_L_FakeUnsupervised = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(</span><br><span class="line">        logits = D_fake_logit[:, <span class="number">0</span>], labels = tf.ones_like(D_fake_logit[:, <span class="number">0</span>], dtype=tf.float32)))</span><br><span class="line"></span><br><span class="line">D_L = D_L_Supervised + D_L_RealUnsupervised + D_L_FakeUnsupervised</span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;Generator loss is a combination of fake_image loss which falsely wants to assert R/F neuron output to 0 and feature matching loss which penalizes the mean absolute error between the average value of some set of features on the training data and the average values of that set of features on the generated samples.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">             <span class="comment">### Generator loss ###                </span></span><br><span class="line"><span class="comment"># G_L_1 -&gt; Fake data wanna be real </span></span><br><span class="line"></span><br><span class="line">G_L_1 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(</span><br><span class="line">        logits = D_fake_logit[:, <span class="number">0</span>],labels = tf.zeros_like(D_fake_logit[:, <span class="number">0</span>], dtype=tf.float32)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># G_L_2 -&gt; Feature matching</span></span><br><span class="line">data_moments = tf.reduce_mean(D_real_features, axis = <span class="number">0</span>)</span><br><span class="line">sample_moments = tf.reduce_mean(D_fake_features, axis = <span class="number">0</span>)</span><br><span class="line">G_L_2 = tf.reduce_mean(tf.square(data_moments-sample_moments))</span><br><span class="line"></span><br><span class="line">G_L = G_L_1 + G_L_2</span><br></pre></td></tr></table></figure></p>
<h1 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h1><p>&emsp;&emsp;The training images are resized from [batch_size, 28 ,28 , 1] to [batch_size, 64, 64, 1] to fit the generator/discriminator architectures. Losses, accuracies and generated samples are calculated and are observed to improve over each epoch.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">  train_accuracies, train_D_losses, train_G_losses = [], [], []</span><br><span class="line">  <span class="keyword">for</span> it <span class="keyword">in</span> range(no_of_batches):</span><br><span class="line">  </span><br><span class="line">  batch = mnist_data.train.next_batch(batch_size, shuffle = <span class="literal">False</span>)</span><br><span class="line">  <span class="comment"># batch[0] has shape: batch_size*28*28*1         </span></span><br><span class="line">  batch_reshaped = tf.image.resize_images(batch[<span class="number">0</span>], [<span class="number">64</span>, <span class="number">64</span>]).eval()</span><br><span class="line">  <span class="comment"># Reshaping the whole batch into batch_size*64*64*1 for disc/gen architecture</span></span><br><span class="line">  batch_z = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (batch_size, <span class="number">1</span>, <span class="number">1</span>, latent))</span><br><span class="line">  mask = get_labeled_mask(labeled_rate, batch_size)</span><br><span class="line">                </span><br><span class="line">  train_feed_dict = &#123;x : scale(batch_reshaped), z : batch_z,</span><br><span class="line">                              label : batch[<span class="number">1</span>], labeled_mask : mask,</span><br><span class="line">                               dropout_rate : <span class="number">0.7</span>, is_training : <span class="literal">True</span>&#125;</span><br><span class="line">  <span class="comment">#The label provided in dict are one hot encoded in 10 classes</span></span><br><span class="line">                </span><br><span class="line">  D_optimizer.run(feed_dict = train_feed_dict)</span><br><span class="line">  G_optimizer.run(feed_dict = train_feed_dict)</span><br><span class="line">                </span><br><span class="line">  train_D_loss = D_L.eval(feed_dict = train_feed_dict)</span><br><span class="line">  train_G_loss = G_L.eval(feed_dict = train_feed_dict)</span><br><span class="line">  train_accuracy = accuracy.eval(feed_dict = train_feed_dict)</span><br><span class="line">          </span><br><span class="line">  train_D_losses.append(train_D_loss)</span><br><span class="line">  train_G_losses.append(train_G_loss)</span><br><span class="line">  train_accuracies.append(train_accuracy)</span><br><span class="line">          </span><br><span class="line">  tr_GL = np.mean(train_G_losses)</span><br><span class="line">  tr_DL = np.mean(train_D_losses)</span><br><span class="line">  tr_acc = np.mean(train_accuracies)       </span><br><span class="line">  </span><br><span class="line">  <span class="keyword">print</span> (<span class="string">'After epoch: '</span>+ str(epoch+<span class="number">1</span>) + <span class="string">' Generator loss: '</span></span><br><span class="line">                       + str(tr_GL) + <span class="string">' Discriminator loss: '</span> + str(tr_DL) + <span class="string">' Accuracy: '</span> + str(tr_acc))</span><br><span class="line">        </span><br><span class="line">  gen_samples = fake_data.eval(feed_dict = &#123;z : np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (<span class="number">25</span>, <span class="number">1</span>, <span class="number">1</span>, latent)), dropout_rate : <span class="number">0.7</span>, is_training : <span class="literal">False</span>&#125;)</span><br><span class="line">  <span class="comment"># Dont train batch-norm while plotting =&gt; is_training = False</span></span><br><span class="line">  test_images = tf.image.resize_images(gen_samples, [<span class="number">64</span>, <span class="number">64</span>]).eval()</span><br><span class="line">  show_result(test_images, (epoch + <span class="number">1</span>), show = <span class="literal">True</span>, save = <span class="literal">False</span>, path = <span class="string">''</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>&emsp;&emsp;The training was done for 5 epochs and 20% labeled_rate due to restricted GPU access. For better results more training epochs with lesser labeled_rate is advised. The complete code notebook can be found <a href="https://github.com/raghav64/SemiSuper_GAN/blob/master/SSGAN.py" target="_blank" rel="noopener">here</a>.<br><img src="/images/Semi-Supervised-Learning-and-GANs/jpeg1-2.jpeg" alt="Training Results"><br>&emsp;&emsp;Unsupervised learning is considered as a lacuna in the field of AGI. To bridge this gap, GANs are considered as a potential solution for learning complex tasks with low labeled data. With blooming new approaches in the domain of semi and unsupervised learning we can expect that this gap will lessen.<br>&emsp;&emsp;I would be remiss not to mention my inspiration from this beautiful blog, this implementation along with the assistance of my colleague working on similar projects.<br><strong><em>Until next time!! Kz</em></strong></p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a href="https://towardsdatascience.com/semi-supervised-learning-and-gans-f23bbf4ac683" target="_blank" rel="noopener">Semi-Supervised Learning and GANs</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/shou-ba-shou-jiao-ni-yong-gan-shi-xian-ban-jian-du-xue-xi.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/shou-ba-shou-jiao-ni-yong-gan-shi-xian-ban-jian-du-xue-xi.html" class="post-title-link" itemprop="url">手把手教你用GAN实现半监督学习</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-08 22:30:59" itemprop="dateCreated datePublished" datetime="2019-05-08T22:30:59+08:00">2019-05-08</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-09 09:17:40" itemprop="dateModified" datetime="2019-05-09T09:17:40+08:00">2019-05-09</time>
              
            
          </span>

          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">20k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">18 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>&emsp;&emsp;本文主要介绍如何在tensorflow上仅使用200个带标签的mnist图像，实现在一万张测试图片上99%的测试精度，原理在于使用GAN做半监督学习。前文主要介绍一些原理部分，后文详细介绍代码及其实现原理。前文介绍比较简单，有基础的同学请略过直接看第二部分，文章末尾给出了代码GitHub链接。对GAN不了解的同学可以查看微信公众号：机器学习算法全栈工程师 的GAN入门文章。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">本博客中的代码最终以GitHub中的代码为准，GitHub链接在文章底部，另外，本文已投稿至微信公众号：机器学习算法全栈工程师，欢迎关注此公众号</span><br></pre></td></tr></table></figure></p>
<h1 id="1-监督，无监督，半监督学习介绍"><a href="#1-监督，无监督，半监督学习介绍" class="headerlink" title="1.监督，无监督，半监督学习介绍"></a>1.监督，无监督，半监督学习介绍</h1><p>&emsp;&emsp;在正式介绍实现半监督学习之前，我在这里首先介绍一下<u>监督学习（supervised learning），半监督学习（semi-supervised learning）和无监督学习（unsupervised learning）的区别</u>。</p>
<ul>
<li><font color="blue">监督学习</font>是指在训练集中包含训练数据的标签（label），比如类别标签，位置标签等等。最普遍使用标签学习的是分类任务，对于分类任务，输入给网络训练样本（samples）的一些特征（feature）以及此样本对应的标签（label），通过神经网络拟合的方法，神经网络可以在特征和标签之间找到一个合适的映射关系（mapping），这样当训练完成后，输入给网络没有label的样本，神经网络可以通过这一个映射关系猜出它属于哪一类。典型机器学习的监督学习的例子是KNN和SVM。目前机器视觉领域的急速发展离不开监督学习。 </li>
<li>而<font color="blue">无监督学习</font>的训练事先没有训练标签，直接输入给算法一些数据，算法会努力学习数据的共同点，寻找样本之间的规律性。无监督学习是很典型的学习，人的学习有时候就是基于无监督的，比如我并不懂音乐，但是我听了上百首歌曲后，我可以根据我听的结果将音乐分为摇滚乐（记为0类）、民谣（记为1类）、纯音乐（记为2类）等等，事实上，我并不知道具体是哪一类，所以将它们记为0，1，2三类。典型的无监督学习方法是聚类算法，比如k-means。 </li>
<li>东方快车电影里面大侦探有过一个台词，人们的话只有对与错，没有中间地带，最后经过一系列事件后他找到了对与错之间的betweeness。在监督学习和无监督学习之间，同样存在着中间地带——<font color="blue">半监督学习</font>。半监督学习简单来说就是将无监督学习和监督学习相结合，一部分包含了监督学习一部分包含了无监督学习，比如给一个分类任务，此分类任务的训练集中有精确标签的数据非常少，但是包含了大量的没有标注的数据，如果直接用监督学习的方法去做的话，效果不一定很好，有标注的训练数据太少很容易导致过拟合，而且大量的无标注的数据都没有充分的利用，最常见的例子是在医学图像的分析检测任务中，医学图像本身就不容易获得，要获得精标注的图像就需要有经验的医生去一个一个标注，显然他们并没有那么多的时间。这时候就是半监督学习的用武之地了，<u>半监督学习很适合用在标签数据少，训练数据又比较多的情况</u>。<br>常见的半监督学习方法主要有：<br>&emsp;&emsp;1.<strong><em>Self training </em></strong><br>&emsp;&emsp;2.<strong><em>Generative model </em></strong><br>&emsp;&emsp;3.<strong><em>S3VMs </em></strong><br>&emsp;&emsp;4.<strong><em>Graph-Based AIgorithems </em></strong><br>&emsp;&emsp;5.<strong><em>Multiview AIgorithems   </em></strong></li>
</ul>
<p>&emsp;&emsp;接下来我会结合<strong><em>Improved Techniques for Training GANs</em></strong>这篇论文详细介绍如何使用目前最火的生成对抗模型GAN去实现半监督学习，也即是<font color="red">半监督学习的第二种方法</font>，并给出详细的代码解释，对理论不是很熟悉的同学可以直接看代码。另外注明：<u>我只复现了论文半监督学习的部分，之前也有人复现了此部分，但是我感觉他对原文有很大的曲解，他使用了所有的标签去帮助生成，并不在分类上，不太符合半监督学习的本质，而且代码很复杂</u>，感兴趣的可以去GitHub上搜ssgan,希望能帮助你。 </p>
<h1 id="2-Improved-Techniques-for-Training-GANs"><a href="#2-Improved-Techniques-for-Training-GANs" class="headerlink" title="2. Improved Techniques for Training GANs"></a>2. Improved Techniques for Training GANs</h1><p>&emsp;&emsp;GAN是无监督学习的代表，它可以不断学习模拟数据的分布进而生成和训练数据相似分布的样本，在训练过程不需要标签，<u>GAN在无监督学习领域，生成领域，半监督学习领域以及强化学习领域都有广泛的应用</u>。但是GAN存在很多的训练不稳定等等的问题，作者good fellow在2016年放出了Improved Techniques for Training GANs，对GAN训练不稳定的问题做了一些解释和经验上的解决方案，并给出了和半监督学习结合的方法。<br>&emsp;&emsp;从平衡点角度解释GAN的不稳定性来说，GAN的<b>纳什均衡点</b>是一个鞍点，并不是一个局部最小值点，基于梯度的方法主要是寻找高维空间中的极小值点，因此使用梯度训练的方法很难使GAN收敛到平衡点。为此，为了进一部分缓解这个问题，goodfellow联合提出了一些改进方案，<br>主要有： </p>
<ul>
<li>Feature matching, </li>
<li>Minibatch discrimination </li>
<li>weight Historical averaging (相当于一个正则化的方式) </li>
<li>One-sided label smoothing </li>
<li>Virtual batch normalization </li>
</ul>
<p>后来发现<u>Feature matching在半监督学习上表现良好，mini-batch discrimination表现很差</u>。 </p>
<h1 id="3-semi-supervised-GAN"><a href="#3-semi-supervised-GAN" class="headerlink" title="3. semi-supervised GAN"></a>3. semi-supervised GAN</h1><p>&emsp;&emsp;对于一个普通的分类器来说，假设对MNIST分类，一共有10类数据，分别是0-9，分类器模型以数据x作为输入，输出一个K=10维的向量，经过softmax后计算出分类概率最大的那个类别。<u>在监督学习领域，往往是通过最小化类别标签和预测分布 的交叉熵来实现最好的结果</u>。<br>&emsp;&emsp;但是<font color="red">将GAN用在半监督学习领域</font>的时候需要做一些改变，生成器不做改变，仍然负责从输入噪声数据中生成图像，判别器D不在是一个简单的真假分类（二分类）器，假设输入数据有K类，D就是K+1的分类器，多出的那一类是判别输入是否是生成器G生成的图像。网络的流程图见下图：<br><img src="/images/手把手教你用GAN实现半监督学习/dib1-1.dib" alt><br>&emsp;&emsp;网络结构确定了之后就是损失函数的设计部分，借助GAN我们就可以从无标签数据中学习，只要知道输入数据是真实数据，那就可以通过最大化\(logP_{model}(y\in{1,2,…,K}|x)\)来实现，上述式子可解释为不管输入的是哪一类真的图片（不是生成器G生成的假图片），只要最大化输出它是真图像的概率就可以了，不需要具体分出是哪一类。由于GAN的生成器的参与，训练数据中有一半都是生成的假数据。<br>&emsp;&emsp;下面给出判别器D的损失函数设计，D损失函数包括两个部分，一个是<u>监督学习损失</u>，一个是<u>半监督学习损失</u>，具体公式如下： </p>
<script type="math/tex; mode=display">L=L_{supervised} + L_{unsupervised}</script><p>其中：<br><img src="/images/手把手教你用GAN实现半监督学习/png1-1.png" alt><br>对于无监督学习来说，只需要输出真假就可以了，不需要确定是哪一类，因此我们令 </p>
<script type="math/tex; mode=display">D(x)=1-logP_{model}(y\in{1,2,...,K}|x)</script><p>其中\( P_{model} \)表示判别是假图像的概率，那么D(x)就代表了输出是真图像的概率，那么无监督学习的损失函数就可以表示为 </p>
<script type="math/tex; mode=display">L_{unsupervised} = -\{E_{x\sim Pdata(x)}logD(x) + E_{z\sim noise}log(1-D(G(z)))\}</script><p>&emsp;&emsp;这不就是GAN的损失函数嘛！好了，到这里得出结论，在半监督学习中，判别器的分类要多分一类，多出的这一类表示的是生成器生成的假图像这一类，另外判别器的损失函数不仅包括了监督损失函数而且还有无监督的损失函数，在训练过程中同时最小化这两者。损失函数介绍完毕，接下来介绍代码实现部分。</p>
<h1 id="4-代码实现及解读"><a href="#4-代码实现及解读" class="headerlink" title="4.代码实现及解读"></a>4.代码实现及解读</h1><p>&emsp;&emsp;<font color="red">注：完整代码的GitHub连接在文章底部。这里只截取关键部分做介绍 </font><br>&emsp;&emsp;在代码中，我使用feature matching，one side label smoothing方式，并没有使用论文中介绍的Historical averaging,而是只对判别器D使用了简单的l2正则化，防止过拟合，另外论文中介绍的Minibatch discrimination, Virtual batch normalization等等都没有使用，主要是这两者在半监督学习中表现不是很好，但是如果想获得好的生成结果还是很有用的。<br>&emsp;&emsp;首先介绍网络结构部分，因为是在mnist数据集比较简单，所以随便搭了一个判别器和生成器，具体如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discriminator</span><span class="params">(self, name, inputs, reuse)</span>:</span></span><br><span class="line">        l = tf.shape(inputs)[<span class="number">0</span>]</span><br><span class="line">        inputs = tf.reshape(inputs, (l,self.img_size,self.img_size,self.dim))</span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(name,reuse=reuse):</span><br><span class="line">            out = []</span><br><span class="line">            output = conv2d(<span class="string">'d_con1'</span>,inputs,<span class="number">5</span>, <span class="number">64</span>, stride=<span class="number">2</span>, padding=<span class="string">'SAME'</span>) <span class="comment">#14*14</span></span><br><span class="line">            output1 = lrelu(self.bn(<span class="string">'d_bn1'</span>,output))</span><br><span class="line">            out.append(output1)</span><br><span class="line">            <span class="comment"># output1 = tf.contrib.keras.layers.GaussianNoise</span></span><br><span class="line">            output = conv2d(<span class="string">'d_con2'</span>, output1, <span class="number">3</span>, <span class="number">64</span>*<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="string">'SAME'</span>)<span class="comment">#7*7</span></span><br><span class="line">            output2 = lrelu(self.bn(<span class="string">'d_bn2'</span>, output))</span><br><span class="line">            out.append(output2)</span><br><span class="line">            output = conv2d(<span class="string">'d_con3'</span>, output2, <span class="number">3</span>, <span class="number">64</span>*<span class="number">4</span>, stride=<span class="number">1</span>, padding=<span class="string">'VALID'</span>)<span class="comment">#5*5</span></span><br><span class="line">            output3 = lrelu(self.bn(<span class="string">'d_bn3'</span>, output))</span><br><span class="line">            out.append(output3)</span><br><span class="line">            output = conv2d(<span class="string">'d_con4'</span>, output3, <span class="number">3</span>, <span class="number">64</span>*<span class="number">4</span>, stride=<span class="number">2</span>, padding=<span class="string">'VALID'</span>)<span class="comment">#2*2</span></span><br><span class="line">            output4 = lrelu(self.bn(<span class="string">'d_bn4'</span>, output))</span><br><span class="line">            out.append(output4)</span><br><span class="line">            output = tf.reshape(output4, [l, <span class="number">2</span>*<span class="number">2</span>*<span class="number">64</span>*<span class="number">4</span>])<span class="comment"># 2*2*64*4</span></span><br><span class="line">            output = fc(<span class="string">'d_fc'</span>, output, self.num_class)</span><br><span class="line">            <span class="comment"># output = tf.nn.softmax(output)</span></span><br><span class="line">            <span class="keyword">return</span> output, out</span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;其中conv2d()是卷积操作，参数依次是，<u>层的名字，输入tensor，卷积核大小，输出通道数，步长，padding</u>。判别器中每一层都加了归一化层，这里使用最简单的归一化，函数如下所示，另外每一层的激活函数使用leakyrelu。判别器D最终返回两个值，第一个是计算的logits，另外一个是一个列表，列表的每一个元素代表判别器每一层的输出，为接下来实现feature matching做准备。<br>&emsp;&emsp;生成器结构如下所示：<font color="red">其最后一层激活函数使用tanh</font><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">(self,name, noise, reuse)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(name,reuse=reuse):</span><br><span class="line">        l = self.batch_size</span><br><span class="line">        output = fc(<span class="string">'g_dc'</span>, noise, <span class="number">2</span>*<span class="number">2</span>*<span class="number">64</span>)</span><br><span class="line">        output = tf.reshape(output, [<span class="number">-1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">64</span>])</span><br><span class="line">        output = tf.nn.relu(self.bn(<span class="string">'g_bn1'</span>,output))</span><br><span class="line">        output = deconv2d(<span class="string">'g_dcon1'</span>,output,<span class="number">5</span>,outshape=[l, <span class="number">4</span>, <span class="number">4</span>, <span class="number">64</span>*<span class="number">4</span>])</span><br><span class="line">        output = tf.nn.relu(self.bn(<span class="string">'g_bn2'</span>,output))</span><br><span class="line"></span><br><span class="line">        output = deconv2d(<span class="string">'g_dcon2'</span>, output, <span class="number">5</span>, outshape=[l, <span class="number">8</span>, <span class="number">8</span>, <span class="number">64</span> * <span class="number">2</span>])</span><br><span class="line">        output = tf.nn.relu(self.bn(<span class="string">'g_bn3'</span>, output))</span><br><span class="line"></span><br><span class="line">        output = deconv2d(<span class="string">'g_dcon3'</span>, output, <span class="number">5</span>, outshape=[l, <span class="number">16</span>, <span class="number">16</span>,<span class="number">64</span> * <span class="number">1</span>])</span><br><span class="line">        output = tf.nn.relu(self.bn(<span class="string">'g_bn4'</span>, output))</span><br><span class="line"></span><br><span class="line">        output = deconv2d(<span class="string">'g_dcon4'</span>, output, <span class="number">5</span>, outshape=[l, <span class="number">32</span>, <span class="number">32</span>, self.dim])</span><br><span class="line">        output = tf.image.resize_images(output, (<span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">        <span class="comment"># output = tf.nn.relu(self.bn('g_bn4', output))</span></span><br><span class="line">        <span class="keyword">return</span> tf.nn.tanh(output)</span><br></pre></td></tr></table></figure></p>
<p>网络结构是根据DCGAN的结构改的，所以网络简要介绍到这里。</p>
<p>接下来介绍网络初始化方面：<br>首先在train.py里建立一个Train的类，并做一些初始化<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">from</span> glob <span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy.misc <span class="keyword">as</span> scm</span><br><span class="line"><span class="keyword">from</span> vlib.layers <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> vlib.load_data <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> vlib.plot <span class="keyword">as</span> plot</span><br><span class="line"><span class="keyword">import</span> vlib.my_extract <span class="keyword">as</span> dataload</span><br><span class="line"><span class="keyword">import</span> vlib.save_images <span class="keyword">as</span> save_img</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data <span class="comment">#as mnist_data</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'data/'</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># temp = 0.89</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Train</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, sess, args)</span>:</span></span><br><span class="line">        <span class="comment">#sess=tf.Session()</span></span><br><span class="line">        self.sess = sess</span><br><span class="line">        self.img_size = <span class="number">28</span>   <span class="comment"># the size of image</span></span><br><span class="line">        self.trainable = <span class="literal">True</span></span><br><span class="line">        self.batch_size = <span class="number">50</span>  <span class="comment"># must be even number</span></span><br><span class="line">        self.lr = <span class="number">0.0002</span></span><br><span class="line">        self.mm = <span class="number">0.5</span>      <span class="comment"># momentum term for adam</span></span><br><span class="line">        self.z_dim = <span class="number">128</span>   <span class="comment"># the dimension of noise z</span></span><br><span class="line">        self.EPOCH = <span class="number">50</span>    <span class="comment"># the number of max epoch</span></span><br><span class="line">        self.LAMBDA = <span class="number">0.1</span>  <span class="comment"># parameter of WGAN-GP</span></span><br><span class="line">        self.model = args.model  <span class="comment"># 'DCGAN' or 'WGAN'</span></span><br><span class="line">        self.dim = <span class="number">1</span>       <span class="comment"># RGB is different with gray pic</span></span><br><span class="line">        self.num_class = <span class="number">11</span></span><br><span class="line">        self.load_model = args.load_model</span><br><span class="line">        self.build_model()  <span class="comment"># initializer</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_model</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># build  placeholders</span></span><br><span class="line">        self.x=tf.placeholder(tf.float32,shape=[self.batch_size,self.img_size*self.img_size*self.dim],name=<span class="string">'real_img'</span>)</span><br><span class="line">        self.z = tf.placeholder(tf.float32, shape=[self.batch_size, self.z_dim], name=<span class="string">'noise'</span>)</span><br><span class="line">        self.label = tf.placeholder(tf.float32, shape=[self.batch_size, self.num_class - <span class="number">1</span>], name=<span class="string">'label'</span>)</span><br><span class="line">        self.flag = tf.placeholder(tf.float32, shape=[], name=<span class="string">'flag'</span>)</span><br><span class="line">        self.flag2 = tf.placeholder(tf.float32, shape=[], name=<span class="string">'flag2'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># define the network</span></span><br><span class="line">        self.G_img = self.generator(<span class="string">'gen'</span>, self.z, reuse=<span class="literal">False</span>)</span><br><span class="line">        d_logits_r, layer_out_r = self.discriminator(<span class="string">'dis'</span>, self.x, reuse=<span class="literal">False</span>)</span><br><span class="line">        d_logits_f, layer_out_f = self.discriminator(<span class="string">'dis'</span>, self.G_img, reuse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        d_regular = tf.add_n(tf.get_collection(<span class="string">'regularizer'</span>, <span class="string">'dis'</span>), <span class="string">'loss'</span>)  <span class="comment"># D regular loss</span></span><br><span class="line">        <span class="comment"># caculate the unsupervised loss</span></span><br><span class="line">        un_label_r = tf.concat([tf.ones_like(self.label), tf.zeros(shape=(self.batch_size, <span class="number">1</span>))], axis=<span class="number">1</span>)</span><br><span class="line">        un_label_f = tf.concat([tf.zeros_like(self.label), tf.ones(shape=(self.batch_size, <span class="number">1</span>))], axis=<span class="number">1</span>)</span><br><span class="line">        logits_r, logits_f = tf.nn.softmax(d_logits_r), tf.nn.softmax(d_logits_f)</span><br><span class="line">        d_loss_r = -tf.log(tf.reduce_sum(logits_r[:, :<span class="number">-1</span>])/tf.reduce_sum(logits_r[:,:]))</span><br><span class="line">        d_loss_f = -tf.log(tf.reduce_sum(logits_f[:, <span class="number">-1</span>])/tf.reduce_sum(logits_f[:,:]))</span><br><span class="line">        <span class="comment"># d_loss_r = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=un_label_r*0.9, logits=d_logits_r))</span></span><br><span class="line">        <span class="comment"># d_loss_f = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=un_label_f*0.9, logits=d_logits_f))</span></span><br><span class="line">        <span class="comment"># feature match</span></span><br><span class="line">        f_match = tf.constant(<span class="number">0.</span>, dtype=tf.float32)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">            f_match += tf.reduce_mean(tf.multiply(layer_out_f[i]-layer_out_r[i], layer_out_f[i]-layer_out_r[i]))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># caculate the supervised loss</span></span><br><span class="line">        s_label = tf.concat([self.label, tf.zeros(shape=(self.batch_size,<span class="number">1</span>))], axis=<span class="number">1</span>)</span><br><span class="line">        s_l_r = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=s_label*<span class="number">0.9</span>, logits=d_logits_r))</span><br><span class="line">        s_l_f = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=un_label_f*<span class="number">0.9</span>, logits=d_logits_f))  <span class="comment"># same as d_loss_f</span></span><br><span class="line">        self.d_l_1, self.d_l_2 = d_loss_r + d_loss_f, s_l_r</span><br><span class="line">        self.d_loss = d_loss_r + d_loss_f + s_l_r*self.flag*<span class="number">10</span> + d_regular</span><br><span class="line">        self.g_loss = d_loss_f + <span class="number">0.01</span>*f_match</span><br><span class="line"></span><br><span class="line">        all_vars = tf.global_variables()</span><br><span class="line">        g_vars = [v <span class="keyword">for</span> v <span class="keyword">in</span> all_vars <span class="keyword">if</span> <span class="string">'gen'</span> <span class="keyword">in</span> v.name]</span><br><span class="line">        d_vars = [v <span class="keyword">for</span> v <span class="keyword">in</span> all_vars <span class="keyword">if</span> <span class="string">'dis'</span> <span class="keyword">in</span> v.name]</span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> all_vars:</span><br><span class="line">            <span class="keyword">print</span> v</span><br><span class="line">        <span class="keyword">if</span> self.model == <span class="string">'DCGAN'</span>:</span><br><span class="line">            self.opt_d = tf.train.AdamOptimizer(self.lr, beta1=self.mm).minimize(self.d_loss, var_list=d_vars)</span><br><span class="line">            self.opt_g = tf.train.AdamOptimizer(self.lr, beta1=self.mm).minimize(self.g_loss, var_list=g_vars)</span><br><span class="line">        <span class="keyword">elif</span> self.model == <span class="string">'WGAN_GP'</span>:</span><br><span class="line">            self.opt_d = tf.train.AdamOptimizer(<span class="number">1e-5</span>, beta1=<span class="number">0.5</span>, beta2=<span class="number">0.9</span>).minimize(self.d_loss, var_list=d_vars)</span><br><span class="line">            self.opt_g = tf.train.AdamOptimizer(<span class="number">1e-5</span>, beta1=<span class="number">0.5</span>, beta2=<span class="number">0.9</span>).minimize(self.g_loss, var_list=g_vars)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">'model can only be "DCGAN","WGAN_GP" !'</span>)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="comment"># test</span></span><br><span class="line">        test_logits, _ = self.discriminator(<span class="string">'dis'</span>, self.x, reuse=<span class="literal">True</span>)</span><br><span class="line">        test_logits = tf.nn.softmax(test_logits)</span><br><span class="line">        temp = tf.reshape(test_logits[:, <span class="number">-1</span>],shape=[self.batch_size, <span class="number">1</span>])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">            temp = tf.concat([temp, tf.reshape(test_logits[:, <span class="number">-1</span>],shape=[self.batch_size, <span class="number">1</span>])], axis=<span class="number">1</span>)</span><br><span class="line">        test_logits -= temp</span><br><span class="line">        self.prediction = tf.nn.in_top_k(test_logits, tf.argmax(s_label, axis=<span class="number">1</span>), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.saver = tf.train.Saver()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.load_model:</span><br><span class="line">            init = tf.global_variables_initializer()</span><br><span class="line">            self.sess.run(init)</span><br><span class="line">        <span class="keyword">elif</span> self.load_model:</span><br><span class="line">            self.saver.restore(self.sess, os.getcwd()+<span class="string">'/model_saved/model.ckpt'</span>)</span><br><span class="line">            <span class="keyword">print</span> <span class="string">'model load done'</span></span><br><span class="line">        self.sess.graph.finalize()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">'model_saved'</span>):</span><br><span class="line">            os.mkdir(<span class="string">'model_saved'</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">'gen_picture'</span>):</span><br><span class="line">            os.mkdir(<span class="string">'gen_picture'</span>)</span><br><span class="line">        noise = np.random.normal(<span class="number">-1</span>, <span class="number">1</span>, [self.batch_size, <span class="number">128</span>])</span><br><span class="line">        temp = <span class="number">0.80</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">'training'</span></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> range(self.EPOCH):</span><br><span class="line">            <span class="comment"># iters = int(156191//self.batch_size)</span></span><br><span class="line">            iters = <span class="number">50000</span>//self.batch_size</span><br><span class="line">            flag2 = <span class="number">1</span>  <span class="comment"># if epoch&gt;10 else 0</span></span><br><span class="line">            <span class="keyword">for</span> idx <span class="keyword">in</span> range(iters):</span><br><span class="line">                start_t = time.time()</span><br><span class="line">                flag = <span class="number">1</span> <span class="keyword">if</span> idx &lt; <span class="number">4</span> <span class="keyword">else</span> <span class="number">0</span> <span class="comment"># set we use 2*batch_size=200 train data labeled.</span></span><br><span class="line">                batchx, batchl = mnist.train.next_batch(self.batch_size)</span><br><span class="line">                <span class="comment"># batchx, batchl = self.sess.run([batchx, batchl])</span></span><br><span class="line">                g_opt = [self.opt_g, self.g_loss]</span><br><span class="line">                d_opt = [self.opt_d, self.d_loss, self.d_l_1, self.d_l_2]</span><br><span class="line">                feed = &#123;self.x:batchx, self.z:noise, self.label:batchl, self.flag:flag, self.flag2:flag2&#125;</span><br><span class="line">                <span class="comment"># update the Discrimater k times</span></span><br><span class="line">                _, loss_d, d1,d2 = self.sess.run(d_opt, feed_dict=feed)</span><br><span class="line">                <span class="comment"># update the Generator one time</span></span><br><span class="line">                _, loss_g = self.sess.run(g_opt, feed_dict=feed)</span><br><span class="line">                <span class="keyword">print</span> (<span class="string">"[%3f][epoch:%2d/%2d][iter:%4d/%4d],loss_d:%5f,loss_g:%4f, d1:%4f, d2:%4f"</span>%</span><br><span class="line">                       (time.time()-start_t, epoch, self.EPOCH,idx,iters, loss_d, loss_g,d1,d2)), <span class="string">'flag:'</span>,flag</span><br><span class="line">                plot.plot(<span class="string">'d_loss'</span>, loss_d)</span><br><span class="line">                plot.plot(<span class="string">'g_loss'</span>, loss_g)</span><br><span class="line">                <span class="keyword">if</span> ((idx+<span class="number">1</span>) % <span class="number">100</span>) == <span class="number">0</span>:  <span class="comment"># flush plot picture per 1000 iters</span></span><br><span class="line">                    plot.flush()</span><br><span class="line">                plot.tick()</span><br><span class="line">                <span class="keyword">if</span> (idx+<span class="number">1</span>)%<span class="number">500</span>==<span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">print</span> (<span class="string">'images saving............'</span>)</span><br><span class="line">                    img = self.sess.run(self.G_img, feed_dict=feed)</span><br><span class="line">                    save_img.save_images(img, os.getcwd()+<span class="string">'/gen_picture/'</span>+<span class="string">'sample&#123;&#125;_&#123;&#125;.jpg'</span>\</span><br><span class="line">                                         .format(epoch, (idx+<span class="number">1</span>)/<span class="number">500</span>))</span><br><span class="line">                    <span class="keyword">print</span> <span class="string">'images save done'</span></span><br><span class="line">            test_acc = self.test()</span><br><span class="line">            plot.plot(<span class="string">'test acc'</span>, test_acc)</span><br><span class="line">            plot.flush()</span><br><span class="line">            plot.tick()</span><br><span class="line">            <span class="keyword">print</span> <span class="string">'test acc:&#123;&#125;'</span>.format(test_acc), <span class="string">'temp:%3f'</span>%(temp)</span><br><span class="line">            <span class="keyword">if</span> test_acc &gt; temp:</span><br><span class="line">                <span class="keyword">print</span> (<span class="string">'model saving..............'</span>)</span><br><span class="line">                path = os.getcwd() + <span class="string">'/model_saved'</span></span><br><span class="line">                save_path = os.path.join(path, <span class="string">"model.ckpt"</span>)</span><br><span class="line">                self.saver.save(self.sess, save_path=save_path)</span><br><span class="line">                <span class="keyword">print</span> (<span class="string">'model saved...............'</span>)</span><br><span class="line">                temp = test_acc</span><br><span class="line"></span><br><span class="line"><span class="comment"># output = conv2d('Z_cona&#123;&#125;'.format(i), output, 3, 64, stride=1, padding='SAME')</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">(self,name, noise, reuse)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(name,reuse=reuse):</span><br><span class="line">            l = self.batch_size</span><br><span class="line">            output = fc(<span class="string">'g_dc'</span>, noise, <span class="number">2</span>*<span class="number">2</span>*<span class="number">64</span>)</span><br><span class="line">            output = tf.reshape(output, [<span class="number">-1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">64</span>])</span><br><span class="line">            output = tf.nn.relu(self.bn(<span class="string">'g_bn1'</span>,output))</span><br><span class="line">            output = deconv2d(<span class="string">'g_dcon1'</span>,output,<span class="number">5</span>,outshape=[l, <span class="number">4</span>, <span class="number">4</span>, <span class="number">64</span>*<span class="number">4</span>])</span><br><span class="line">            output = tf.nn.relu(self.bn(<span class="string">'g_bn2'</span>,output))</span><br><span class="line"></span><br><span class="line">            output = deconv2d(<span class="string">'g_dcon2'</span>, output, <span class="number">5</span>, outshape=[l, <span class="number">8</span>, <span class="number">8</span>, <span class="number">64</span> * <span class="number">2</span>])</span><br><span class="line">            output = tf.nn.relu(self.bn(<span class="string">'g_bn3'</span>, output))</span><br><span class="line"></span><br><span class="line">            output = deconv2d(<span class="string">'g_dcon3'</span>, output, <span class="number">5</span>, outshape=[l, <span class="number">16</span>, <span class="number">16</span>,<span class="number">64</span> * <span class="number">1</span>])</span><br><span class="line">            output = tf.nn.relu(self.bn(<span class="string">'g_bn4'</span>, output))</span><br><span class="line"></span><br><span class="line">            output = deconv2d(<span class="string">'g_dcon4'</span>, output, <span class="number">5</span>, outshape=[l, <span class="number">32</span>, <span class="number">32</span>, self.dim])</span><br><span class="line">            output = tf.image.resize_images(output, (<span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">            <span class="comment"># output = tf.nn.relu(self.bn('g_bn4', output))</span></span><br><span class="line">            <span class="keyword">return</span> tf.nn.tanh(output)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">discriminator</span><span class="params">(self, name, inputs, reuse)</span>:</span></span><br><span class="line">        l = tf.shape(inputs)[<span class="number">0</span>]</span><br><span class="line">        inputs = tf.reshape(inputs, (l,self.img_size,self.img_size,self.dim))</span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(name,reuse=reuse):</span><br><span class="line">            out = []</span><br><span class="line">            output = conv2d(<span class="string">'d_con1'</span>,inputs,<span class="number">5</span>, <span class="number">64</span>, stride=<span class="number">2</span>, padding=<span class="string">'SAME'</span>) <span class="comment">#14*14</span></span><br><span class="line">            output1 = lrelu(self.bn(<span class="string">'d_bn1'</span>,output))</span><br><span class="line">            out.append(output1)</span><br><span class="line">            <span class="comment"># output1 = tf.contrib.keras.layers.GaussianNoise</span></span><br><span class="line">            output = conv2d(<span class="string">'d_con2'</span>, output1, <span class="number">3</span>, <span class="number">64</span>*<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="string">'SAME'</span>)<span class="comment">#7*7</span></span><br><span class="line">            output2 = lrelu(self.bn(<span class="string">'d_bn2'</span>, output))</span><br><span class="line">            out.append(output2)</span><br><span class="line">            output = conv2d(<span class="string">'d_con3'</span>, output2, <span class="number">3</span>, <span class="number">64</span>*<span class="number">4</span>, stride=<span class="number">1</span>, padding=<span class="string">'VALID'</span>)<span class="comment">#5*5</span></span><br><span class="line">            output3 = lrelu(self.bn(<span class="string">'d_bn3'</span>, output))</span><br><span class="line">            out.append(output3)</span><br><span class="line">            output = conv2d(<span class="string">'d_con4'</span>, output3, <span class="number">3</span>, <span class="number">64</span>*<span class="number">4</span>, stride=<span class="number">2</span>, padding=<span class="string">'VALID'</span>)<span class="comment">#2*2</span></span><br><span class="line">            output4 = lrelu(self.bn(<span class="string">'d_bn4'</span>, output))</span><br><span class="line">            out.append(output4)</span><br><span class="line">            output = tf.reshape(output4, [l, <span class="number">2</span>*<span class="number">2</span>*<span class="number">64</span>*<span class="number">4</span>])<span class="comment"># 2*2*64*4</span></span><br><span class="line">            output = fc(<span class="string">'d_fc'</span>, output, self.num_class)</span><br><span class="line">            <span class="comment"># output = tf.nn.softmax(output)</span></span><br><span class="line">            <span class="keyword">return</span> output, out</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bn</span><span class="params">(self, name, input)</span>:</span></span><br><span class="line">        val = tf.contrib.layers.batch_norm(input, decay=<span class="number">0.9</span>,</span><br><span class="line">                                           updates_collections=<span class="literal">None</span>,</span><br><span class="line">                                           epsilon=<span class="number">1e-5</span>,</span><br><span class="line">                                           scale=<span class="literal">True</span>,</span><br><span class="line">                                           is_training=<span class="literal">True</span>,</span><br><span class="line">                                           scope=name)</span><br><span class="line">        <span class="keyword">return</span> val</span><br><span class="line"></span><br><span class="line">    <span class="comment"># def get_loss(self, logits, layer_out):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(self)</span>:</span></span><br><span class="line">        count = <span class="number">0.</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">'testing................'</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>//self.batch_size):</span><br><span class="line">            testx, textl = mnist.test.next_batch(self.batch_size)</span><br><span class="line">            prediction = self.sess.run(self.prediction, feed_dict=&#123;self.x:testx, self.label:textl&#125;)</span><br><span class="line">            count += np.sum(prediction)</span><br><span class="line">        <span class="keyword">return</span> count/<span class="number">10000.</span></span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;<font color="red">args</font>是传进来的参数，主要包括三个，</p>
<ul>
<li>一个是<strong><em>args.model</em></strong>，选择DCGAN模式还是WGAN-GP模式，二者的不同主要在于损失函数不同和优化器的学习率不同，其他都一样。</li>
<li>第二个参数是<strong><em>args.trainable</em></strong>，训练还是测试，训练时为True，测试是False。</li>
<li><strong><em>Loadmodel</em></strong>表示是否选择加载训练好的权重。 </li>
</ul>
<p>&emsp;&emsp;Build_model函数里面主要包括了网络训练前的准备工作，主要包括损失函数的设计和优化器的设计。下文将详细做出介绍，尤其是损失函数部分。<br>&emsp;&emsp;首先，建立了五个placeholder，flag表示两个标志位，只有0-1两种情况，注意到我num_class是11，也就是做11分类，但是lable的placeholder中shape是(batchsize,10)。为了方便，我将生成器的生成结果和真实数据X级联在一起作为判别器的输入，输出再把他它们结果split分开。<br>&emsp;&emsp;d_regular 表示正则化，这里我将判别器中所有的weights做了l2正则。<br>&emsp;&emsp;监督学习的损失函数使用常见的交叉熵损失函数，对生成器生成的图像的label的one_hot型为：<br>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]<br>&emsp;&emsp;将原始的label扩展到(batchsize，11)后再和生成器生成的假数据的label在第一维度concat到一起得到batchl，另外乘以0.9，做单边标签平滑（one side smoothing），由此计算得到监督学习的损失函数值s_l,。 </p>
<h2 id="生成器G的损失函数"><a href="#生成器G的损失函数" class="headerlink" title="生成器G的损失函数"></a>生成器G的损失函数</h2><p>&emsp;&emsp;生成器G的损失函数包括两部分，一个是来自GAN训练的部分，另外一个是feature matching , 论文中提到的feature matching意思是<font color="blue">特征匹配</font>，主要思想是希望生成器生成的假数据输入到判别器，经过判别器每一层计算的结果和将真实数据X输入到判别器，判别器每一层的结果尽可能的相似，公式如下： </p>
<script type="math/tex; mode=display">\|E_{x\sim Pdata(x)}f(x) - E_{z\sim Pz(z)}f(G(z))\|^2_2</script><p>&emsp;&emsp;其中\(f(x)\)是D的每一层的输出。Feature matching 是指导G进行训练，所以我将他放在了G的损失函数里。</p>
<h2 id="分类器D的损失函数："><a href="#分类器D的损失函数：" class="headerlink" title="分类器D的损失函数："></a>分类器D的损失函数：</h2><p>相比较G的损失函数，D的损失函数就比较麻烦了<br>接下来介绍无监督学习的损失函数实现：<br>在前面介绍的无监督学习的损失函数中，有一部分和GAN的损失函数很相似，所以在代码中我们使用了<br><img src="/images/手把手教你用GAN实现半监督学习/png1-2.png" alt><br>&emsp;&emsp;无监督学习的时候没有标签的指导，此时判别器或者称为分类器D无法正确对输入进行分类，此时只要求D能够区分真假就可以了，由此我们得到了无监督学习的损失un_s，直观上也很好理解，假设输入给判别器D真图像，它结果经过<em>softmax</em>后输出类似下面表格的形式，其中前十个黄色区域表示对0-9的分类概率，最后一个灰色的表示对假图像的分类概率，由于无监督学习中判别器D并不知道具体是哪一类数据，所以干脆D的损失函数最小化输出假图像的概率就可以了，当输入为生成器生成的假图像时，只要最小化D输出为真图像的概率，由此我们得到了un_s.。但是此时有一个问题，即是有监督学习的时候不就没有用了吗，因为这时候应该使用s_l.为了解决这个问题，我使用了一个标志位flag作为控制他们之间的使用，具体代码： </p>
<script type="math/tex; mode=display">flag*s\_i + (1-flag)*un\_s</script><p>&emsp;&emsp;有标签的时候flag是1，表示使用s_l,无监督的时候flag是0，表示使用无监督损失函数。此时已经完成了判别器D损失函数的一部分设计，剩下的一部分和GAN中的D的损失一样，在代码中我给出了两种损失函数，一个是原始GAN的交叉熵损失函数，和DCGAN使用的一样，另外一个是improved wgan论文中使用的损失函数，但是在做了对比之后，我强烈建议使用DCGAN来做，improved wgan的损失函数虽然在生成结果的优化上有很大帮助，但是并不适合半监督学习中。 </p>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>接下来就是训练部分：<br>&emsp;&emsp;此时可能有一个疑问，我们是如何实现只使用200带标签的数据训练的，答案就在flag这个标志位里，在训练部分代码中，当迭代次数小于200的时候，flag=1, 此时表示使用s_l作为损失函数的一部分，当flag=0的时候，un_s起作用而s_l并没有起作用，这时，即使我们feed了正确的标签数据，但是s_l不起作用，就相当于没有使用标签。<br>&emsp;&emsp;flag的作用本来是使用他控制feature matching是否工作的，因为这部分损失相当的大，后来发现影响不大，暂时就放在这里了。 </p>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(self)</span>:</span></span><br><span class="line">       count = <span class="number">0.</span></span><br><span class="line">       <span class="keyword">print</span> <span class="string">'testing................'</span></span><br><span class="line">       <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>//self.batch_size):</span><br><span class="line">           testx, textl = mnist.test.next_batch(self.batch_size)</span><br><span class="line">           prediction = self.sess.run(self.prediction, feed_dict=&#123;self.x:testx, self.label:textl&#125;)</span><br><span class="line">           count += np.sum(prediction)</span><br><span class="line">       <span class="keyword">return</span> count/<span class="number">10000.</span></span><br></pre></td></tr></table></figure>
<h2 id="测试精度结果变化图"><a href="#测试精度结果变化图" class="headerlink" title="测试精度结果变化图"></a>测试精度结果变化图</h2><p><img src="/images/手把手教你用GAN实现半监督学习/jpg1-1.jpg" alt></p>
<h1 id="本文实验代码"><a href="#本文实验代码" class="headerlink" title="本文实验代码"></a>本文实验代码</h1><p>使用GAN实现半监督学习代码<a href="https://github.com/LDOUBLEV/semi-supervised-GAN" target="_blank" rel="noopener">https://github.com/LDOUBLEV/semi-supervised-GAN</a><br>如果感觉有用的话，欢迎star， fork</p>
<h1 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h1><p>&emsp;&emsp;详细代码请以github中为准，另关于结果不理想的问题，可能和之前做的迁移学习有关，下面是最近跑出来的结果，最好的精度是0.95，这个问题有时间会慢慢解决。另：链接中的模型精度是很高的，可以直接调用<br><img src="/images/手把手教你用GAN实现半监督学习/png1-3.png" alt></p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://blog.csdn.net/qq_25737169/article/details/78532719" target="_blank" rel="noopener">手把手教你用GAN实现半监督学习</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/xun-lian-tensorflow-shi-bie-shou-xie-shu-zi.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/xun-lian-tensorflow-shi-bie-shou-xie-shu-zi.html" class="post-title-link" itemprop="url">训练TensorFlow识别手写数字</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-07 08:02:53 / 修改时间：09:28:07" itemprop="dateCreated datePublished" datetime="2019-05-07T08:02:53+08:00">2019-05-07</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">14k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">12 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="TensorFlowSharp安装和使用入门"><a href="#TensorFlowSharp安装和使用入门" class="headerlink" title="TensorFlowSharp安装和使用入门"></a>TensorFlowSharp安装和使用入门</h1><p>(<font color="red">posted @ 2017-11-25 21:31</font>)<br>Tensorflow是一个人工智能框架。TensorflowSharp是对Tensorflow C语言版接口的封装，便于C#开发人员在项目中使用Tensorflow。</p>
<h2 id="一、使用方法"><a href="#一、使用方法" class="headerlink" title="一、使用方法"></a>一、使用方法</h2><p>TensorflowSharp的使用很简单，首先使用NuGet安装TensorflowSharp包，然后新建C#控制台程序，输入下面代码，运行即可。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">// 创建图</span><br><span class="line">var g = new TFGraph();</span><br><span class="line"></span><br><span class="line">// 定义常量</span><br><span class="line">var a = g.Const(<span class="number">2</span>);</span><br><span class="line">var b = g.Const(<span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">// 加法和乘法运算</span><br><span class="line">var add = g.Add(a, b);</span><br><span class="line">var mul = g.Mul(a, b);</span><br><span class="line"></span><br><span class="line">// 创建会话</span><br><span class="line">var sess = new TFSession(g);</span><br><span class="line"></span><br><span class="line">// 计算加法</span><br><span class="line">var result1 = sess.GetRunner().Run(add).GetValue();</span><br><span class="line">Console.WriteLine(<span class="string">"a+b=&#123;0&#125;"</span>, result1);</span><br><span class="line"></span><br><span class="line">// 计算乘法</span><br><span class="line">var result2 = sess.GetRunner().Run(mul).GetValue();</span><br><span class="line">Console.WriteLine(<span class="string">"a*b=&#123;0&#125;"</span>, result2);</span><br><span class="line"></span><br><span class="line">// 关闭会话</span><br><span class="line">sess.CloseSession();</span><br></pre></td></tr></table></figure></p>
<p>运行后输出结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a+b=<span class="number">5</span></span><br><span class="line">a*b=<span class="number">6</span></span><br></pre></td></tr></table></figure></p>
<h2 id="二、注意事项"><a href="#二、注意事项" class="headerlink" title="二、注意事项"></a>二、注意事项</h2><ol>
<li>国内目前无法访问Tensorflow官网，但是可以访问谷歌提供的Tensorflow官网镜像。</li>
<li>国内使用NuGet安装TensorflowSharp很容易失败，可以直接从Nuget官网下载，然后改后缀名zip，解压后手工安装。</li>
<li>TensorflowSharp项目使用的.net版本必须高于4.6.1，本教程使用的版本是4.7.0，可以在属性选项卡中设置。</li>
<li>TensorflowSharp项目必须使用64位CPU，需要在属性选项卡生成中，去掉首选32位的勾选。</li>
<li>手动安装TensorflowSharp，处理要引用TensorFlowSharp.dll，还要将libtensorflow.dll复制到每个项目的输出目录。</li>
</ol>
<h2 id="三、相关网站"><a href="#三、相关网站" class="headerlink" title="三、相关网站"></a>三、相关网站</h2><p>Tensorflow教程：<a href="https://github.com/tengge1/learn-tensorflow-sharp" target="_blank" rel="noopener">https://github.com/tengge1/learn-tensorflow-sharp</a><br>Tensorflow官网：<a href="http://www.tensorflow.org" target="_blank" rel="noopener">http://www.tensorflow.org</a><br>Google Tensorflow镜像：<a href="https://tensorflow.google.cn/" target="_blank" rel="noopener">https://tensorflow.google.cn/</a><br>Tensorflow开源项目：<a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow</a><br>TensorflowSharp开源项目：<a href="https://github.com/migueldeicaza/TensorFlowSharp" target="_blank" rel="noopener">https://github.com/migueldeicaza/TensorFlowSharp</a><br>TensorflowSharp NuGet主页：<a href="https://www.nuget.org/packages/TensorFlowSharp/" target="_blank" rel="noopener">https://www.nuget.org/packages/TensorFlowSharp/</a><br>Tensorflow中文社区：<a href="http://www.tensorfly.cn/" target="_blank" rel="noopener">http://www.tensorfly.cn/</a></p>
<h1 id="03-使用TensorFlow做计算题"><a href="#03-使用TensorFlow做计算题" class="headerlink" title="03 使用TensorFlow做计算题"></a>03 使用TensorFlow做计算题</h1><p>我们使用Tensorflow，计算<code>((a+b)*c)^2/a</code>，然后求平方根。看代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入储存容器</span></span><br><span class="line">a = tf.placeholder(tf.float16)</span><br><span class="line">b = tf.placeholder(tf.float16)</span><br><span class="line">c = tf.placeholder(tf.float16)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算</span></span><br><span class="line">d = tf.add(a, b) <span class="comment">#加法</span></span><br><span class="line">e = tf.multiply(d, c) <span class="comment">#乘法</span></span><br><span class="line">f = tf.pow(e, <span class="number">2</span>) <span class="comment">#平方</span></span><br><span class="line">g = tf.divide(f, a) <span class="comment">#除法</span></span><br><span class="line">h = tf.sqrt(g) <span class="comment">#平方根</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 会话</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 赋值</span></span><br><span class="line">feed_dict= &#123;a:<span class="number">1</span>, b:<span class="number">2</span>, c:<span class="number">3</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算</span></span><br><span class="line">result = sess.run(h, feed_dict= feed_dict)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭会话</span></span><br><span class="line">sess.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure></p>
<p>这里让a=1，b=2，c=3，如果输出9.0，证明运行成功。<br>Tensorflow做计算的方法是，先把计算的式子构建一个图，然后把这个图和赋值在cpu上一起运行，计算速度比较快。</p>
<h1 id="04-TensorFlow中的常量、变量和数据类型"><a href="#04-TensorFlow中的常量、变量和数据类型" class="headerlink" title="04 TensorFlow中的常量、变量和数据类型"></a>04 TensorFlow中的常量、变量和数据类型</h1><p>打开Python Shell，先输入<code>import tensorflow as tf</code>，然后可以执行以下命令。<br>Tensorflow中的常量创建方法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hello = tf.constant(<span class="string">'Hello,world!'</span>, dtype=tf.string)</span><br></pre></td></tr></table></figure></p>
<p>其中，’Hello,world!’是常量初始值；tf.string是常量类型，可以省略。常量和变量都可以去构建Tensorflow中的图。</p>
<p>Tensorflow中变量的创建方法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = tf.Variable(<span class="number">10</span>, dtype=tf.int32)</span><br></pre></td></tr></table></figure></p>
<p>其中，10是变量初始值，tf.int32是变量的类型。<br>Tensorflow中，主要有以下几种数据类型。<br>tf.int8：8位整数。<br>tf.int16：16位整数。<br>tf.int32：32位整数。<br>tf.int64：64位整数。</p>
<p>tf.uint8：8位无符号整数。<br>tf.uint16：16位无符号整数。</p>
<p>tf.float16：16位浮点数。<br>tf.float32：32位浮点数。<br>tf.float64：64位浮点数。<br>tf.double：等同于tf.float64。</p>
<p>tf.string：字符串。</p>
<p>tf.bool：布尔型。</p>
<p>tf.complex64：64位复数。<br>tf.complex128：128位复数。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="http://wiki.jikexueyuan.com/project/tensorflow-zh/resources/dims_types.html" target="_blank" rel="noopener">《张量的阶、形状、数据类型》</a></li>
</ul>
<h1 id="05-TensorFlow中变量的初始化"><a href="#05-TensorFlow中变量的初始化" class="headerlink" title="05 TensorFlow中变量的初始化"></a>05 TensorFlow中变量的初始化</h1><p>打开Python Shell，输入<strong>import tensorflow as tf</strong>，然后可以执行以下代码。<br>1、创建一个<code>2*3</code>的矩阵，并让所有元素的值为0.（类型为tf.float）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = tf.zeros([<span class="number">2</span>,<span class="number">3</span>], dtype = tf.float32)</span><br></pre></td></tr></table></figure></p>
<p>2、创建一个<code>3*4</code>的矩阵，并让所有元素的值为1.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b = tf.ones([<span class="number">3</span>,<span class="number">4</span>])</span><br></pre></td></tr></table></figure></p>
<p>3、创建一个<code>1*10</code>的矩阵，使用2来填充。（类型为tf.int32，可忽略）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c = tf.constant(<span class="number">2</span>, dtype=tf.int32, shape=[<span class="number">1</span>,<span class="number">10</span>])</span><br></pre></td></tr></table></figure></p>
<p>4、创建一个<code>1*10</code>的矩阵，其中的元素符合正态分布，平均值是20，标准偏差是3.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d = tf.random_normal([<span class="number">1</span>,<span class="number">10</span>],mean = <span class="number">20</span>, stddev = <span class="number">3</span>)</span><br></pre></td></tr></table></figure></p>
<p>上面所有的值都可以用来初始化变量。例如用0.01来填充一个<code>1*2</code>的矩阵来初始化一个叫bias的变量。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bias = tf.Variable(tf.zeros([<span class="number">1</span>,<span class="number">2</span>]) + <span class="number">0.01</span>)</span><br></pre></td></tr></table></figure></p>
<p>如果你想查看这些量具体的值，可以在Session中执行它并输出。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sess = tf.Session()</span><br><span class="line">print(sess.run(d))</span><br></pre></td></tr></table></figure></p>
<p>这里，我得到了以下的值：<br>[[ 22.44503784  18.19544983  17.89671898  17.67314911  19.45074844<br>   18.6805439   18.56541443  16.59041977  22.11240005  19.12819099]]。它就是上面4我们创建的量的值。</p>
<h1 id="参考文献-1"><a href="#参考文献-1" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="http://blog.sina.com.cn/s/blog_8b2a28790102wnkh.html" target="_blank" rel="noopener">《Tensorflow学习笔记（3）》</a></li>
</ul>
<h1 id="06-使用TensorFlow拟合x与y之间的关系"><a href="#06-使用TensorFlow拟合x与y之间的关系" class="headerlink" title="06 使用TensorFlow拟合x与y之间的关系"></a>06 使用TensorFlow拟合x与y之间的关系</h1><p>看代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#构造输入数据（我们用神经网络拟合x_data和y_data之间的关系）</span></span><br><span class="line">x_data = np.linspace(<span class="number">-1</span>,<span class="number">1</span>,<span class="number">300</span>)[:, np.newaxis] <span class="comment">#-1到1等分300份形成的二维矩阵</span></span><br><span class="line">noise = np.random.normal(<span class="number">0</span>,<span class="number">0.05</span>, x_data.shape) <span class="comment">#噪音，形状同x_data在0-0.05符合正态分布的小数</span></span><br><span class="line">y_data = np.square(x_data)<span class="number">-0.5</span>+noise <span class="comment">#x_data平方，减0.05，再加噪音值</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#输入层（1个神经元）</span></span><br><span class="line">xs = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>]) <span class="comment">#占位符，None表示n*1维矩阵，其中n不确定</span></span><br><span class="line">ys = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>]) <span class="comment">#占位符，None表示n*1维矩阵，其中n不确定</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#隐层（10个神经元）</span></span><br><span class="line">W1 = tf.Variable(tf.random_normal([<span class="number">1</span>,<span class="number">10</span>])) <span class="comment">#权重，1*10的矩阵，并用符合正态分布的随机数填充</span></span><br><span class="line">b1 = tf.Variable(tf.zeros([<span class="number">1</span>,<span class="number">10</span>])+<span class="number">0.1</span>) <span class="comment">#偏置，1*10的矩阵，使用0.1填充</span></span><br><span class="line">Wx_plus_b1 = tf.matmul(xs,W1) + b1 <span class="comment">#矩阵xs和W1相乘，然后加上偏置</span></span><br><span class="line">output1 = tf.nn.relu(Wx_plus_b1) <span class="comment">#激活函数使用tf.nn.relu</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#输出层（1个神经元）</span></span><br><span class="line">W2 = tf.Variable(tf.random_normal([<span class="number">10</span>,<span class="number">1</span>]))</span><br><span class="line">b2 = tf.Variable(tf.zeros([<span class="number">1</span>,<span class="number">1</span>])+<span class="number">0.1</span>)</span><br><span class="line">Wx_plus_b2 = tf.matmul(output1,W2) + b2</span><br><span class="line">output2 = Wx_plus_b2</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失</span></span><br><span class="line">loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-output2),reduction_indices=[<span class="number">1</span>])) <span class="comment">#在第一维上，偏差平方后求和，再求平均值，来计算损失</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss) <span class="comment"># 使用梯度下降法，设置步长0.1，来最小化损失</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化</span></span><br><span class="line">init = tf.global_variables_initializer() <span class="comment">#初始化所有变量</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init) <span class="comment">#变量初始化</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#训练</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>): <span class="comment">#训练1000次</span></span><br><span class="line">    _,loss_value = sess.run([train_step,loss],feed_dict=&#123;xs:x_data,ys:y_data&#125;) <span class="comment">#进行梯度下降运算，并计算每一步的损失</span></span><br><span class="line">    <span class="keyword">if</span>(i%<span class="number">50</span>==<span class="number">0</span>):</span><br><span class="line">        print(loss_value) <span class="comment"># 每50步输出一次损失</span></span><br></pre></td></tr></table></figure></p>
<p>输出：<br>0.405348<br>0.00954485<br>0.0068925<br>0.00551958<br>0.00471453<br>0.00425206<br>0.00400382<br>0.00381883<br>0.00367445<br>0.00353349<br>0.00341325<br>0.00330487<br>0.00321128<br>0.00313468<br>0.0030646<br>0.0030014<br>0.00294802<br>0.00290179<br>0.0028618<br>0.00282344<br>可以看到，随机训练的进行，损失越来越小，证明拟合越来越好。</p>
<h1 id="参考文献-2"><a href="#参考文献-2" class="headerlink" title="参考文献"></a>参考文献</h1><ol>
<li><a href="http://blog.csdn.net/jerry81333/article/details/53004903" target="_blank" rel="noopener">《Tensorflow 自带可视化Tensorboard使用方法 附项目代码》</a></li>
<li><a href="http://blog.csdn.net/qq_32166627/article/details/52734387" target="_blank" rel="noopener">《tensorflow学习（六）：tensorflow中的tf.reduce_mean()这类函数》</a></li>
</ol>
<h1 id="07-训练TensorFlow识别手写数字"><a href="#07-训练TensorFlow识别手写数字" class="headerlink" title="07 训练TensorFlow识别手写数字"></a>07 训练TensorFlow识别手写数字</h1><p>打开Python Shell，输入以下代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取数据（如果存在就读取，不存在就下载完再读取）</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data/"</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入</span></span><br><span class="line">x = tf.placeholder(<span class="string">"float"</span>, [<span class="literal">None</span>, <span class="number">784</span>]) <span class="comment">#输入占位符（每张手写数字784个像素点）</span></span><br><span class="line">y_ = tf.placeholder(<span class="string">"float"</span>, [<span class="literal">None</span>,<span class="number">10</span>]) <span class="comment">#输入占位符（这张手写数字具体代表的值，0-9对应矩阵的10个位置）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算分类softmax会将xW+b分成10类，对应0-9</span></span><br><span class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>,<span class="number">10</span>])) <span class="comment">#权重</span></span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>])) <span class="comment">#偏置</span></span><br><span class="line">y = tf.nn.softmax(tf.matmul(x,W) + b) <span class="comment"># 输入矩阵x与权重矩阵W相乘，加上偏置矩阵b，然后求softmax（sigmoid函数升级版，可以分成多类）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算偏差和</span></span><br><span class="line">cross_entropy = -tf.reduce_sum(y_*tf.log(y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用梯度下降法（步长0.01），来使偏差和最小</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化变量</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>): <span class="comment"># 训练10次</span></span><br><span class="line">  batch_xs, batch_ys = mnist.train.next_batch(<span class="number">100</span>) <span class="comment"># 随机取100个手写数字图片</span></span><br><span class="line">  sess.run(train_step, feed_dict=&#123;x: batch_xs, y_: batch_ys&#125;) <span class="comment"># 执行梯度下降算法，输入值x：batch_xs，输入值y：batch_ys</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算训练精度</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y,<span class="number">1</span>), tf.argmax(y_,<span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</span><br><span class="line">print(sess.run(accuracy, feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels&#125;)) <span class="comment">#运行精度图，x和y_从测试手写图片中取值</span></span><br></pre></td></tr></table></figure></p>
<p>执行该段代码，输出0.8002。训练10次得到80.02%的识别准确度，还是可以的。<br>说明：由于网络原因，手写数字图片可能无法下载，可以直接下载本人做好的程序，里面已经包含了手写图片资源和py脚本。(链接已失效)</p>
<h1 id="参考文献-3"><a href="#参考文献-3" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://www.cnblogs.com/tengge/p/6363586.html" target="_blank" rel="noopener">07 训练TensorFlow识别手写数字</a></li>
<li><a href="http://www.tensorfly.cn/tfdoc/tutorials/mnist_beginners.html" target="_blank" rel="noopener">《面向机器学习初学者的 MNIST 初级教程》</a></li>
</ul>
<h1 id="10-TensorFlow中模型保存与读取"><a href="#10-TensorFlow中模型保存与读取" class="headerlink" title="10 TensorFlow中模型保存与读取"></a>10 TensorFlow中模型保存与读取</h1><p>我们的模型训练出来想给别人用，或者是我今天训练不完，明天想接着训练，怎么办？这就需要模型的保存与读取。看代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment">#输入数据</span></span><br><span class="line">x_data = np.linspace(<span class="number">-1</span>,<span class="number">1</span>,<span class="number">300</span>)[:, np.newaxis]</span><br><span class="line">noise = np.random.normal(<span class="number">0</span>,<span class="number">0.05</span>, x_data.shape)</span><br><span class="line">y_data = np.square(x_data)<span class="number">-0.5</span>+noise</span><br><span class="line"></span><br><span class="line"><span class="comment">#输入层</span></span><br><span class="line">xs = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>])</span><br><span class="line">ys = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#隐层</span></span><br><span class="line">W1 = tf.Variable(tf.random_normal([<span class="number">1</span>,<span class="number">10</span>]))</span><br><span class="line">b1 = tf.Variable(tf.zeros([<span class="number">1</span>,<span class="number">10</span>])+<span class="number">0.1</span>)</span><br><span class="line">Wx_plus_b1 = tf.matmul(xs,W1) + b1</span><br><span class="line">output1 = tf.nn.relu(Wx_plus_b1)</span><br><span class="line"></span><br><span class="line"><span class="comment">#输出层</span></span><br><span class="line">W2 = tf.Variable(tf.random_normal([<span class="number">10</span>,<span class="number">1</span>]))</span><br><span class="line">b2 = tf.Variable(tf.zeros([<span class="number">1</span>,<span class="number">1</span>])+<span class="number">0.1</span>)</span><br><span class="line">Wx_plus_b2 = tf.matmul(output1,W2) + b2</span><br><span class="line">output2 = Wx_plus_b2</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失</span></span><br><span class="line">loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-output2),reduction_indices=[<span class="number">1</span>]))</span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">#模型保存加载工具</span></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"><span class="comment">#判断模型保存路径是否存在，不存在就创建</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">'tmp/'</span>):</span><br><span class="line">    os.mkdir(<span class="string">'tmp/'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line"><span class="keyword">if</span> os.path.exists(<span class="string">'tmp/checkpoint'</span>): <span class="comment">#判断模型是否存在</span></span><br><span class="line">    saver.restore(sess, <span class="string">'tmp/model.ckpt'</span>) <span class="comment">#存在就从模型中恢复变量</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    init = tf.global_variables_initializer() <span class="comment">#不存在就初始化变量</span></span><br><span class="line">    sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    _,loss_value = sess.run([train_step,loss], feed_dict=&#123;xs:x_data,ys:y_data&#125;)</span><br><span class="line">    <span class="keyword">if</span>(i%<span class="number">50</span>==<span class="number">0</span>): <span class="comment">#每50次保存一次模型</span></span><br><span class="line">        save_path = saver.save(sess, <span class="string">'tmp/model.ckpt'</span>) <span class="comment">#保存模型到tmp/model.ckpt，注意一定要有一层文件夹，否则保存不成功！！！</span></span><br><span class="line">        print(<span class="string">"模型保存：%s 当前训练损失：%s"</span>%(save_path, loss_value))</span><br></pre></td></tr></table></figure></p>
<p>大家第一次训练得到：</p>
<p>模型保存：tmp/model.ckpt 当前训练损失：1.35421<br>模型保存：tmp/model.ckpt 当前训练损失：0.011808<br>模型保存：tmp/model.ckpt 当前训练损失：0.00916655<br>模型保存：tmp/model.ckpt 当前训练损失：0.00690887<br>模型保存：tmp/model.ckpt 当前训练损失：0.00575491<br>模型保存：tmp/model.ckpt 当前训练损失：0.00526401<br>模型保存：tmp/model.ckpt 当前训练损失：0.00498503<br>模型保存：tmp/model.ckpt 当前训练损失：0.00478226<br>模型保存：tmp/model.ckpt 当前训练损失：0.0046346<br>模型保存：tmp/model.ckpt 当前训练损失：0.00454276<br>模型保存：tmp/model.ckpt 当前训练损失：0.00446402<br>模型保存：tmp/model.ckpt 当前训练损失：0.00436883<br>模型保存：tmp/model.ckpt 当前训练损失：0.00427732<br>模型保存：tmp/model.ckpt 当前训练损失：0.00418589<br>模型保存：tmp/model.ckpt 当前训练损失：0.00409241<br>模型保存：tmp/model.ckpt 当前训练损失：0.00400956<br>模型保存：tmp/model.ckpt 当前训练损失：0.00392799<br>模型保存：tmp/model.ckpt 当前训练损失：0.00383506<br>模型保存：tmp/model.ckpt 当前训练损失：0.00373741<br>模型保存：tmp/model.ckpt 当前训练损失：0.00366922</p>
<pre><code>第二次继续训练，得到：
</code></pre><p>模型保存：tmp/model.ckpt 当前训练损失：0.00412003<br>模型保存：tmp/model.ckpt 当前训练损失：0.00388735<br>模型保存：tmp/model.ckpt 当前训练损失：0.00382827<br>模型保存：tmp/model.ckpt 当前训练损失：0.00379988<br>模型保存：tmp/model.ckpt 当前训练损失：0.00378107<br>模型保存：tmp/model.ckpt 当前训练损失：0.003764<br>模型保存：tmp/model.ckpt 当前训练损失：0.00375149<br>模型保存：tmp/model.ckpt 当前训练损失：0.00374324<br>模型保存：tmp/model.ckpt 当前训练损失：0.00373386<br>模型保存：tmp/model.ckpt 当前训练损失：0.00372364<br>模型保存：tmp/model.ckpt 当前训练损失：0.00371543<br>模型保存：tmp/model.ckpt 当前训练损失：0.00370875<br>模型保存：tmp/model.ckpt 当前训练损失：0.00370262<br>模型保存：tmp/model.ckpt 当前训练损失：0.00369697<br>模型保存：tmp/model.ckpt 当前训练损失：0.00369161<br>模型保存：tmp/model.ckpt 当前训练损失：0.00368653<br>模型保存：tmp/model.ckpt 当前训练损失：0.00368169<br>模型保存：tmp/model.ckpt 当前训练损失：0.00367714<br>模型保存：tmp/model.ckpt 当前训练损失：0.00367274<br>模型保存：tmp/model.ckpt 当前训练损失：0.00366843<br>可以看到，第二次训练是在第一次训练的基础上继续训练的。于是，我们可以把我们想要的模型保存下来，慢慢训练。</p>
<h1 id="参考文献-4"><a href="#参考文献-4" class="headerlink" title="参考文献"></a>参考文献</h1><ol>
<li>《TensorFlow使用指南》：<a href="http://www.tensorfly.cn/tfdoc/tutorials/mnist_tf.html" target="_blank" rel="noopener">http://www.tensorfly.cn/tfdoc/tutorials/mnist_tf.html</a></li>
<li>TensorFlow中模型保存与读取：<a href="https://www.cnblogs.com/tengge/p/6379893.html" target="_blank" rel="noopener">https://www.cnblogs.com/tengge/p/6379893.html</a></li>
</ol>
<h1 id="11-使用TensorBoard显示图片"><a href="#11-使用TensorBoard显示图片" class="headerlink" title="11 使用TensorBoard显示图片"></a>11 使用TensorBoard显示图片</h1><p>首先，下载一张png格式的图片（注意：只支持png格式），命名为1.png。然后，打开PythonShell，输入以下代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取图片数据</span></span><br><span class="line">file = open(<span class="string">'1.png'</span>, <span class="string">'rb'</span>)</span><br><span class="line">data = file.read()</span><br><span class="line">file.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图片处理</span></span><br><span class="line">image = tf.image.decode_png(data, channels=<span class="number">4</span>)</span><br><span class="line">image = tf.expand_dims(image, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加到日志中</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">writer = tf.summary.FileWriter(<span class="string">'logs'</span>)</span><br><span class="line">summary_op = tf.summary.image(<span class="string">"image1"</span>, image)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行并写入日志</span></span><br><span class="line">summary = sess.run(summary_op)</span><br><span class="line">writer.add_summary(summary)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭</span></span><br><span class="line">writer.close()</span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;然后，在相同目录打开cmd，输入<strong>tensorboard —logdir=logs</strong>，然后打开浏览器输入<code>http://localhost:6006/</code>。在Tensorboard的Images标签页，就可以看到我们的png图片了。<br><img src="/images/训练TensorFlow识别手写数字/tensorboard.png" alt></p>
<h2 id="参考文献-5"><a href="#参考文献-5" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li><a href="https://www.cnblogs.com/tengge/p/6390148.html" target="_blank" rel="noopener">11 使用TensorBoard显示图片</a></li>
</ul>
<h1 id="12-使用卷积神经网络识别手写数字"><a href="#12-使用卷积神经网络识别手写数字" class="headerlink" title="12 使用卷积神经网络识别手写数字"></a>12 使用卷积神经网络识别手写数字</h1><p>看代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载训练和测试数据</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST_data/'</span>, one_hot = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建session</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 占位符</span></span><br><span class="line">x = tf.placeholder(tf.float32, shape=[<span class="literal">None</span>, <span class="number">784</span>]) <span class="comment"># 每张图片28*28，共784个像素</span></span><br><span class="line">y_ = tf.placeholder(tf.float32, shape=[<span class="literal">None</span>, <span class="number">10</span>]) <span class="comment"># 输出为0-9共10个数字，其实就是把图片分为10类</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 权重初始化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">    initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>) <span class="comment"># 使用截尾正态分布的随机数初始化权重，标准偏差是0.1（噪音）</span></span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">    initial = tf.constant(<span class="number">0.1</span>, shape = shape) <span class="comment"># 使用一个小正数初始化偏置，避免出现偏置总为0的情况</span></span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 卷积和集合</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, W)</span>:</span> <span class="comment"># 计算2d卷积</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.conv2d(x, W, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span><span class="params">(x)</span>:</span> <span class="comment"># 计算最大集合</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一层卷积</span></span><br><span class="line">W_conv1 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>]) <span class="comment"># 为每个5*5小块计算32个特征</span></span><br><span class="line">b_conv1 = bias_variable([<span class="number">32</span>])</span><br><span class="line"></span><br><span class="line">x_image = tf.reshape(x, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>]) <span class="comment"># 将图片像素转换为4维tensor，其中二三维是宽高，第四维是像素</span></span><br><span class="line">h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)</span><br><span class="line">h_pool1 = max_pool_2x2(h_conv1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二层卷积</span></span><br><span class="line">W_conv2 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">64</span>])</span><br><span class="line">b_conv2 = bias_variable([<span class="number">64</span>])</span><br><span class="line"></span><br><span class="line">h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)</span><br><span class="line">h_pool2 = max_pool_2x2(h_conv2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 密集层</span></span><br><span class="line">W_fc1 = weight_variable([<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>, <span class="number">1024</span>]) <span class="comment"># 创建1024个神经元对整个图片进行处理</span></span><br><span class="line">b_fc1 = bias_variable([<span class="number">1024</span>])</span><br><span class="line"></span><br><span class="line">h_pool2_flat = tf.reshape(h_pool2, [<span class="number">-1</span>, <span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>])</span><br><span class="line">h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 退出（为了减少过度拟合，在读取层前面加退出层，仅训练时有效）</span></span><br><span class="line">keep_prob = tf.placeholder(tf.float32)</span><br><span class="line">h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取层（最后我们加一个像softmax表达式那样的层）</span></span><br><span class="line">W_fc2 = weight_variable([<span class="number">1024</span>, <span class="number">10</span>])</span><br><span class="line">b_fc2 = bias_variable([<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测类和损失函数</span></span><br><span class="line">cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv)) <span class="comment"># 计算偏差平均值</span></span><br><span class="line">train_step = tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(cross_entropy) <span class="comment"># 每一步训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y_conv,<span class="number">1</span>), tf.argmax(y_,<span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    batch = mnist.train.next_batch(<span class="number">50</span>)</span><br><span class="line">    <span class="keyword">if</span> i%<span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        train_accuracy = accuracy.eval(feed_dict=&#123; x:batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>], keep_prob: <span class="number">1.0</span>&#125;, session = sess) <span class="comment"># 每10次训练计算一次精度</span></span><br><span class="line">        print(<span class="string">"步数 %d, 精度 %g"</span>%(i, train_accuracy))</span><br><span class="line">    train_step.run(feed_dict=&#123;x: batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>], keep_prob: <span class="number">0.5</span>&#125;, session = sess)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭</span></span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure></p>
<p>执行上面的代码后输出：</p>
<p>Extracting MNIST_data/train-images-idx3-ubyte.gz<br>Extracting MNIST_data/train-labels-idx1-ubyte.gz<br>Extracting MNIST_data/t10k-images-idx3-ubyte.gz<br>Extracting MNIST_data/t10k-labels-idx1-ubyte.gz<br>步数 0, 精度 0.12<br>步数 10, 精度 0.34<br>步数 20, 精度 0.52<br>步数 30, 精度 0.56<br>步数 40, 精度 0.6<br>步数 50, 精度 0.74<br>步数 60, 精度 0.74<br>步数 70, 精度 0.78<br>步数 80, 精度 0.82</p>
<p>……….</p>
<p>步数 900, 精度 0.96<br>步数 910, 精度 0.98<br>步数 920, 精度 0.96<br>步数 930, 精度 0.98<br>步数 940, 精度 0.98<br>步数 950, 精度 0.9<br>步数 960, 精度 0.98<br>步数 970, 精度 0.9<br>步数 980, 精度 1<br>步数 990, 精度 0.9<br>&emsp;&emsp;可以看到，使用卷积神经网络训练1000次可以让精度达到95%以上，据说训练20000次精度可以达到99.2%以上。由于CPU不行，太耗时间，就不训练那么多了。大家可以跟使用softmax训练识别手写数字进行对比。<a href="http://www.cnblogs.com/tengge/p/6363586.html" target="_blank" rel="noopener">《07 训练Tensorflow识别手写数字》</a></p>
<h1 id="参考文献-6"><a href="#参考文献-6" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://www.cnblogs.com/tengge/p/6920144.html" target="_blank" rel="noopener">12 使用卷积神经网络识别手写数字</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/windows-xi-tong-xia-tensorboard-xian-shi-kong-bai-de-wen-ti.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/windows-xi-tong-xia-tensorboard-xian-shi-kong-bai-de-wen-ti.html" class="post-title-link" itemprop="url">Windows系统下Tensorboard显示空白的问题</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-04-26 22:13:14 / 修改时间：22:24:32" itemprop="dateCreated datePublished" datetime="2019-04-26T22:13:14+08:00">2019-04-26</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">262</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">1 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Tensorboard显示空白，或者graphs中显示“No graph definition files were found”，在数据正确的前提下，最可能是路径的问题。<br>Windows 下通过cmd启动tensorboard，采用如下两种方法可以避免路径造成的问题（假设文件在D盘的logs文件夹下）：<br>1.文件夹之间使用 // 分割<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;tensorboard --logdir=D://logs</span><br></pre></td></tr></table></figure></p>
<p>2.将路径直接切换到文件的上一级目录下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;cd D:</span><br><span class="line">&gt;tensorboard --logdir=logs</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif" alt="Junjie Jia">
            
              <p class="site-author-name" itemprop="name">Junjie Jia</p>
              <p class="site-description motion-element" itemprop="description">生命中的每一步都必须认真对待，把握今天，成就明天！</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">56</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">23</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">30</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                  
                    
                  
                  <a href="https://github.com/imjunjie" title="GitHub &rarr; https://github.com/imjunjie" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i></a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                  
                    
                  
                  <a href="mailto:junjie017@gmail.com" title="E-Mail &rarr; mailto:junjie017@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i></a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Junjie Jia</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
    <span title="站点总字数">458k</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
    <span title="站点阅读时长">6:57</span>
  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.0.0</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=7.0.0"></script>

  <script src="/js/src/motion.js?v=7.0.0"></script>



  
  


  <script src="/js/src/affix.js?v=7.0.0"></script>

  <script src="/js/src/schemes/pisces.js?v=7.0.0"></script>




  

  


  <script src="/js/src/bootstrap.js?v=7.0.0"></script>


  
  



  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  


  

  

  

  

  

  

  

  

  

  


  <!-- 代码块复制功能 -->
<script type="text/javascript" src="/js/src/clipboard.min.js"></script>  
<script type="text/javascript" src="/js/src/clipboard-use.js"></script>

</body>
</html>

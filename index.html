<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">























  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link rel="stylesheet" href="https://fonts.cat.net/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext">
  






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.0.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.0.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.0.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.0.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.0.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.0.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false,"dimmer":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
<meta property="og:type" content="website">
<meta property="og:title" content="Imjunjie">
<meta property="og:url" content="http://imjunjie.github.io/index.html">
<meta property="og:site_name" content="Imjunjie">
<meta property="og:description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Imjunjie">
<meta name="twitter:description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">



  <link rel="alternate" href="/atom.xml" title="Imjunjie" type="application/atom+xml">




  <link rel="canonical" href="http://imjunjie.github.io/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Imjunjie</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Imjunjie</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">蜻蜓雨荷</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/quan-ping-tai-zhong-wen-sublime-text-3207-ji-huo.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/quan-ping-tai-zhong-wen-sublime-text-3207-ji-huo.html" class="post-title-link" itemprop="url">（全平台）中文-Sublime Text 3207激活</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-20 15:30:02 / 修改时间：15:48:53" itemprop="dateCreated datePublished" datetime="2019-05-20T15:30:02+08:00">2019-05-20</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">3.3k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">3 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>有朋友反馈说安装不了Package Control<br>研究了一下，之前Host的列表把ST3的全都屏蔽了<br>仔细想了想有点智障，只用屏蔽license server就行<br>已更新，新的host就没问题了。<br>感谢@eui620的提醒</p>
<hr>
<p>我没在win下开发的习惯…<br>抱歉没发现WinHex不能保存超过200K的文件<br>用这个在线编辑器吧，啥平台都行。<br><a href="https://hexed.it" target="_blank" rel="noopener">https://hexed.it</a></p>
<hr>
<h1 id="1-下载软件"><a href="#1-下载软件" class="headerlink" title="1. 下载软件"></a>1. 下载软件</h1><p>官网: <a href="http://www.sublimetext.com/3/" target="_blank" rel="noopener">点我下载</a><br>网盘地址见底部</p>
<h1 id="2-安装软件"><a href="#2-安装软件" class="headerlink" title="2. 安装软件"></a>2. 安装软件</h1><p>这个我就不多BB了。<br>安装完请勿打开SublimeText3。<br>（若已打开关了就是）</p>
<h1 id="破解”-gt-3-破解"><a href="#破解”-gt-3-破解" class="headerlink" title="破解”&gt;3. 破解"></a>破解”&gt;3. 破解</h1><p>3207版本基本杜绝了共享license key的方法<br>所以我们要修改验证license时的trigger<br>因官方采用revoke illegal licenses的方式，即使当时显示激活成功，联网验证时便会凉凉。</p>
<p>所以我们还要采用hosts屏蔽法复制以下地址直接粘贴到相应系统的hosts文件内<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> license.sublimehq.com</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> www.sublimetext.com</span><br><span class="line"><span class="number">50.116</span><span class="number">.34</span><span class="number">.243</span> sublime.wbond.net</span><br><span class="line"><span class="number">50.116</span><span class="number">.34</span><span class="number">.243</span> packagecontrol.io</span><br></pre></td></tr></table></figure></p>
<h2 id="3-1-修改trigger"><a href="#3-1-修改trigger" class="headerlink" title="3.1 修改trigger"></a>3.1 修改trigger</h2><h3 id="3-1-1-Win"><a href="#3-1-1-Win" class="headerlink" title="3.1.1 Win"></a>3.1.1 Win</h3><ul>
<li>利用WinHex(网盘会有)或其他HexEditor打开软件根目录下的sublime_text.exe</li>
<li>搜索16进制 97 94 0D 00</li>
<li>改为  00 00 00 00</li>
<li>保存</li>
</ul>
<h3 id="3-1-2-Mac"><a href="#3-1-2-Mac" class="headerlink" title="3.1.2 Mac"></a>3.1.2 Mac</h3><ul>
<li><p>拷出/Applications/Sublime Text.app/Contents/MacOS/Sublime Text</p>
</li>
<li><p>其实就是 应用程序 文件夹下找到SublimeText应用，然后右键-&gt;显示包内容，然后打开/Contents/MacOS/ 然后找到 Sublime Text 这个文件 拷出来</p>
</li>
<li><p>利用0xED(网盘会有)或者其他HexEditor打开它</p>
</li>
<li>搜索16进制 97 94 0D 00</li>
<li>改为  00 00 00 00</li>
<li>如果实在不会修改网盘里有修改好的现成的</li>
<li>保存</li>
<li>打开终端，切换到当前目录</li>
<li>然后键入chmod 755 Sublime Text</li>
<li>替换掉/Applications/Sublime Text.app/Contents/MacOS/Sublime Text</li>
<li>完事儿</li>
</ul>
<h3 id="3-1-3-Linux"><a href="#3-1-3-Linux" class="headerlink" title="3.1.3 Linux"></a>3.1.3 Linux</h3><p>基本同Mac操作</p>
<ul>
<li>找个16进制编辑器打开软件根目录下的Sublime Text</li>
<li>搜索16进制 97 94 0D 00</li>
<li>改为  00 00 00 00</li>
<li>保存</li>
<li>打开终端，切换到当前目录</li>
<li>然后键入chmod 755 Sublime Text</li>
<li>完事儿</li>
</ul>
<h2 id="3-2-修改host"><a href="#3-2-修改host" class="headerlink" title="3.2 修改host"></a>3.2 修改host</h2><h3 id="3-2-1-Win"><a href="#3-2-1-Win" class="headerlink" title="3.2.1 Win"></a>3.2.1 Win</h3><p>Windows的hosts文件在：<br>系统盘:/windows/system32/drivers/etc/hosts<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Tips: Win下的权限获取可能有点复杂，不如先拷到桌面，编辑完替换回去。</span><br><span class="line">在最后一行插入</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> license.sublimehq.com</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> www.sublimetext.com</span><br><span class="line"><span class="number">50.116</span><span class="number">.34</span><span class="number">.243</span> sublime.wbond.net</span><br><span class="line"><span class="number">50.116</span><span class="number">.34</span><span class="number">.243</span> packagecontrol.io</span><br></pre></td></tr></table></figure>
<h3 id="3-2-2-Mac"><a href="#3-2-2-Mac" class="headerlink" title="3.2.2 Mac"></a>3.2.2 Mac</h3><ol>
<li>打开Terminal(终端)</li>
<li>输入 sudo nano /Private/etc/hosts 回车</li>
<li>输入密码后回车</li>
<li><p>在最后一行插入</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> license.sublimehq.com</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> www.sublimetext.com</span><br><span class="line"><span class="number">50.116</span><span class="number">.34</span><span class="number">.243</span> sublime.wbond.net</span><br><span class="line"><span class="number">50.116</span><span class="number">.34</span><span class="number">.243</span> packagecontrol.io</span><br></pre></td></tr></table></figure>
</li>
<li><p>按下Control + X，输入Y确定修改，确认保存路径后敲击回车</p>
</li>
</ol>
<h3 id="3-2-3-Linux"><a href="#3-2-3-Linux" class="headerlink" title="3.2.3 Linux"></a>3.2.3 Linux</h3><p>同Mac</p>
<h1 id="4-激活"><a href="#4-激活" class="headerlink" title="4. 激活"></a>4. 激活</h1><p>打开Sublime Text 3<br>选择Help -&gt; Enter License<br>输入<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">----- BEGIN LICENSE -----</span><br><span class="line">TwitterInc</span><br><span class="line"><span class="number">200</span> User License</span><br><span class="line">EA7E<span class="number">-890007</span></span><br><span class="line"><span class="number">1</span>D77F72E <span class="number">390</span>CDD93 <span class="number">4</span>DCBA022 FAF60790</span><br><span class="line"><span class="number">61</span>AA12C0 A37081C5 D0316412 <span class="number">4584</span>D136</span><br><span class="line"><span class="number">94</span>D7F7D4 <span class="number">95</span>BC8C1C <span class="number">527</span>DA828 <span class="number">560</span>BB037</span><br><span class="line">D1EDDD8C AE7B379F <span class="number">50</span>C9D69D B35179EF</span><br><span class="line"><span class="number">2</span>FE898C4 <span class="number">8E4277</span>A8 <span class="number">555</span>CE714 E1FB0E43</span><br><span class="line">D5D52613 C3D12E98 BC49967F <span class="number">7652</span>EED2</span><br><span class="line"><span class="number">9</span>D2D2E61 <span class="number">67610860</span> <span class="number">6</span>D338B72 <span class="number">5</span>CF95C69</span><br><span class="line">E36B85CC <span class="number">84991</span>F19 <span class="number">7575</span>D828 <span class="number">470</span>A92AB</span><br><span class="line">------ END LICENSE ------</span><br></pre></td></tr></table></figure></p>
<p>选择Use license </p>
<h1 id="5-大功告成"><a href="#5-大功告成" class="headerlink" title="5.大功告成"></a>5.大功告成</h1><p><img src="/images/（全平台）中文-Sublime-Text-3207激活/png1-1.png" alt></p>
<h1 id="6-中文化"><a href="#6-中文化" class="headerlink" title="6.中文化"></a>6.中文化</h1><p>不知道该不该写，好多人觉得哇人家破解版带个汉化猴赛雷<br>其实在Package Control就有 Rexdf 翻译的插件</p>
<ul>
<li>按下command + shift + p(win或linux为 ctrl + shift + p) 输入 install 选择 Install Package Control<br><img src="/images/（全平台）中文-Sublime-Text-3207激活/png1-2.png" alt></li>
<li>等待提示安装完成</li>
<li>完成后按下command + shift + p(win或linux为 ctrl + shift + p) 输入 install 选择 Package Control: Install Package<br><img src="/images/（全平台）中文-Sublime-Text-3207激活/png1-3.png" alt></li>
<li>输入 localization 选择 ChineseLocalizitions<br><img src="/images/（全平台）中文-Sublime-Text-3207激活/png1-4.png" alt></li>
<li>等待提示安装完成</li>
<li>大功告成，如需切换语言选择help -&gt; Languages<br><img src="/images/（全平台）中文-Sublime-Text-3207激活/png1-5.png" alt></li>
</ul>
<h1 id="7-附件"><a href="#7-附件" class="headerlink" title="7.附件"></a>7.附件</h1><p>附件什么附件？？<br>我这破等级还想发附件？？？<br>卑微，蚂蚁花卑，葡萄美酒夜光卑…..<br><a href="https://pan.baidu.com/s/14FCBvNuadVjsbkUSZD2JbQ" target="_blank" rel="noopener">百度网盘</a>  密码:lksz</p>
<h1 id="问答"><a href="#问答" class="headerlink" title="问答"></a>问答</h1><h2 id="（发表于-2019-4-16-08-08，by-hjner）"><a href="#（发表于-2019-4-16-08-08，by-hjner）" class="headerlink" title="（发表于 2019-4-16 08:08，by hjner）"></a>（发表于 2019-4-16 08:08，by hjner）</h2><p>我测试，说注册码不对…..XP 下测试的。</p>
<hr>
<p>第二次重装，同样出现  ：<br>plugin_host has exited unexpectedly,plugin functionality won’t be available until Sublime Text has been restarted</p>
<p>不关闭程序，先设置好HOST文件，屏蔽服务器，然后，直接 输入注册码，反而通过！<br>之前重启程序在输入注册码，则无效。</p>
<p>谢谢，成功！</p>
<hr>
<p>安装中文时候，出现<br>installing package control,出现提示，访问<br><a href="https://packagecontrol.io/installation" target="_blank" rel="noopener">https://packagecontrol.io/installation</a></p>
<p>手动安装，</p>
<p>但是网站进不去…只有以后再试试了。</p>
<h2 id="发表于-2019-5-7-16-36-by-花了19元"><a href="#发表于-2019-5-7-16-36-by-花了19元" class="headerlink" title="(发表于 2019-5-7 16:36 by 花了19元)"></a>(发表于 2019-5-7 16:36 by 花了19元)</h2><p>127.0.0.1 license.sublimehq.com<br>127.0.0.1 www.sublimetext.com<br>50.116.34.243 sublime.wbond.net<br>50.116.34.243 packagecontrol.io</p>
<p>激活成功，但是这样修改hosts，插件安装不了。</p>
<p>解决办法(<a href="https://www.jianshu.com/p/23b823d6e786)：" target="_blank" rel="noopener">https://www.jianshu.com/p/23b823d6e786)：</a><br>点击 Preferences &gt; Package Settings &gt; Package Control &gt; Settings - User<br>添加配置<br>“channels”: [“<a href="https://raw.githubusercontent.com/HBLong/channel_v3_daily/master/channe" target="_blank" rel="noopener">https://raw.githubusercontent.com/HBLong/channel_v3_daily/master/channe</a></p>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/win10-ru-he-zi-ding-yi-you-jian-cai-dan-xiu-gai-zhu-ce-biao-tu-wen.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/win10-ru-he-zi-ding-yi-you-jian-cai-dan-xiu-gai-zhu-ce-biao-tu-wen.html" class="post-title-link" itemprop="url">Win10如何自定义右键菜单-修改注册表（图文）</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-20 14:36:40 / 修改时间：15:19:07" itemprop="dateCreated datePublished" datetime="2019-05-20T14:36:40+08:00">2019-05-20</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">5.1k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">5 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="理论介绍"><a href="#理论介绍" class="headerlink" title="理论介绍"></a>理论介绍</h1><p>&emsp;&emsp;我研究这个是因为发现右键菜单在安装了一下软件后，越来越臃肿，有用的没用的菜单项都被塞进去了，于是自己动手给菜单瘦个身。</p>
<p>&emsp;&emsp;这里首先警告一句：<strong>下面操作全部涉及到修改注册表，看见不认识，不确定的注册表项，别手欠看见空项或者自以为无用的注册表项，就瞎乱删。最好是有一定操作注册表的基础在跟着本文操作，至少要知道怎么备份和恢复注册表。手欠的孩子都请自己准备好恢复或重装系统，本文的经过作者本人亲自实践无误，但不保证文中描述完全正确或适用于所有版本的win10操作系统。如果在按照本文说明操作时，发生了系统崩溃，死机，或其他任何可修复/不可修复的系统问题，你可以顺着网线来打我啊，然而我也救不了你。</strong></p>
<p>&emsp;&emsp;首先，所有的右键菜单项，几乎都可以在注册表中设置。按<font color="red"> Win + R </font>打开“ <code>运行…</code>”窗口，输入<font color="red"> regedit </font>，按回车键打开。注意：注册表编辑器是需要管理员权限的。<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/jpg1-1.jpg" alt></p>
<p>打开注册表，根项展开有5个子项，如上图所示。右键菜单的项目都包含在第一子项<font color="red"> HKEY_CALSS_ROOT </font>中。展开该项，第一个子项一般是<font color="red"> * </font>，这个统配符表示一切后缀的文件都通用。也就是说，这个子项中的一切右键菜单项，没有特别说明，会出现每一个文件的右键菜单中。</p>
<p>展开这一子项，在其内部，所有的右键菜单分为两部分存储（我也懒得去搞清楚这两块区域有什么不同），见下图：<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/jpg1-2.jpg" alt></p>
<p>用红线圈起来的两个注册表键，就是放置了右键菜单的地方，看看有哪些是自己安装的软件带来的，看名字挑着没用的就能删除了。<strong>这里特别提醒一句，看见键名称是一串序列号的，请仔细核对后，确认不是系统项再删除。用这种长串数字当名字的键，如果里面空空如也，那很有可能是系统项。</strong></p>
<p>然后是文件夹，文件夹分为两类菜单，一类是鼠标指向一个文件夹图标时，点击右键出来的菜单；第二类菜单时鼠标在已经打开的文件夹窗口的空白处，点击右键弹出的菜单。如下图所示，第一类菜单的注册表项直接在 Directory 下，shell和shellex\ContextMenuHandlers 里面；第二类菜单则在子项 Background 里面。<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/jpg1-3.jpg" alt></p>
<p>哦，对了，还有比较特殊的桌面菜单。在桌面空白处点击右键，弹出的菜单在 DesktopBackground 项里面：<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/jpg1-4.jpg" alt></p>
<p>是的，细心的人应该已经发现了，这里的菜单项不全。是的，不全，然而我也不知道其他的在哪里，懒得找……</p>
<p>然后还有一些，比如：<br>驱动器（就是C盘、光驱，之类那些，带着卷标的），在 Drive 项里面；<br>文件夹还有一些在 Folder 项里面；<br>字体文件的在 fontfile 项里面；<br>等等…… 英文好的同学可以自行发挥了。 </p>
<p>上面讲的是如何找到一些项，然后就能删除里面多余的菜单项。下面将一些添加项的方法：</p>
<p>以python文件为例（<code>*.py</code>），python如见有两个大分支：2.x系列和3.x系列。那么有时候我们的机器上会同时安装这两个python的运行环境，这时候想要快速的用python解释器打开某个<code>*.py</code>文件，要么就是命令行，要么就是频繁更改打开方式，要么就是来回挪动环境变量的前后顺序……好吧，我不废话了，下面开始动手添加右键菜单。</p>
<p>首先，还是找到包含python脚本文件的右键菜单项的注册表键，完整的路径是 Computer\HKEY_CLASSES_ROOT\pysFile ，如下图。这里可以看到，有3个子项。一眼可以看到右键菜单的藏身之处：<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/jpg1-5.jpg" alt></p>
<p>一般安装python时，附带的菜单项倒在 Shell 子键里面，展开，把一串什么 runwithidle 之类的统统干掉，然后我们来加入自己的项。<br>右键点击 Shell ，然后选择 新建 ，然后选择 键：<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/jpg1-6.jpg" alt></p>
<p>简单点的话，不做附加设置，这个键的名字就会是右键菜单项的显示名字，如下图所示：<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/jpg1-7.jpg" alt><br>之后，如果更改这个键的默认值，就会更改菜单的显示名字：<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/jpg1-8.jpg" alt><br>只有一个键，是不能让这个菜单项真正生效的，这时如果点击这个菜单项，就会收到系统发出的错误警告。下面来添加点击这个菜单项所触发的命令：<br>在新建的键里面（图里面的 MieHaHa键），再新建一个键，命名为 command，一般大小写都行，但是我还是建议全小写吧。然后更改这个键的默认值，双击(Default)（中文操作系统这里应该是默认），会弹出修改框，把值修改为你的python.exe所在完整路径+参数就可以了，比如我的python36安装在<code>D:\Environment\Python36\python.exe, 那么我这里就要输入 &quot;D:\Environment\Python36\python.exe&quot; &quot;%1&quot; %*</code>。这里简单解释一下，这里的值，就相当与是命令行里敲的命令。因为是点击文件弹出的菜单， %1 就是被点击的py文件的完整路径。</p>
<p>有了这个菜单项，就能使用这一项直接用python运行脚本文件了。然而，这也太简陋了，看好多程序都用dll文件，把自己的菜单项折叠成了一个子菜单组，简洁又方便。在WIN10里，其实不用dll，只用注册表，也能自己制作一个折叠的子菜单组，比如上图（图8）的 Run With 项就是我自己写的一个菜单组。下图直接上键的树：<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/jpg1-9.jpg" alt></p>
<p>除了最内层两个 command 和 最外层的 runwith 其余的键都没有值。 runwith 里需要新建两个 字符串的值：一个命名为 MUIVerb，值为 &amp;Run With，也就是这个菜单组的名称，注意要以 &amp; 开头，这个字符不会被显示；第二个值，命名为Subcommands，没有值。如下图：<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/jpg1-10.jpg" alt></p>
<h1 id="将-Sublime-Text-添加到系统右键菜单栏的方法"><a href="#将-Sublime-Text-添加到系统右键菜单栏的方法" class="headerlink" title="将 Sublime Text 添加到系统右键菜单栏的方法"></a>将 Sublime Text 添加到系统右键菜单栏的方法</h1><p>Sublime Text 是一个代码编辑器（Sublime Text 2是收费软件，但可以无限期试用），也是HTML和散文先进的文本编辑器。Sublime Text是由程序员Jon Skinner于2008年1月份所开发出来，它最初被设计为一个具有丰富扩展功能的Vim。<br>Sublime Text具有漂亮的用户界面和强大的功能，例如代码缩略图，Python的插件，代码段等。还可自定义键绑定，菜单和工具栏。Sublime Text 的主要功能包括：拼写检查，书签，完整的 Python API ， Goto 功能，即时项目切换，多选择，多窗口等等。Sublime Text 是一个跨平台的编辑器，同时支持Windows、Linux、Mac OS X等操作系统。（摘自百度百科）</p>
<p>咳咳，废话少说，切入正题：<br>这么好的编译器在打开需要编译的文件时却存在一个非常让人头疼的问题：不能右键菜单选择使用 Sublime text 打开！！！</p>
<p>下面为大家介绍一种通过修改系统注册表的方法将 Sublime text 添加到右键菜单中： </p>
<ol>
<li><p>首先使用 Win + R 打开运行，输入 regedit 按下回车键进入注册表；<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png1-1.png" alt><br>运行后进入注册表界面：<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png1-2.png" alt></p>
</li>
<li><p>依次展开 HKEY_CLASSES_ROOT -&gt; * -&gt; shell，右键 shell 新建一个项并命名为：Open With Sublime Text 如图：<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png1-3.png" alt></p>
</li>
<li><p>双击选中新建项 Open With Sublime Text ，在右边展示栏空白处右键新建字符串值，数值名称填 lcon ，数值数据填 E:\Sublime Text3\sublime_text.exe,0 （注意：路径请改成你安装Sublime Text 的路径喔）<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png1-4.png" alt><br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png1-5.png" alt></p>
</li>
<li><p>右键新建的 Open With Sublime Text 新建一个项，命名为 Command （注意：请必须命名为 Command 喔），并双击选中 Command ，在右边的展示栏中将默认项的数值数据修改为：E:\Sublime Text 3\sublime_text.exe “%1” （注意：1、将我的路径改成你安装 Sublime Text 的路径，2、”必须要写喔）<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png1-6.png" alt><br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png1-7.png" alt><br>进行到这里，右键菜单的 Open With Sublime Text 选项就实现啦！！！</p>
</li>
</ol>
<h1 id="sublime-text-添加到鼠标右键功能"><a href="#sublime-text-添加到鼠标右键功能" class="headerlink" title="sublime text 添加到鼠标右键功能"></a>sublime text 添加到鼠标右键功能</h1><p>Sublime Text是一款具有代码高亮、语法提示、自动完成且反应快速的编辑器软件，不仅具有华丽的界面，还支持插件扩展机制，用她来写代码，绝对是一种享受。如何把sublime text添加到鼠标右键，以方便我们使用呢？</p>
<h2 id="方法与步骤"><a href="#方法与步骤" class="headerlink" title="方法与步骤"></a>方法与步骤</h2><p>1.在Windows系统中，下载并安装sublime text3 软件，（可以到sublime text3 的官方网站下载），如下图，可以按不同的系统选择下载安装包。<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png2-1.png" alt></p>
<p>2.下载完成后，双击安装包文件进行安装，安装比较简单，按照提示点击“下一步”，最后完成安装，如下图所示。<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png2-2.png" alt></p>
<p>3.sublime text 添加到鼠标右键功能：把以下内容复制并保存到文件，重命名为：sublime_addright.reg，然后双击就可以了。<br>（注意：需要把下面代码中的Sublime的安装目录（标粗部分），替换成自已实际的Sublime安装目录）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Windows Registry Editor Version <span class="number">5.00</span></span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\*\shell\SublimeText3]</span><br><span class="line"></span><br><span class="line"><span class="meta">@="用 SublimeText3 打开"</span></span><br><span class="line"></span><br><span class="line"><span class="string">"Icon"</span>=<span class="string">"C:\\Program Files\\Sublime Text 3\\sublime_text.exe,0"</span></span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\*\shell\SublimeText3\command]</span><br><span class="line"></span><br><span class="line"><span class="meta">@="C:\\Program Files\\Sublime Text 3\\sublime_text.exe %1"</span></span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\Directory\shell\SublimeText3]</span><br><span class="line"></span><br><span class="line"><span class="meta">@="用 SublimeText3 打开"</span></span><br><span class="line"></span><br><span class="line"><span class="string">"Icon"</span>=<span class="string">"C:\\Program Files\\Sublime Text 3\\sublime_text.exe,0"</span></span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\Directory\shell\SublimeText3\command]</span><br><span class="line"></span><br><span class="line"><span class="meta">@="C:\\Program Files\\Sublime Text 3\\sublime_text.exe %1"</span></span><br></pre></td></tr></table></figure></p>
<p>其中，@=”用 SublimeText3 打开” 引号中的内容为出现在鼠标右键菜单中的文字内容。<br>4.双击文件sublime_addright.reg 完成后，鼠标选中要编辑的文件，点击鼠标右键，弹出菜单，其中就会出现刚才添加的“用 SublimeText3 打开”选项，如下图所示。<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png2-3.png" alt></p>
<h1 id="将Sublime-Text-添加到鼠标右键的方法"><a href="#将Sublime-Text-添加到鼠标右键的方法" class="headerlink" title="将Sublime Text 添加到鼠标右键的方法"></a>将Sublime Text 添加到鼠标右键的方法</h1><p><strong>步骤:</strong></p>
<ol>
<li>win+R 打开运行，并输入regedit。</li>
<li>在左侧依次打开HKEY_CLASSES_ROOT*\shell</li>
<li><p>在shell下新建“Sublime Text”项，在右侧窗口的“默认”键值栏内输入“用Sublime Text打开”。项的名称和键值可以任意，最好是和程序关联起来。其中键值将显示在右键菜单中。</p>
</li>
<li><p>在“用Sublime Text打开”下再新建Command项，在右侧窗口的“默认”键值栏内输入Sublime Text程序所在的路径,在路径后添加 %1。%1表示要打开的文件参数。</p>
</li>
<li>关闭注册表窗口，立即生效。（如图）<br><img src="/images/Win10如何自定义右键菜单-修改注册表（图文）/png3-1.png" alt></li>
</ol>
<p><strong>注意事项：</strong></p>
<pre><code>    1. 第四步时的Command无法自定义。必须输入Command才可以。
    2. 输入程序路径时注意为以下格式：例. d:\sub\sub.exe %1
</code></pre><p>&emsp;&emsp;万事不要太依赖别人，自己动手才能丰衣足食。这个鼠标右键也可以使用第三方程序来调用添加，而且这个改注册表不止方便，还可以举一反三，做的更多。<br>&emsp;&emsp;附上下载链接这个中文不会乱码: 链接：<a href="https://pan.baidu.com/s/1jH9KD8a" target="_blank" rel="noopener">https://pan.baidu.com/s/1jH9KD8a</a> 密码：p6du</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://blog.csdn.net/CrowNAir/article/details/78128566" target="_blank" rel="noopener">Win10如何自定义右键菜单-修改注册表（图文</a></li>
<li><a href="https://blog.csdn.net/MariaGit/article/details/79016807" target="_blank" rel="noopener">将 Sublime Text 添加到系统右键菜单栏的方法</a></li>
<li><a href="https://jingyan.baidu.com/article/cdddd41c99d07653ca00e147.html" target="_blank" rel="noopener">sublime text 添加到鼠标右键功能</a></li>
<li><a href="https://blog.csdn.net/a_piaoyouareminemine/article/details/49969299" target="_blank" rel="noopener">将Sublime Text 添加到鼠标右键的方法</a></li>
<li><a href="https://blog.csdn.net/linysuccess/article/details/79179799" target="_blank" rel="noopener">win10右键菜单修改，任意位置打开cmd命令行程序</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/semi-supervised-learning-with-gans.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/semi-supervised-learning-with-gans.html" class="post-title-link" itemprop="url">Semi-supervised learning with GANs</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-09 11:47:15 / 修改时间：15:50:55" itemprop="dateCreated datePublished" datetime="2019-05-09T11:47:15+08:00">2019-05-09</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">23k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">21 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><br>&emsp;&emsp;In this post I will cover a partial re-implementation of a <a href="https://arxiv.org/abs/1805.08957" target="_blank" rel="noopener">recent paper</a> on manifold regularization (Lecouat et al., 2018) for semi-supervised learning with <a href="http://papers.nips.cc/paper/5423-generative-adversarial-nets" target="_blank" rel="noopener">Generative Adversarial Networks</a> (Goodfellow et al., 2014). I will attempt to re-implement their main contribution, rather than getting all the hyperparameter details just right. Also, for the sake of demonstration, time constraints and simplicity, I will consider the MNIST dataset rather than the CIFAR10 or SVHN datasets as done in <a href="https://arxiv.org/abs/1805.08957" target="_blank" rel="noopener">the paper</a>. Ultimately, this post aims at bridging the gap between the theory and implementation for GANs in the semi-supervised learning setting. The code that comes with this post can be found <a href="https://github.com/jostosh/gan/blob/master/dcganmnist/mnist_ssl.py" target="_blank" rel="noopener">here</a>.</p>
<h1 id="Generative-Adversarial-Networks"><a href="#Generative-Adversarial-Networks" class="headerlink" title="Generative Adversarial Networks"></a>Generative Adversarial Networks</h1><p>&emsp;&emsp;Let’s quickly go over Generative Adversarial Networks (GAN). In terms of the current pace within the AI/ML community, they have been around for a while (just about 4 years), so you might already be familiar with them. The ‘vanilla’ GAN procedure is to train a generator to generate images that are realistic and capable of fooling a discriminator. The generator generates the images by means of a deep neural network that takes in a noise vector z.<br>&emsp;&emsp;The discriminator (which is a deep neural network as well) is fed with the generated images, but also with some real data. Its job is to say whether each image is either real (coming from the dataset) or fake (coming from the generator), which in terms of implementation comes down to binary classification. The image below summarizes the vanilla GAN setup.<br><img src="/images/Semi-supervised-learning-with-GANs/png1-1.png" alt="Vanilla GAN setup"></p>
<h1 id="Semi-supervised-learning"><a href="#Semi-supervised-learning" class="headerlink" title="Semi-supervised learning"></a>Semi-supervised learning</h1><p>&emsp;&emsp;Semi-supervised learning problems concern a mix of labeled and unlabeled data. Leveraging the information in both the labeled and unlabeled data to eventually improve the performance on unseen labeled data is an interesting and more challenging problem than merely doing supervised learning on a large labeled dataset. In this case we might be limited to having only about 200 samples per class. So what should we do when only a small portion of the data is labeled?<br>&emsp;&emsp;Note that adversarial training of vanilla GANs doesn’t require labeled data. At the same time, the deep neural network of the discriminator is able to learn powerful and robust abstractions of images by gradually becoming better at discriminating fake from real. Whatever it’s learning about unlabeled images will presumably also yield useful feature descriptors of labeled images. So how do we use the discriminator for both labeled and unlabeled data? Well, the discriminator is not necessarily limited to just telling fake from real. We could decide to train it to also classify the real data.<br>&emsp;&emsp;A GAN with a classifying discriminator would be able to exploit both the unlabeled as well as the labeled data. The unlabeled data will be used to merely tell fake from real. The labeled data would be used to optimize the classification performance. In practice, this just means that the discriminator has a softmax output distribution for which we minimize the cross-entropy. Indeed, part of the training procedure is just doing supervised learning. The other part is about adversarial training. The image below summarizes the semi-supervised learning setup with a GAN.<br><img src="/images/Semi-supervised-learning-with-GANs/png1-2.png" alt="Vanilla GAN setup"></p>
<h1 id="The-implementation"><a href="#The-implementation" class="headerlink" title="The implementation"></a>The implementation</h1><p>&emsp;&emsp;Let’s just head over to the implementation, since that might be the best way of understanding what’s happening. The snippet below prepares the data. It doesn’t really contain anything sophisticated. Basically, we take 400 samples per class and concatenate the resulting arrays as being our actual supervised subset. The unlabeled dataset consists of all train data (it also includes the labeled data, since we might as well use it anyway). As is customary for training GANs now, the output of the generator uses a hyperbolic tangent function, meaning its output is between -1 and +1. Therefore, we rescale the data to be in that range as well. Then, we create TensorFlow iterators so that we can efficiently go through the data later without having to struggle with feed dicts later on.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prepare_input_pipeline</span><span class="params">(flags_obj)</span>:</span></span><br><span class="line">    (train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data(</span><br><span class="line">        <span class="string">"/home/jos/datasets/mnist/mnist.npz"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reshape_and_scale</span><span class="params">(x, img_shape=<span class="params">(<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span>)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> x.reshape(img_shape).astype(np.float32) / <span class="number">255.</span> * <span class="number">2.0</span> - <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Reshape data and rescale to [-1, 1]</span></span><br><span class="line">    train_x = reshape_and_scale(train_x)</span><br><span class="line">    test_x = reshape_and_scale(test_x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Shuffle train data</span></span><br><span class="line">    train_x_unlabeled, train_y_unlabeled = shuffle(train_x, train_y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Select subset as supervised</span></span><br><span class="line">    train_x_labeled, train_y_labeled = [], []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(flags_obj.num_classes):</span><br><span class="line">        train_x_labeled.append(</span><br><span class="line">            train_x_unlabeled[train_y_unlabeled == i][:flags_obj.num_labeled_examples])</span><br><span class="line">        train_y_labeled.append(</span><br><span class="line">            train_y_unlabeled[train_y_unlabeled == i][:flags_obj.num_labeled_examples])</span><br><span class="line">    train_x_labeled = np.concatenate(train_x_labeled)</span><br><span class="line">    train_y_labeled = np.concatenate(train_y_labeled)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">"InputPipeline"</span>):</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">train_pipeline</span><span class="params">(data, shuffle_buffer_size)</span>:</span></span><br><span class="line">            <span class="keyword">return</span> tf.data.Dataset.from_tensor_slices(data)\</span><br><span class="line">                .cache()\</span><br><span class="line">                .shuffle(buffer_size=shuffle_buffer_size)\</span><br><span class="line">                .batch(flags_obj.batch_size)\</span><br><span class="line">                .repeat()\</span><br><span class="line">                .make_one_shot_iterator()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Setup pipeline for labeled data</span></span><br><span class="line">        train_ds_lab = train_pipeline(</span><br><span class="line">            (train_x_labeled, train_y_labeled.astype(np.int64)),</span><br><span class="line">            flags_obj.num_labeled_examples * flags_obj.num_classes)</span><br><span class="line">        images_lab, labels_lab = train_ds_lab.get_next()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Setup pipeline for unlabeled data</span></span><br><span class="line">        train_ds_unl = train_pipeline(</span><br><span class="line">            (train_x_unlabeled, train_y_unlabeled.astype(np.int64)), len(train_x_labeled))</span><br><span class="line">        images_unl, labels_unl = train_ds_unl.get_next()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Setup another pipeline that also uses the unlabeled data, so that we use a different</span></span><br><span class="line">        <span class="comment"># batch for computing the discriminator loss and the generator loss</span></span><br><span class="line">        train_x_unlabeled, train_y_unlabeled = shuffle(train_x_unlabeled, train_y_unlabeled)</span><br><span class="line">        train_ds_unl2 = train_pipeline(</span><br><span class="line">            (train_x_unlabeled, train_y_unlabeled.astype(np.int64)), len(train_x_labeled))</span><br><span class="line">        images_unl2, labels_unl2 = train_ds_unl2.get_next()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Setup pipeline for test data</span></span><br><span class="line">        test_ds = tf.data.Dataset.from_tensor_slices((test_x, test_y.astype(np.int64)))\</span><br><span class="line">            .cache()\</span><br><span class="line">            .batch(flags_obj.batch_size)\</span><br><span class="line">            .repeat()\</span><br><span class="line">            .make_one_shot_iterator()</span><br><span class="line">        images_test, labels_test = test_ds.get_next()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (images_lab, labels_lab), (images_unl, labels_unl), (images_unl2, labels_unl2), \</span><br><span class="line">           (images_test, labels_test)</span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;Next up is to define the discriminator network. I have deviated quite a bit from the architecture in the <a href="https://arxiv.org/abs/1805.08957" target="_blank" rel="noopener">paper</a>. I’m going to play safe here and just use Keras layers to construct the model. Actually, this enables us to very conveniently reuse all weights for different input tensors, which will prove to be useful later on. In short, the discriminator’s architecture uses 3 convolutions with 5x5 kernels and strides of 2x2, 2x2 and 1x1 respectively. Each convolution is followed by a leaky ReLU activation and a dropout layer with a dropout rate of 0.3. The flattened output of this stack of convolutions will be used as the feature layer.<br>&emsp;&emsp;The feature layer can be used for a <a href="https://arxiv.org/abs/1606.03498" target="_blank" rel="noopener">feature matching loss</a> (rather than a sigmoid cross-entropy loss as in vanilla GANs), which has proven to yield a more reliable training process. The part of the network up to this feature layer is defined in <code>_define_tail</code> in the snippet below. The <code>_define_head</code> method defines the rest of the network. The ‘head’ of the network introduces only one additional fully connected layer with 10 outputs, that correspond to the logits of the class labels. Other than that, there are some methods to make the interface of a <code>Discriminator</code> instance behave similar to that of a <code>tf.keras.models.Sequential</code> instance.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""The discriminator network. Split up in a 'tail' and 'head' network, so that we can</span></span><br><span class="line"><span class="string">        easily get the """</span></span><br><span class="line">        self.tail = self._define_tail()</span><br><span class="line">        self.head = self._define_head()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_define_tail</span><span class="params">(self, name=<span class="string">"Discriminator"</span>)</span>:</span></span><br><span class="line">        <span class="string">"""Defines the network until the intermediate layer that can be used for feature-matching</span></span><br><span class="line"><span class="string">        loss."""</span></span><br><span class="line">        feature_model = models.Sequential(name=name)</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">conv2d_dropout</span><span class="params">(filters, strides, index=<span class="number">0</span>)</span>:</span></span><br><span class="line">            <span class="comment"># Adds a convolution followed by a Dropout layer</span></span><br><span class="line">            suffix = str(index)</span><br><span class="line">            feature_model.add(layers.Conv2D(</span><br><span class="line">                filters=filters, strides=strides, name=<span class="string">"Conv&#123;&#125;"</span>.format(suffix), padding=<span class="string">'same'</span>,</span><br><span class="line">                kernel_size=<span class="number">5</span>, activation=tf.nn.leaky_relu))</span><br><span class="line">            feature_model.add(layers.Dropout(name=<span class="string">"Dropout&#123;&#125;"</span>.format(suffix), rate=<span class="number">0.3</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Three blocks of convs and dropouts. They all have 5x5 kernels, leaky ReLU and 0.3</span></span><br><span class="line">        <span class="comment"># dropout rate.</span></span><br><span class="line">        conv2d_dropout(filters=<span class="number">32</span>, strides=<span class="number">2</span>, index=<span class="number">0</span>)</span><br><span class="line">        conv2d_dropout(filters=<span class="number">64</span>, strides=<span class="number">2</span>, index=<span class="number">1</span>)</span><br><span class="line">        conv2d_dropout(filters=<span class="number">64</span>, strides=<span class="number">1</span>, index=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Flatten it and build logits layer</span></span><br><span class="line">        feature_model.add(layers.Flatten(name=<span class="string">"Flatten"</span>))</span><br><span class="line">        <span class="keyword">return</span> feature_model</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_define_head</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># Defines the remaining layers after the 'tail'</span></span><br><span class="line">        head_model = models.Sequential(name=<span class="string">"DiscriminatorHead"</span>)</span><br><span class="line">        head_model.add(layers.Dense(units=<span class="number">10</span>, activation=<span class="literal">None</span>, name=<span class="string">"Logits"</span>))</span><br><span class="line">        <span class="keyword">return</span> head_model</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">trainable_variables</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># Return both tail's parameters a well as those of the head</span></span><br><span class="line">        <span class="keyword">return</span> self.tail.trainable_variables + self.head.trainable_variables</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, x, *args, **kwargs)</span>:</span></span><br><span class="line">        <span class="comment"># By adding this, the code below can treat a Discriminator instance as a</span></span><br><span class="line">        <span class="comment"># tf.keras.models.Sequential instance</span></span><br><span class="line">        features = self.tail(x, *args, **kwargs)</span><br><span class="line">        <span class="keyword">return</span> self.head(features, *args, **kwargs), features</span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;The generator’s architecture also uses <code>5x5</code> kernels. Many implementations of DCGAN-like architectures use transposed convolutions (sometimes wrongfully referred to as ‘deconvolutions’). I have decided to give the upsampling-convolution alternative a try. This should alleviate the issue of the <u>checkerboard pattern</u> that sometimes appears in generated images. Other than that, there are ReLU nonlinearities, and a first layer to go from the 100-dimensional noise to a (rather awkwardly shaped) <code>7x7x64</code> spatial representation.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">define_generator</span><span class="params">()</span>:</span></span><br><span class="line">    model = models.Sequential(name=<span class="string">"Generator"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">conv2d_block</span><span class="params">(filters, upsample=True, activation=tf.nn.relu, index=<span class="number">0</span>)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> upsample:</span><br><span class="line">            model.add(layers.UpSampling2D(name=<span class="string">"UpSampling"</span> + str(index), size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">        model.add(layers.Conv2D(</span><br><span class="line">            filters=filters, kernel_size=<span class="number">5</span>, padding=<span class="string">'same'</span>, name=<span class="string">"Conv2D"</span> + str(index),</span><br><span class="line">            activation=activation))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># From flat noise to spatial</span></span><br><span class="line">    model.add(layers.Dense(<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>, activation=tf.nn.relu, name=<span class="string">"NoiseToSpatial"</span>))</span><br><span class="line">    model.add(layers.Reshape((<span class="number">7</span>, <span class="number">7</span>, <span class="number">64</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Four blocks of convolutions, 2 that upsample and convolve, and 2 more that</span></span><br><span class="line">    <span class="comment"># just convolve</span></span><br><span class="line">    conv2d_block(filters=<span class="number">128</span>, upsample=<span class="literal">True</span>, index=<span class="number">0</span>)</span><br><span class="line">    conv2d_block(filters=<span class="number">64</span>, upsample=<span class="literal">True</span>, index=<span class="number">1</span>)</span><br><span class="line">    conv2d_block(filters=<span class="number">64</span>, upsample=<span class="literal">False</span>, index=<span class="number">2</span>)</span><br><span class="line">    conv2d_block(filters=<span class="number">1</span>, upsample=<span class="literal">False</span>, activation=tf.nn.tanh, index=<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;I have tried to make this model work with what TensorFlow’s Keras layers have to offer so that the code would be easy to digest (and to implement of course). This also means that I have deviated from the architectures in <a href="https://arxiv.org/abs/1805.08957" target="_blank" rel="noopener">the paper</a> (e.g. I’m not using weight normalization). Because of this experimental approach, I have also experienced just how sensitive the training setup is to small variations in network architectures and parameters. There are plenty of neat GAN ‘hacks’ listed <a href="https://github.com/soumith/ganhacks" target="_blank" rel="noopener">here</a> which I definitely found insightful.     </p>
<h1 id="Putting-it-together"><a href="#Putting-it-together" class="headerlink" title="Putting it together"></a>Putting it together</h1><p>&emsp;&emsp;Let’s do the forward computations now so that we see how all of the above comes together. This consists of setting up the input pipeline, noise vector, generator and discriminator. The snippet below does all of this. Note that when <code>define_generator</code> returns the <code>Sequential</code> instance, we can just use it as a functor to obtain the output of it for the noise tensor given by z.<br>&emsp;&emsp;The discriminator will do a lot more. It will take (i) the ‘fake’ images coming from the generator, (ii) a batch of unlabeled images and finally (iii) a batch of labeled images (both with and without dropout to also report the train accuracy). We can just repetitively call the <code>Discriminator</code> instance to build the graph for each of those outputs. Keras will make sure that the variables are reused in all cases. To turn off dropout for the labeled training data, we have to pass <code>training=False</code> explicitly.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">(images_lab, labels_lab), (images_unl, labels_unl), (images_unl2, labels_unl2), \</span><br><span class="line">            (images_test, labels_test) = prepare_input_pipeline(flags_obj)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"BatchSize"</span>):</span><br><span class="line">    batch_size_tensor = tf.shape(images_lab)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the noise vectors</span></span><br><span class="line">z, z_perturbed = define_noise(batch_size_tensor, flags_obj)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate images from noise vector</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"Generator"</span>):</span><br><span class="line">    g_model = define_generator()</span><br><span class="line">    images_fake = g_model(z)</span><br><span class="line">    images_fake_perturbed = g_model(z_perturbed)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Discriminate between real and fake, and try to classify the labeled data</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"Discriminator"</span>) <span class="keyword">as</span> discriminator_scope:</span><br><span class="line">    d_model = Discriminator()</span><br><span class="line">    logits_fake, features_fake          = d_model(images_fake, training=<span class="literal">True</span>)</span><br><span class="line">    logits_fake_perturbed, _            = d_model(images_fake_perturbed, training=<span class="literal">True</span>)</span><br><span class="line">    logits_real_unl, features_real_unl  = d_model(images_unl, training=<span class="literal">True</span>)</span><br><span class="line">    logits_real_lab, features_real_lab  = d_model(images_lab, training=<span class="literal">True</span>)</span><br><span class="line">    logits_train, _                     = d_model(images_lab, training=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="The-discriminator’s-loss"><a href="#The-discriminator’s-loss" class="headerlink" title="The discriminator’s loss"></a>The discriminator’s loss</h1><p>&emsp;&emsp;Recall that the discriminator will be doing more than just separating fake from real. It also classifies the labeled data. For this, we define a supervised loss which takes the softmax output. In terms of implementation, this means that we feed the unnormalized logits to <code>tf.nn.sparse_cross_entropy_with_logits</code>.<br>&emsp;&emsp;Defining the loss for the unsupervised part is where things get a little bit more involved. Because the softmax distribution is overparameterized, we can fix the unnormalized logit at 0 for an image to be fake (i.e. coming from the generator). If we do so, the probability of it being real just turns into:</p>
<script type="math/tex; mode=display">p(x)=\frac{Z(x)}{Z(x)+exp(l_{fake})} = \frac{Z(x)}{Z(x)+1}</script><p>&emsp;&emsp;where Z(x) is the sum of the unnormalized probabilities. Note that we currently only have the logits. Ultimately, we want to use the log-probability of the fake class to define our loss function. This can now be achieved by computing the whole expression in log-space:</p>
<script type="math/tex; mode=display">log(p(x)) = log(Z(x)) - log(1+Z(x)) = logsumexp(l_1,...,l_K) - softplus(logsumexp(l_1,...,l_K))</script><p>&emsp;&emsp;Where the lower case l with subscripts denote the individual logits. Divisions become subtractions and sums can be computed by the logsumexp function. Finally, we have used the definition of the softplus function:</p>
<script type="math/tex; mode=display">softplus(x) = log(1+x)</script><p>&emsp;&emsp;In general, if you have the log-representation of a probability, it is numerically safer to keep things in log-space for as long as you can, since we are able to represent much smaller numbers in that case.<br>&emsp;&emsp;We’re not there yet. Generative adversarial training asks us to ascend the gradient of:</p>
<script type="math/tex; mode=display">log(D(x)) + log(1-D(G(z)))</script><p>&emsp;&emsp;So whenever we call <code>tf.train.AdamOptimizer.minimize</code> we should descent:</p>
<script type="math/tex; mode=display">-log(D(x)) - log(1-D(G(z))) = -log(\frac{Z(x)}{1+Z(x)})-log(1-\frac{Z(G(z))}{1+Z(G(z))})</script><p>&emsp;&emsp;The first term on the right-hand side of the equation can be written:</p>
<script type="math/tex; mode=display">softplus(logsumexp(l^{(x)}_1,...,l^{(x)}_K)) - logsumexp(l^{(x)}_1,...,l^{(x)}_K)</script><p>&emsp;&emsp;The second term of the right-hand side can be written as:</p>
<script type="math/tex; mode=display">-log(1-\frac{Z(G(z))}{1+Z(G(z))}) = -log(\frac{1}{1+Z(G(z))}) = softplus(logsumexp(l^{G(z)}_1,...,l^{G(z)}_K))</script><p>&emsp;&emsp;So that finally, we arrive at the following loss:</p>
<script type="math/tex; mode=display">softplus(logsumexp(l^{(x)}_1,...,l^{(x)}_K)) - logsumexp(l^{(x)}_1,...,l^{(x)}_K) + softplus(logsumexp(l^{G(z)}_1,...,l^{G(z)}_K))</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Set the discriminator losses</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"DiscriminatorLoss"</span>):</span><br><span class="line">    <span class="comment"># Supervised loss, just cross-entropy. This normalizes p(y|x) where 1 &lt;= y &lt;= K</span></span><br><span class="line">    loss_supervised = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(</span><br><span class="line">        labels=labels_lab, logits=logits_real_lab))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Sum of unnormalized log probabilities</span></span><br><span class="line">    logits_sum_real = tf.reduce_logsumexp(logits_real_unl, axis=<span class="number">1</span>)</span><br><span class="line">    logits_sum_fake = tf.reduce_logsumexp(logits_fake, axis=<span class="number">1</span>)</span><br><span class="line">    loss_unsupervised = <span class="number">0.5</span> * (</span><br><span class="line">        tf.negative(tf.reduce_mean(logits_sum_real)) +</span><br><span class="line">        tf.reduce_mean(tf.nn.softplus(logits_sum_real)) +</span><br><span class="line">        tf.reduce_mean(tf.nn.softplus(logits_sum_fake)))</span><br><span class="line">    loss_d = loss_supervised + loss_unsupervised</span><br></pre></td></tr></table></figure>
<h1 id="Optimizing-the-discriminator"><a href="#Optimizing-the-discriminator" class="headerlink" title="Optimizing the discriminator"></a>Optimizing the discriminator</h1><p>&emsp;&emsp;Let’s setup the operations for actually updating the parameters of the discriminator. We will just reside to the Adam optimizer. While tweaking the parameters before I wrote this post, I figured I might slow down the discriminator by setting its learning rate at 0.1 times that of the generator. After that my results got much better, so I decided to leave it there for now. Notice also that we can very easily select the subset of variables corresponding to the discriminator by exploiting the encapsulation offered by Keras.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Configure discriminator training ops</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"Train"</span>) <span class="keyword">as</span> train_scope:</span><br><span class="line">    optimizer = tf.train.AdamOptimizer(flags_obj.lr * <span class="number">0.1</span>)</span><br><span class="line">    optimize_d = optimizer.minimize(loss_d, var_list=d_model.trainable_variables)</span><br><span class="line">    train_accuracy_op = accuracy(logits_train, labels_lab)</span><br></pre></td></tr></table></figure></p>
<h1 id="Adding-some-control-flow-to-the-graph"><a href="#Adding-some-control-flow-to-the-graph" class="headerlink" title="Adding some control flow to the graph"></a>Adding some control flow to the graph</h1><p>&emsp;&emsp;After we have the new weights for the discriminator, we want the generator’s update to be aware of the updated weights. TensorFlow will not guarantee that the updated weights will actually be used even if we were to redeclare the forward computation after defining the minimization operations for the discriminator. We can still force this by using <code>tf.control_dependencies</code>. Any operation defined in the scope of this context manager will depend on the evaluation of the ones that are passed to context manager at instantiation. In other words, our generator’s update that we define later on will be guaranteed to compute the gradients using the updated weights of the discriminator.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(discriminator_scope):</span><br><span class="line">    <span class="keyword">with</span> tf.control_dependencies([optimize_d]):</span><br><span class="line">        <span class="comment"># Build a second time, so that new variables are used</span></span><br><span class="line">        logits_fake, features_fake = d_model(images_fake, training=<span class="literal">True</span>)</span><br><span class="line">        logits_real_unl, features_real_unl = d_model(images_unl2, training=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="The-generator’s-loss-and-updates"><a href="#The-generator’s-loss-and-updates" class="headerlink" title="The generator’s loss and updates"></a>The generator’s loss and updates</h1><p>&emsp;&emsp;In this implementation, the generator tries to minimize the L2 distance of the average features of the generated images vs. the average features of the real images. This <a href="https://arxiv.org/abs/1606.03498" target="_blank" rel="noopener">feature-matching loss</a> (Salimans et al., 2016) has proven to be more stable for training GANs than directly trying to optimize the discriminator’s probability for observing real data. It is straightforward to implement. While we’re at it, let’s also define the update operations for the generator. Notice that the learning rate of this optimizer is 10 times that of the discriminator.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Set the generator loss and the actual train op</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"GeneratorLoss"</span>):</span><br><span class="line">    feature_mean_real = tf.reduce_mean(features_real_unl, axis=<span class="number">0</span>)</span><br><span class="line">    feature_mean_fake = tf.reduce_mean(features_fake, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># L1 distance of features is the loss for the generator</span></span><br><span class="line">    loss_g = tf.reduce_mean(tf.abs(feature_mean_real - feature_mean_fake))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(train_scope):</span><br><span class="line">    optimizer = tf.train.AdamOptimizer(flags_obj.lr, beta1=<span class="number">0.5</span>)</span><br><span class="line">    train_op = optimizer.minimize(loss_g, var_list=g_model.trainable_variables)</span><br></pre></td></tr></table></figure></p>
<h1 id="Adding-manifold-regularization"><a href="#Adding-manifold-regularization" class="headerlink" title="Adding manifold regularization"></a>Adding manifold regularization</h1><p>&emsp;&emsp;<a href="https://arxiv.org/abs/1805.08957" target="_blank" rel="noopener">Lecouat et. al</a> (2018) propose to add manifold regularization to the feature-matching GAN training procedure of <a href="https://arxiv.org/abs/1606.03498" target="_blank" rel="noopener">Salimans et al. (2016)</a>. The regularization forces the discriminator to yield similar logits (unnormalized log probabilities) for nearby points in the latent space in which z resides. It can be implemented by generating a second perturbed version of z and computing the generator’s and discriminator’s outputs once more with this slightly altered vector.    </p>
<p>&emsp;&emsp;This means that the noise generation code looks as follows:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">define_noise</span><span class="params">(batch_size_tensor, flags_obj)</span>:</span></span><br><span class="line">    <span class="comment"># Setup noise vector</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">"LatentNoiseVector"</span>):</span><br><span class="line">        z = tfd.Normal(loc=<span class="number">0.0</span>, scale=flags_obj.stddev).sample(</span><br><span class="line">            sample_shape=(batch_size_tensor, flags_obj.z_dim_size))</span><br><span class="line">        z_perturbed = z + tfd.Normal(loc=<span class="number">0.0</span>, scale=flags_obj.stddev).sample(</span><br><span class="line">            sample_shape=(batch_size_tensor, flags_obj.z_dim_size)) * <span class="number">1e-5</span></span><br><span class="line">    <span class="keyword">return</span> z, z_perturbed</span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;The discriminator’s loss will be updated as follows (note the 3 extra lines at the bottom):<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set the discriminator losses</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"DiscriminatorLoss"</span>):</span><br><span class="line">    <span class="comment"># Supervised loss, just cross-entropy. This normalizes p(y|x) where 1 &lt;= y &lt;= K</span></span><br><span class="line">    loss_supervised = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(</span><br><span class="line">        labels=labels_lab, logits=logits_real_lab))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Sum of unnormalized log probabilities</span></span><br><span class="line">    logits_sum_real = tf.reduce_logsumexp(logits_real_unl, axis=<span class="number">1</span>)</span><br><span class="line">    logits_sum_fake = tf.reduce_logsumexp(logits_fake, axis=<span class="number">1</span>)</span><br><span class="line">    loss_unsupervised = <span class="number">0.5</span> * (</span><br><span class="line">        tf.negative(tf.reduce_mean(logits_sum_real)) +</span><br><span class="line">        tf.reduce_mean(tf.nn.softplus(logits_sum_real)) +</span><br><span class="line">        tf.reduce_mean(tf.nn.softplus(logits_sum_fake)))</span><br><span class="line">    loss_d = loss_supervised + loss_unsupervised</span><br><span class="line">    <span class="keyword">if</span> flags_obj.man_reg:</span><br><span class="line">        loss_d += <span class="number">1e-3</span> * tf.nn.l2_loss(logits_fake - logits_fake_perturbed) \</span><br><span class="line">            / tf.to_float(batch_size_tensor)</span><br></pre></td></tr></table></figure></p>
<h1 id="Classification-performance"><a href="#Classification-performance" class="headerlink" title="Classification performance"></a>Classification performance</h1><p>&emsp;&emsp;So how does it really perform? I have provided a few plots below. There are many things I might try to squeeze out additional performance (for instance, just training for longer, using a learning rate schedule, implementing weight normalization), but the main purpose of writing this post was to get to know a relatively simple yet powerful semi-supervised learning approach. After 100 epochs of training, the mean test accuracy approaches 98.9 percent.<br>&emsp;&emsp;The full script can be found <a href="https://github.com/jostosh/gan" target="_blank" rel="noopener">here</a>. Thanks for reading!<br><img src="/images/Semi-supervised-learning-with-GANs/jpeg1-1.jpeg" alt></p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a href="https://medium.com/@jos.vandewolfshaar/semi-supervised-learning-with-gans-23255865d0a4" target="_blank" rel="noopener">Semi-supervised learning with GANs</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/semi-supervised-learning-and-gans.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/semi-supervised-learning-and-gans.html" class="post-title-link" itemprop="url">Semi-Supervised Learning and GANs</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-09 09:50:06 / 修改时间：11:05:07" itemprop="dateCreated datePublished" datetime="2019-05-09T09:50:06+08:00">2019-05-09</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">13k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">12 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="/images/Semi-Supervised-Learning-and-GANs/jpeg1-1.jpeg" alt><br>&emsp;&emsp;Vincent Van Gogh painted this beautiful art: ‘The Starry Night’ in 1889 and today my GAN model (I like to call it GAN Gogh :P) painted some MNIST digits with only 20% labeled data!! How could it achieve this remarkable feat? … Let’s find out </p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p><strong><em>What is semi-supervised learning?</em></strong><br>&emsp;&emsp;Most deep learning classifiers require a large amount of labeled samples to generalize well, but getting such data is an expensive and difficult process. To deal with this limitation Semi-supervised learning is presented, which is a class of techniques that make use of a morsel of labeled data along with a large amount of unlabeled data.<code>Many machine-learning researchers have found that unlabeled data, when used in conjunction with a small amount of labeled data can produce considerable improvement in learning accuracy</code>. GANs have shown a lot of potential in semi-supervised learning where the classifier can obtain a good performance with very few labeled data.</p>
<p><strong><em>Background on GANs</em></strong><br>&emsp;&emsp;GANs are members of deep generative models. They are particularly interesting because they don’t explicitly represent a probability distribution over the space where the data lies. Instead, they provide some way of interacting less directly with this probability distribution by drawing samples from it.<br><img src="/images/Semi-Supervised-Learning-and-GANs/png1-1.png" alt="Architecture of a Vanilla GAN"><br>The basic idea of GAN is to set up a game between two players:</p>
<ul>
<li>A generator G: Takes random noise z as input and outputs an image x. Its parameters are tuned to get a high score from the discriminator on fake images that it generates.</li>
<li>A discriminator D: Takes an image x as input and outputs a score which reflects its confidence that it is a real image. Its parameters are tuned to have a high score when it is fed by a real image, and a low score when a fake image is fed from the generator.</li>
</ul>
<p>&emsp;&emsp;I suggest you to go through this and this for more details on their working and optimisation objectives. Now, let us turn the wheels a little and talk about one of the most prominent applications of GANs, semi-supervised learning.</p>
<h1 id="Intuition"><a href="#Intuition" class="headerlink" title="Intuition"></a>Intuition</h1><p>&emsp;&emsp;The vanilla architecture of discriminator has only one output neuron for classifying the R/F probabilities. We train both the networks simultaneously and discard the discriminator after the training as it was used only for improving the generator.<br><img src="/images/Semi-Supervised-Learning-and-GANs/png1-2.png" alt><br>&emsp;&emsp;For the semi-supervised task, in addition to R/F neuron, the discriminator will now have 10 more neurons for classification of MNIST digits. Also, this time their roles change and we can discard the generator after training, whose only objective was to generate unlabeled data to improve the discriminator’s performance.<br><strong><em>&emsp;&emsp;Now the discriminator is turned into an 11-class classifier with 1 neuron (R/F neuron) representing the fake data output and the other 10 representing real data with classes. The following has to be kept in mind:</em></strong></p>
<ul>
<li>To assert R/F neuron output label = 0, when real unsupervised data from dataset is fed </li>
<li>To assert R/F neuron output label= 1, when fake unsupervised data from generator is fed </li>
<li>To assert R/F output label = 0 and corresponding label output = 1, when real supervised data is fed </li>
</ul>
<p>This combination of different sources of data will help the discriminator classify more accurately than, if it had been only provided with a portion of labeled data.</p>
<h1 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h1><p>Now it’s time to get our hands dirty with some code :D<br><strong><em>The Discriminator</em></strong><br>&emsp;&emsp;The architecture followed is similar to the one proposed in <a href="https://arxiv.org/pdf/1511.06434.pdf" target="_blank" rel="noopener">DCGAN paper</a>. We use strided convolutions for reducing the dimensions of the feature-vectors rather than any pooling layers and apply a series of leaky_relu, dropout and BN for all layers to stabilize the learning. BN is dropped for input layer and last layer (for the purpose of feature matching). In the end, we perform Global Average Pooling to take the average over the spatial dimensions of the feature vectors. This squashes the tensor dimensions to a single value. After flattening the features, a dense layer of 11 classes is added with softmax activation for multi-class output.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discriminator</span><span class="params">(x, dropout_rate = <span class="number">0.</span>, is_training = True, reuse = False)</span>:</span></span><br><span class="line">   <span class="comment"># input x -&gt; n+1 classes</span></span><br><span class="line">   <span class="keyword">with</span> tf.variable_scope(<span class="string">'Discriminator'</span>, reuse = reuse): </span><br><span class="line">     <span class="comment"># x = ?*64*64*1</span></span><br><span class="line">     </span><br><span class="line">     <span class="comment">#Layer 1</span></span><br><span class="line">     conv1 = tf.layers.conv2d(x, <span class="number">128</span>, kernel_size = [<span class="number">4</span>,<span class="number">4</span>], strides = [<span class="number">2</span>,<span class="number">2</span>],</span><br><span class="line">                             padding = <span class="string">'same'</span>, activation = tf.nn.leaky_relu, name = <span class="string">'conv1'</span>) <span class="comment"># ?*32*32*128</span></span><br><span class="line">     <span class="comment">#No batch-norm for input layer</span></span><br><span class="line">     dropout1 = tf.nn.dropout(conv1, dropout_rate)</span><br><span class="line">     </span><br><span class="line">     <span class="comment">#Layer2</span></span><br><span class="line">     conv2 = tf.layers.conv2d(dropout1, <span class="number">256</span>, kernel_size = [<span class="number">4</span>,<span class="number">4</span>], strides = [<span class="number">2</span>,<span class="number">2</span>],</span><br><span class="line">                             padding = <span class="string">'same'</span>, activation = tf.nn.leaky_relu, name = <span class="string">'conv2'</span>) <span class="comment"># ?*16*16*256</span></span><br><span class="line">     batch2 = tf.layers.batch_normalization(conv2, training = is_training)</span><br><span class="line">     dropout2 = tf.nn.dropout(batch2, dropout_rate)</span><br><span class="line">     </span><br><span class="line">     <span class="comment">#Layer3</span></span><br><span class="line">     conv3 = tf.layers.conv2d(dropout2, <span class="number">512</span>, kernel_size = [<span class="number">4</span>,<span class="number">4</span>], strides = [<span class="number">4</span>,<span class="number">4</span>],</span><br><span class="line">                             padding = <span class="string">'same'</span>, activation = tf.nn.leaky_relu, name = <span class="string">'conv3'</span>) <span class="comment"># ?*4*4*512</span></span><br><span class="line">     batch3 = tf.layers.batch_normalization(conv3, training = is_training)</span><br><span class="line">     dropout3 = tf.nn.dropout(batch3, dropout_rate)</span><br><span class="line">       </span><br><span class="line">     <span class="comment"># Layer 4</span></span><br><span class="line">     conv4 = tf.layers.conv2d(dropout3, <span class="number">1024</span>, kernel_size=[<span class="number">3</span>,<span class="number">3</span>], strides=[<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">                              padding=<span class="string">'valid'</span>,activation = tf.nn.leaky_relu, name=<span class="string">'conv4'</span>) <span class="comment"># ?*2*2*1024</span></span><br><span class="line">     <span class="comment"># No batch-norm as this layer's op will be used in feature matching loss</span></span><br><span class="line">     <span class="comment"># No dropout as feature matching needs to be definite on logits</span></span><br><span class="line"></span><br><span class="line">     <span class="comment"># Layer 5</span></span><br><span class="line">     <span class="comment"># Note: Applying Global average pooling        </span></span><br><span class="line">     flatten = tf.reduce_mean(conv4, axis = [<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">     logits_D = tf.layers.dense(flatten, (<span class="number">1</span> + num_classes))</span><br><span class="line">     out_D = tf.nn.softmax(logits_D)     </span><br><span class="line">   <span class="keyword">return</span> flatten,logits_D,out_D</span><br></pre></td></tr></table></figure></p>
<p><strong><em>The Generator</em></strong><br>&emsp;&emsp;The generator architecture is designed to mirror the discriminator’s spatial outputs. Fractional strided convolutions are used to increase the spatial dimension of the representation. An input of 4-D tensor of noise z is fed which undergoes a series of transposed convolutions, relu, BN(except at output layer) and dropout operations. Finally tanh activation maps the output image in range (-1,1).<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">(z, dropout_rate = <span class="number">0.</span>, is_training = True, reuse = False)</span>:</span></span><br><span class="line">    <span class="comment"># input latent z -&gt; image x</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'Generator'</span>, reuse = reuse):</span><br><span class="line">      <span class="comment">#Layer 1</span></span><br><span class="line">      deconv1 = tf.layers.conv2d_transpose(z, <span class="number">512</span>, kernel_size = [<span class="number">4</span>,<span class="number">4</span>],</span><br><span class="line">                                         strides = [<span class="number">1</span>,<span class="number">1</span>], padding = <span class="string">'valid'</span>,</span><br><span class="line">                                        activation = tf.nn.relu, name = <span class="string">'deconv1'</span>) <span class="comment"># ?*4*4*512</span></span><br><span class="line">      batch1 = tf.layers.batch_normalization(deconv1, training = is_training)</span><br><span class="line">      dropout1 = tf.nn.dropout(batch1, dropout_rate)</span><br><span class="line">      </span><br><span class="line">      <span class="comment">#Layer 2</span></span><br><span class="line">      deconv2 = tf.layers.conv2d_transpose(dropout1, <span class="number">256</span>, kernel_size = [<span class="number">4</span>,<span class="number">4</span>],</span><br><span class="line">                                         strides = [<span class="number">4</span>,<span class="number">4</span>], padding = <span class="string">'same'</span>,</span><br><span class="line">                                        activation = tf.nn.relu, name = <span class="string">'deconv2'</span>)<span class="comment"># ?*16*16*256</span></span><br><span class="line">      batch2 = tf.layers.batch_normalization(deconv2, training = is_training)</span><br><span class="line">      dropout2 = tf.nn.dropout(batch2, dropout_rate)</span><br><span class="line">        </span><br><span class="line">      <span class="comment">#Layer 3</span></span><br><span class="line">      deconv3 = tf.layers.conv2d_transpose(dropout2, <span class="number">128</span>, kernel_size = [<span class="number">4</span>,<span class="number">4</span>],</span><br><span class="line">                                         strides = [<span class="number">2</span>,<span class="number">2</span>], padding = <span class="string">'same'</span>,</span><br><span class="line">                                        activation = tf.nn.relu, name = <span class="string">'deconv3'</span>)<span class="comment"># ?*32*32*256</span></span><br><span class="line">      batch3 = tf.layers.batch_normalization(deconv3, training = is_training)</span><br><span class="line">      dropout3 = tf.nn.dropout(batch3, dropout_rate)</span><br><span class="line">      </span><br><span class="line">      <span class="comment">#Output layer</span></span><br><span class="line">      deconv4 = tf.layers.conv2d_transpose(dropout3, <span class="number">1</span>, kernel_size = [<span class="number">4</span>,<span class="number">4</span>],</span><br><span class="line">                                        strides = [<span class="number">2</span>,<span class="number">2</span>], padding = <span class="string">'same'</span>,</span><br><span class="line">                                        activation = <span class="literal">None</span>, name = <span class="string">'deconv4'</span>)<span class="comment"># ?*64*64*1</span></span><br><span class="line">      out = tf.nn.tanh(deconv4)</span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure></p>
<h1 id="Model-Loss"><a href="#Model-Loss" class="headerlink" title="Model Loss"></a>Model Loss</h1><p>&emsp;&emsp;We start by preparing an extended label for the whole batch by appending actual label to zeros. This is done to assert the R/F neuron output to 0 when the labeled data is fed. The discriminator loss for unlabeled data can be thought of as a binary sigmoid loss by asserting R/F neuron output to 1 for fake images and 0 for real images.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">             <span class="comment">### Discriminator loss ###</span></span><br><span class="line"><span class="comment"># Supervised loss -&gt; which class the real data belongs to    </span></span><br><span class="line">temp = tf.nn.softmax_cross_entropy_with_logits_v2(logits = D_real_logit,</span><br><span class="line">                                              labels = extended_label) </span><br><span class="line"><span class="comment"># Labeled_mask and temp are of same size = batch_size where temp is softmax cross_entropy calculated over whole batch</span></span><br><span class="line"></span><br><span class="line">D_L_Supervised = tf.reduce_sum(tf.multiply(temp,labeled_mask)) / tf.reduce_sum(labeled_mask)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Multiplying temp with labeled_mask gives supervised loss on labeled_mask</span></span><br><span class="line"><span class="comment"># data only, calculating mean by dividing by no of labeled samples</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Unsupervised loss -&gt; R/F    </span></span><br><span class="line">D_L_RealUnsupervised = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(</span><br><span class="line">        logits = D_real_logit[:, <span class="number">0</span>], labels = tf.zeros_like(D_real_logit[:, <span class="number">0</span>], dtype=tf.float32)))</span><br><span class="line"></span><br><span class="line">D_L_FakeUnsupervised = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(</span><br><span class="line">        logits = D_fake_logit[:, <span class="number">0</span>], labels = tf.ones_like(D_fake_logit[:, <span class="number">0</span>], dtype=tf.float32)))</span><br><span class="line"></span><br><span class="line">D_L = D_L_Supervised + D_L_RealUnsupervised + D_L_FakeUnsupervised</span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;Generator loss is a combination of fake_image loss which falsely wants to assert R/F neuron output to 0 and feature matching loss which penalizes the mean absolute error between the average value of some set of features on the training data and the average values of that set of features on the generated samples.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">             <span class="comment">### Generator loss ###                </span></span><br><span class="line"><span class="comment"># G_L_1 -&gt; Fake data wanna be real </span></span><br><span class="line"></span><br><span class="line">G_L_1 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(</span><br><span class="line">        logits = D_fake_logit[:, <span class="number">0</span>],labels = tf.zeros_like(D_fake_logit[:, <span class="number">0</span>], dtype=tf.float32)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># G_L_2 -&gt; Feature matching</span></span><br><span class="line">data_moments = tf.reduce_mean(D_real_features, axis = <span class="number">0</span>)</span><br><span class="line">sample_moments = tf.reduce_mean(D_fake_features, axis = <span class="number">0</span>)</span><br><span class="line">G_L_2 = tf.reduce_mean(tf.square(data_moments-sample_moments))</span><br><span class="line"></span><br><span class="line">G_L = G_L_1 + G_L_2</span><br></pre></td></tr></table></figure></p>
<h1 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h1><p>&emsp;&emsp;The training images are resized from [batch_size, 28 ,28 , 1] to [batch_size, 64, 64, 1] to fit the generator/discriminator architectures. Losses, accuracies and generated samples are calculated and are observed to improve over each epoch.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">  train_accuracies, train_D_losses, train_G_losses = [], [], []</span><br><span class="line">  <span class="keyword">for</span> it <span class="keyword">in</span> range(no_of_batches):</span><br><span class="line">  </span><br><span class="line">  batch = mnist_data.train.next_batch(batch_size, shuffle = <span class="literal">False</span>)</span><br><span class="line">  <span class="comment"># batch[0] has shape: batch_size*28*28*1         </span></span><br><span class="line">  batch_reshaped = tf.image.resize_images(batch[<span class="number">0</span>], [<span class="number">64</span>, <span class="number">64</span>]).eval()</span><br><span class="line">  <span class="comment"># Reshaping the whole batch into batch_size*64*64*1 for disc/gen architecture</span></span><br><span class="line">  batch_z = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (batch_size, <span class="number">1</span>, <span class="number">1</span>, latent))</span><br><span class="line">  mask = get_labeled_mask(labeled_rate, batch_size)</span><br><span class="line">                </span><br><span class="line">  train_feed_dict = &#123;x : scale(batch_reshaped), z : batch_z,</span><br><span class="line">                              label : batch[<span class="number">1</span>], labeled_mask : mask,</span><br><span class="line">                               dropout_rate : <span class="number">0.7</span>, is_training : <span class="literal">True</span>&#125;</span><br><span class="line">  <span class="comment">#The label provided in dict are one hot encoded in 10 classes</span></span><br><span class="line">                </span><br><span class="line">  D_optimizer.run(feed_dict = train_feed_dict)</span><br><span class="line">  G_optimizer.run(feed_dict = train_feed_dict)</span><br><span class="line">                </span><br><span class="line">  train_D_loss = D_L.eval(feed_dict = train_feed_dict)</span><br><span class="line">  train_G_loss = G_L.eval(feed_dict = train_feed_dict)</span><br><span class="line">  train_accuracy = accuracy.eval(feed_dict = train_feed_dict)</span><br><span class="line">          </span><br><span class="line">  train_D_losses.append(train_D_loss)</span><br><span class="line">  train_G_losses.append(train_G_loss)</span><br><span class="line">  train_accuracies.append(train_accuracy)</span><br><span class="line">          </span><br><span class="line">  tr_GL = np.mean(train_G_losses)</span><br><span class="line">  tr_DL = np.mean(train_D_losses)</span><br><span class="line">  tr_acc = np.mean(train_accuracies)       </span><br><span class="line">  </span><br><span class="line">  <span class="keyword">print</span> (<span class="string">'After epoch: '</span>+ str(epoch+<span class="number">1</span>) + <span class="string">' Generator loss: '</span></span><br><span class="line">                       + str(tr_GL) + <span class="string">' Discriminator loss: '</span> + str(tr_DL) + <span class="string">' Accuracy: '</span> + str(tr_acc))</span><br><span class="line">        </span><br><span class="line">  gen_samples = fake_data.eval(feed_dict = &#123;z : np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (<span class="number">25</span>, <span class="number">1</span>, <span class="number">1</span>, latent)), dropout_rate : <span class="number">0.7</span>, is_training : <span class="literal">False</span>&#125;)</span><br><span class="line">  <span class="comment"># Dont train batch-norm while plotting =&gt; is_training = False</span></span><br><span class="line">  test_images = tf.image.resize_images(gen_samples, [<span class="number">64</span>, <span class="number">64</span>]).eval()</span><br><span class="line">  show_result(test_images, (epoch + <span class="number">1</span>), show = <span class="literal">True</span>, save = <span class="literal">False</span>, path = <span class="string">''</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>&emsp;&emsp;The training was done for 5 epochs and 20% labeled_rate due to restricted GPU access. For better results more training epochs with lesser labeled_rate is advised. The complete code notebook can be found <a href="https://github.com/raghav64/SemiSuper_GAN/blob/master/SSGAN.py" target="_blank" rel="noopener">here</a>.<br><img src="/images/Semi-Supervised-Learning-and-GANs/jpeg1-2.jpeg" alt="Training Results"><br>&emsp;&emsp;Unsupervised learning is considered as a lacuna in the field of AGI. To bridge this gap, GANs are considered as a potential solution for learning complex tasks with low labeled data. With blooming new approaches in the domain of semi and unsupervised learning we can expect that this gap will lessen.<br>&emsp;&emsp;I would be remiss not to mention my inspiration from this beautiful blog, this implementation along with the assistance of my colleague working on similar projects.<br><strong><em>Until next time!! Kz</em></strong></p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a href="https://towardsdatascience.com/semi-supervised-learning-and-gans-f23bbf4ac683" target="_blank" rel="noopener">Semi-Supervised Learning and GANs</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/shou-ba-shou-jiao-ni-yong-gan-shi-xian-ban-jian-du-xue-xi.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/shou-ba-shou-jiao-ni-yong-gan-shi-xian-ban-jian-du-xue-xi.html" class="post-title-link" itemprop="url">手把手教你用GAN实现半监督学习</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-08 22:30:59" itemprop="dateCreated datePublished" datetime="2019-05-08T22:30:59+08:00">2019-05-08</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-09 09:17:40" itemprop="dateModified" datetime="2019-05-09T09:17:40+08:00">2019-05-09</time>
              
            
          </span>

          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">20k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">18 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>&emsp;&emsp;本文主要介绍如何在tensorflow上仅使用200个带标签的mnist图像，实现在一万张测试图片上99%的测试精度，原理在于使用GAN做半监督学习。前文主要介绍一些原理部分，后文详细介绍代码及其实现原理。前文介绍比较简单，有基础的同学请略过直接看第二部分，文章末尾给出了代码GitHub链接。对GAN不了解的同学可以查看微信公众号：机器学习算法全栈工程师 的GAN入门文章。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">本博客中的代码最终以GitHub中的代码为准，GitHub链接在文章底部，另外，本文已投稿至微信公众号：机器学习算法全栈工程师，欢迎关注此公众号</span><br></pre></td></tr></table></figure></p>
<h1 id="1-监督，无监督，半监督学习介绍"><a href="#1-监督，无监督，半监督学习介绍" class="headerlink" title="1.监督，无监督，半监督学习介绍"></a>1.监督，无监督，半监督学习介绍</h1><p>&emsp;&emsp;在正式介绍实现半监督学习之前，我在这里首先介绍一下<u>监督学习（supervised learning），半监督学习（semi-supervised learning）和无监督学习（unsupervised learning）的区别</u>。</p>
<ul>
<li><font color="blue">监督学习</font>是指在训练集中包含训练数据的标签（label），比如类别标签，位置标签等等。最普遍使用标签学习的是分类任务，对于分类任务，输入给网络训练样本（samples）的一些特征（feature）以及此样本对应的标签（label），通过神经网络拟合的方法，神经网络可以在特征和标签之间找到一个合适的映射关系（mapping），这样当训练完成后，输入给网络没有label的样本，神经网络可以通过这一个映射关系猜出它属于哪一类。典型机器学习的监督学习的例子是KNN和SVM。目前机器视觉领域的急速发展离不开监督学习。 </li>
<li>而<font color="blue">无监督学习</font>的训练事先没有训练标签，直接输入给算法一些数据，算法会努力学习数据的共同点，寻找样本之间的规律性。无监督学习是很典型的学习，人的学习有时候就是基于无监督的，比如我并不懂音乐，但是我听了上百首歌曲后，我可以根据我听的结果将音乐分为摇滚乐（记为0类）、民谣（记为1类）、纯音乐（记为2类）等等，事实上，我并不知道具体是哪一类，所以将它们记为0，1，2三类。典型的无监督学习方法是聚类算法，比如k-means。 </li>
<li>东方快车电影里面大侦探有过一个台词，人们的话只有对与错，没有中间地带，最后经过一系列事件后他找到了对与错之间的betweeness。在监督学习和无监督学习之间，同样存在着中间地带——<font color="blue">半监督学习</font>。半监督学习简单来说就是将无监督学习和监督学习相结合，一部分包含了监督学习一部分包含了无监督学习，比如给一个分类任务，此分类任务的训练集中有精确标签的数据非常少，但是包含了大量的没有标注的数据，如果直接用监督学习的方法去做的话，效果不一定很好，有标注的训练数据太少很容易导致过拟合，而且大量的无标注的数据都没有充分的利用，最常见的例子是在医学图像的分析检测任务中，医学图像本身就不容易获得，要获得精标注的图像就需要有经验的医生去一个一个标注，显然他们并没有那么多的时间。这时候就是半监督学习的用武之地了，<u>半监督学习很适合用在标签数据少，训练数据又比较多的情况</u>。<br>常见的半监督学习方法主要有：<br>&emsp;&emsp;1.<strong><em>Self training </em></strong><br>&emsp;&emsp;2.<strong><em>Generative model </em></strong><br>&emsp;&emsp;3.<strong><em>S3VMs </em></strong><br>&emsp;&emsp;4.<strong><em>Graph-Based AIgorithems </em></strong><br>&emsp;&emsp;5.<strong><em>Multiview AIgorithems   </em></strong></li>
</ul>
<p>&emsp;&emsp;接下来我会结合<strong><em>Improved Techniques for Training GANs</em></strong>这篇论文详细介绍如何使用目前最火的生成对抗模型GAN去实现半监督学习，也即是<font color="red">半监督学习的第二种方法</font>，并给出详细的代码解释，对理论不是很熟悉的同学可以直接看代码。另外注明：<u>我只复现了论文半监督学习的部分，之前也有人复现了此部分，但是我感觉他对原文有很大的曲解，他使用了所有的标签去帮助生成，并不在分类上，不太符合半监督学习的本质，而且代码很复杂</u>，感兴趣的可以去GitHub上搜ssgan,希望能帮助你。 </p>
<h1 id="2-Improved-Techniques-for-Training-GANs"><a href="#2-Improved-Techniques-for-Training-GANs" class="headerlink" title="2. Improved Techniques for Training GANs"></a>2. Improved Techniques for Training GANs</h1><p>&emsp;&emsp;GAN是无监督学习的代表，它可以不断学习模拟数据的分布进而生成和训练数据相似分布的样本，在训练过程不需要标签，<u>GAN在无监督学习领域，生成领域，半监督学习领域以及强化学习领域都有广泛的应用</u>。但是GAN存在很多的训练不稳定等等的问题，作者good fellow在2016年放出了Improved Techniques for Training GANs，对GAN训练不稳定的问题做了一些解释和经验上的解决方案，并给出了和半监督学习结合的方法。<br>&emsp;&emsp;从平衡点角度解释GAN的不稳定性来说，GAN的<b>纳什均衡点</b>是一个鞍点，并不是一个局部最小值点，基于梯度的方法主要是寻找高维空间中的极小值点，因此使用梯度训练的方法很难使GAN收敛到平衡点。为此，为了进一部分缓解这个问题，goodfellow联合提出了一些改进方案，<br>主要有： </p>
<ul>
<li>Feature matching, </li>
<li>Minibatch discrimination </li>
<li>weight Historical averaging (相当于一个正则化的方式) </li>
<li>One-sided label smoothing </li>
<li>Virtual batch normalization </li>
</ul>
<p>后来发现<u>Feature matching在半监督学习上表现良好，mini-batch discrimination表现很差</u>。 </p>
<h1 id="3-semi-supervised-GAN"><a href="#3-semi-supervised-GAN" class="headerlink" title="3. semi-supervised GAN"></a>3. semi-supervised GAN</h1><p>&emsp;&emsp;对于一个普通的分类器来说，假设对MNIST分类，一共有10类数据，分别是0-9，分类器模型以数据x作为输入，输出一个K=10维的向量，经过softmax后计算出分类概率最大的那个类别。<u>在监督学习领域，往往是通过最小化类别标签和预测分布 的交叉熵来实现最好的结果</u>。<br>&emsp;&emsp;但是<font color="red">将GAN用在半监督学习领域</font>的时候需要做一些改变，生成器不做改变，仍然负责从输入噪声数据中生成图像，判别器D不在是一个简单的真假分类（二分类）器，假设输入数据有K类，D就是K+1的分类器，多出的那一类是判别输入是否是生成器G生成的图像。网络的流程图见下图：<br><img src="/images/手把手教你用GAN实现半监督学习/dib1-1.dib" alt><br>&emsp;&emsp;网络结构确定了之后就是损失函数的设计部分，借助GAN我们就可以从无标签数据中学习，只要知道输入数据是真实数据，那就可以通过最大化\(logP_{model}(y\in{1,2,…,K}|x)\)来实现，上述式子可解释为不管输入的是哪一类真的图片（不是生成器G生成的假图片），只要最大化输出它是真图像的概率就可以了，不需要具体分出是哪一类。由于GAN的生成器的参与，训练数据中有一半都是生成的假数据。<br>&emsp;&emsp;下面给出判别器D的损失函数设计，D损失函数包括两个部分，一个是<u>监督学习损失</u>，一个是<u>半监督学习损失</u>，具体公式如下： </p>
<script type="math/tex; mode=display">L=L_{supervised} + L_{unsupervised}</script><p>其中：<br><img src="/images/手把手教你用GAN实现半监督学习/png1-1.png" alt><br>对于无监督学习来说，只需要输出真假就可以了，不需要确定是哪一类，因此我们令 </p>
<script type="math/tex; mode=display">D(x)=1-logP_{model}(y\in{1,2,...,K}|x)</script><p>其中\( P_{model} \)表示判别是假图像的概率，那么D(x)就代表了输出是真图像的概率，那么无监督学习的损失函数就可以表示为 </p>
<script type="math/tex; mode=display">L_{unsupervised} = -\{E_{x\sim Pdata(x)}logD(x) + E_{z\sim noise}log(1-D(G(z)))\}</script><p>&emsp;&emsp;这不就是GAN的损失函数嘛！好了，到这里得出结论，在半监督学习中，判别器的分类要多分一类，多出的这一类表示的是生成器生成的假图像这一类，另外判别器的损失函数不仅包括了监督损失函数而且还有无监督的损失函数，在训练过程中同时最小化这两者。损失函数介绍完毕，接下来介绍代码实现部分。</p>
<h1 id="4-代码实现及解读"><a href="#4-代码实现及解读" class="headerlink" title="4.代码实现及解读"></a>4.代码实现及解读</h1><p>&emsp;&emsp;<font color="red">注：完整代码的GitHub连接在文章底部。这里只截取关键部分做介绍 </font><br>&emsp;&emsp;在代码中，我使用feature matching，one side label smoothing方式，并没有使用论文中介绍的Historical averaging,而是只对判别器D使用了简单的l2正则化，防止过拟合，另外论文中介绍的Minibatch discrimination, Virtual batch normalization等等都没有使用，主要是这两者在半监督学习中表现不是很好，但是如果想获得好的生成结果还是很有用的。<br>&emsp;&emsp;首先介绍网络结构部分，因为是在mnist数据集比较简单，所以随便搭了一个判别器和生成器，具体如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discriminator</span><span class="params">(self, name, inputs, reuse)</span>:</span></span><br><span class="line">        l = tf.shape(inputs)[<span class="number">0</span>]</span><br><span class="line">        inputs = tf.reshape(inputs, (l,self.img_size,self.img_size,self.dim))</span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(name,reuse=reuse):</span><br><span class="line">            out = []</span><br><span class="line">            output = conv2d(<span class="string">'d_con1'</span>,inputs,<span class="number">5</span>, <span class="number">64</span>, stride=<span class="number">2</span>, padding=<span class="string">'SAME'</span>) <span class="comment">#14*14</span></span><br><span class="line">            output1 = lrelu(self.bn(<span class="string">'d_bn1'</span>,output))</span><br><span class="line">            out.append(output1)</span><br><span class="line">            <span class="comment"># output1 = tf.contrib.keras.layers.GaussianNoise</span></span><br><span class="line">            output = conv2d(<span class="string">'d_con2'</span>, output1, <span class="number">3</span>, <span class="number">64</span>*<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="string">'SAME'</span>)<span class="comment">#7*7</span></span><br><span class="line">            output2 = lrelu(self.bn(<span class="string">'d_bn2'</span>, output))</span><br><span class="line">            out.append(output2)</span><br><span class="line">            output = conv2d(<span class="string">'d_con3'</span>, output2, <span class="number">3</span>, <span class="number">64</span>*<span class="number">4</span>, stride=<span class="number">1</span>, padding=<span class="string">'VALID'</span>)<span class="comment">#5*5</span></span><br><span class="line">            output3 = lrelu(self.bn(<span class="string">'d_bn3'</span>, output))</span><br><span class="line">            out.append(output3)</span><br><span class="line">            output = conv2d(<span class="string">'d_con4'</span>, output3, <span class="number">3</span>, <span class="number">64</span>*<span class="number">4</span>, stride=<span class="number">2</span>, padding=<span class="string">'VALID'</span>)<span class="comment">#2*2</span></span><br><span class="line">            output4 = lrelu(self.bn(<span class="string">'d_bn4'</span>, output))</span><br><span class="line">            out.append(output4)</span><br><span class="line">            output = tf.reshape(output4, [l, <span class="number">2</span>*<span class="number">2</span>*<span class="number">64</span>*<span class="number">4</span>])<span class="comment"># 2*2*64*4</span></span><br><span class="line">            output = fc(<span class="string">'d_fc'</span>, output, self.num_class)</span><br><span class="line">            <span class="comment"># output = tf.nn.softmax(output)</span></span><br><span class="line">            <span class="keyword">return</span> output, out</span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;其中conv2d()是卷积操作，参数依次是，<u>层的名字，输入tensor，卷积核大小，输出通道数，步长，padding</u>。判别器中每一层都加了归一化层，这里使用最简单的归一化，函数如下所示，另外每一层的激活函数使用leakyrelu。判别器D最终返回两个值，第一个是计算的logits，另外一个是一个列表，列表的每一个元素代表判别器每一层的输出，为接下来实现feature matching做准备。<br>&emsp;&emsp;生成器结构如下所示：<font color="red">其最后一层激活函数使用tanh</font><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">(self,name, noise, reuse)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(name,reuse=reuse):</span><br><span class="line">        l = self.batch_size</span><br><span class="line">        output = fc(<span class="string">'g_dc'</span>, noise, <span class="number">2</span>*<span class="number">2</span>*<span class="number">64</span>)</span><br><span class="line">        output = tf.reshape(output, [<span class="number">-1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">64</span>])</span><br><span class="line">        output = tf.nn.relu(self.bn(<span class="string">'g_bn1'</span>,output))</span><br><span class="line">        output = deconv2d(<span class="string">'g_dcon1'</span>,output,<span class="number">5</span>,outshape=[l, <span class="number">4</span>, <span class="number">4</span>, <span class="number">64</span>*<span class="number">4</span>])</span><br><span class="line">        output = tf.nn.relu(self.bn(<span class="string">'g_bn2'</span>,output))</span><br><span class="line"></span><br><span class="line">        output = deconv2d(<span class="string">'g_dcon2'</span>, output, <span class="number">5</span>, outshape=[l, <span class="number">8</span>, <span class="number">8</span>, <span class="number">64</span> * <span class="number">2</span>])</span><br><span class="line">        output = tf.nn.relu(self.bn(<span class="string">'g_bn3'</span>, output))</span><br><span class="line"></span><br><span class="line">        output = deconv2d(<span class="string">'g_dcon3'</span>, output, <span class="number">5</span>, outshape=[l, <span class="number">16</span>, <span class="number">16</span>,<span class="number">64</span> * <span class="number">1</span>])</span><br><span class="line">        output = tf.nn.relu(self.bn(<span class="string">'g_bn4'</span>, output))</span><br><span class="line"></span><br><span class="line">        output = deconv2d(<span class="string">'g_dcon4'</span>, output, <span class="number">5</span>, outshape=[l, <span class="number">32</span>, <span class="number">32</span>, self.dim])</span><br><span class="line">        output = tf.image.resize_images(output, (<span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">        <span class="comment"># output = tf.nn.relu(self.bn('g_bn4', output))</span></span><br><span class="line">        <span class="keyword">return</span> tf.nn.tanh(output)</span><br></pre></td></tr></table></figure></p>
<p>网络结构是根据DCGAN的结构改的，所以网络简要介绍到这里。</p>
<p>接下来介绍网络初始化方面：<br>首先在train.py里建立一个Train的类，并做一些初始化<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">from</span> glob <span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy.misc <span class="keyword">as</span> scm</span><br><span class="line"><span class="keyword">from</span> vlib.layers <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> vlib.load_data <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> vlib.plot <span class="keyword">as</span> plot</span><br><span class="line"><span class="keyword">import</span> vlib.my_extract <span class="keyword">as</span> dataload</span><br><span class="line"><span class="keyword">import</span> vlib.save_images <span class="keyword">as</span> save_img</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data <span class="comment">#as mnist_data</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'data/'</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># temp = 0.89</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Train</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, sess, args)</span>:</span></span><br><span class="line">        <span class="comment">#sess=tf.Session()</span></span><br><span class="line">        self.sess = sess</span><br><span class="line">        self.img_size = <span class="number">28</span>   <span class="comment"># the size of image</span></span><br><span class="line">        self.trainable = <span class="literal">True</span></span><br><span class="line">        self.batch_size = <span class="number">50</span>  <span class="comment"># must be even number</span></span><br><span class="line">        self.lr = <span class="number">0.0002</span></span><br><span class="line">        self.mm = <span class="number">0.5</span>      <span class="comment"># momentum term for adam</span></span><br><span class="line">        self.z_dim = <span class="number">128</span>   <span class="comment"># the dimension of noise z</span></span><br><span class="line">        self.EPOCH = <span class="number">50</span>    <span class="comment"># the number of max epoch</span></span><br><span class="line">        self.LAMBDA = <span class="number">0.1</span>  <span class="comment"># parameter of WGAN-GP</span></span><br><span class="line">        self.model = args.model  <span class="comment"># 'DCGAN' or 'WGAN'</span></span><br><span class="line">        self.dim = <span class="number">1</span>       <span class="comment"># RGB is different with gray pic</span></span><br><span class="line">        self.num_class = <span class="number">11</span></span><br><span class="line">        self.load_model = args.load_model</span><br><span class="line">        self.build_model()  <span class="comment"># initializer</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_model</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># build  placeholders</span></span><br><span class="line">        self.x=tf.placeholder(tf.float32,shape=[self.batch_size,self.img_size*self.img_size*self.dim],name=<span class="string">'real_img'</span>)</span><br><span class="line">        self.z = tf.placeholder(tf.float32, shape=[self.batch_size, self.z_dim], name=<span class="string">'noise'</span>)</span><br><span class="line">        self.label = tf.placeholder(tf.float32, shape=[self.batch_size, self.num_class - <span class="number">1</span>], name=<span class="string">'label'</span>)</span><br><span class="line">        self.flag = tf.placeholder(tf.float32, shape=[], name=<span class="string">'flag'</span>)</span><br><span class="line">        self.flag2 = tf.placeholder(tf.float32, shape=[], name=<span class="string">'flag2'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># define the network</span></span><br><span class="line">        self.G_img = self.generator(<span class="string">'gen'</span>, self.z, reuse=<span class="literal">False</span>)</span><br><span class="line">        d_logits_r, layer_out_r = self.discriminator(<span class="string">'dis'</span>, self.x, reuse=<span class="literal">False</span>)</span><br><span class="line">        d_logits_f, layer_out_f = self.discriminator(<span class="string">'dis'</span>, self.G_img, reuse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        d_regular = tf.add_n(tf.get_collection(<span class="string">'regularizer'</span>, <span class="string">'dis'</span>), <span class="string">'loss'</span>)  <span class="comment"># D regular loss</span></span><br><span class="line">        <span class="comment"># caculate the unsupervised loss</span></span><br><span class="line">        un_label_r = tf.concat([tf.ones_like(self.label), tf.zeros(shape=(self.batch_size, <span class="number">1</span>))], axis=<span class="number">1</span>)</span><br><span class="line">        un_label_f = tf.concat([tf.zeros_like(self.label), tf.ones(shape=(self.batch_size, <span class="number">1</span>))], axis=<span class="number">1</span>)</span><br><span class="line">        logits_r, logits_f = tf.nn.softmax(d_logits_r), tf.nn.softmax(d_logits_f)</span><br><span class="line">        d_loss_r = -tf.log(tf.reduce_sum(logits_r[:, :<span class="number">-1</span>])/tf.reduce_sum(logits_r[:,:]))</span><br><span class="line">        d_loss_f = -tf.log(tf.reduce_sum(logits_f[:, <span class="number">-1</span>])/tf.reduce_sum(logits_f[:,:]))</span><br><span class="line">        <span class="comment"># d_loss_r = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=un_label_r*0.9, logits=d_logits_r))</span></span><br><span class="line">        <span class="comment"># d_loss_f = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=un_label_f*0.9, logits=d_logits_f))</span></span><br><span class="line">        <span class="comment"># feature match</span></span><br><span class="line">        f_match = tf.constant(<span class="number">0.</span>, dtype=tf.float32)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">            f_match += tf.reduce_mean(tf.multiply(layer_out_f[i]-layer_out_r[i], layer_out_f[i]-layer_out_r[i]))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># caculate the supervised loss</span></span><br><span class="line">        s_label = tf.concat([self.label, tf.zeros(shape=(self.batch_size,<span class="number">1</span>))], axis=<span class="number">1</span>)</span><br><span class="line">        s_l_r = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=s_label*<span class="number">0.9</span>, logits=d_logits_r))</span><br><span class="line">        s_l_f = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=un_label_f*<span class="number">0.9</span>, logits=d_logits_f))  <span class="comment"># same as d_loss_f</span></span><br><span class="line">        self.d_l_1, self.d_l_2 = d_loss_r + d_loss_f, s_l_r</span><br><span class="line">        self.d_loss = d_loss_r + d_loss_f + s_l_r*self.flag*<span class="number">10</span> + d_regular</span><br><span class="line">        self.g_loss = d_loss_f + <span class="number">0.01</span>*f_match</span><br><span class="line"></span><br><span class="line">        all_vars = tf.global_variables()</span><br><span class="line">        g_vars = [v <span class="keyword">for</span> v <span class="keyword">in</span> all_vars <span class="keyword">if</span> <span class="string">'gen'</span> <span class="keyword">in</span> v.name]</span><br><span class="line">        d_vars = [v <span class="keyword">for</span> v <span class="keyword">in</span> all_vars <span class="keyword">if</span> <span class="string">'dis'</span> <span class="keyword">in</span> v.name]</span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> all_vars:</span><br><span class="line">            <span class="keyword">print</span> v</span><br><span class="line">        <span class="keyword">if</span> self.model == <span class="string">'DCGAN'</span>:</span><br><span class="line">            self.opt_d = tf.train.AdamOptimizer(self.lr, beta1=self.mm).minimize(self.d_loss, var_list=d_vars)</span><br><span class="line">            self.opt_g = tf.train.AdamOptimizer(self.lr, beta1=self.mm).minimize(self.g_loss, var_list=g_vars)</span><br><span class="line">        <span class="keyword">elif</span> self.model == <span class="string">'WGAN_GP'</span>:</span><br><span class="line">            self.opt_d = tf.train.AdamOptimizer(<span class="number">1e-5</span>, beta1=<span class="number">0.5</span>, beta2=<span class="number">0.9</span>).minimize(self.d_loss, var_list=d_vars)</span><br><span class="line">            self.opt_g = tf.train.AdamOptimizer(<span class="number">1e-5</span>, beta1=<span class="number">0.5</span>, beta2=<span class="number">0.9</span>).minimize(self.g_loss, var_list=g_vars)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">'model can only be "DCGAN","WGAN_GP" !'</span>)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="comment"># test</span></span><br><span class="line">        test_logits, _ = self.discriminator(<span class="string">'dis'</span>, self.x, reuse=<span class="literal">True</span>)</span><br><span class="line">        test_logits = tf.nn.softmax(test_logits)</span><br><span class="line">        temp = tf.reshape(test_logits[:, <span class="number">-1</span>],shape=[self.batch_size, <span class="number">1</span>])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">            temp = tf.concat([temp, tf.reshape(test_logits[:, <span class="number">-1</span>],shape=[self.batch_size, <span class="number">1</span>])], axis=<span class="number">1</span>)</span><br><span class="line">        test_logits -= temp</span><br><span class="line">        self.prediction = tf.nn.in_top_k(test_logits, tf.argmax(s_label, axis=<span class="number">1</span>), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.saver = tf.train.Saver()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.load_model:</span><br><span class="line">            init = tf.global_variables_initializer()</span><br><span class="line">            self.sess.run(init)</span><br><span class="line">        <span class="keyword">elif</span> self.load_model:</span><br><span class="line">            self.saver.restore(self.sess, os.getcwd()+<span class="string">'/model_saved/model.ckpt'</span>)</span><br><span class="line">            <span class="keyword">print</span> <span class="string">'model load done'</span></span><br><span class="line">        self.sess.graph.finalize()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">'model_saved'</span>):</span><br><span class="line">            os.mkdir(<span class="string">'model_saved'</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">'gen_picture'</span>):</span><br><span class="line">            os.mkdir(<span class="string">'gen_picture'</span>)</span><br><span class="line">        noise = np.random.normal(<span class="number">-1</span>, <span class="number">1</span>, [self.batch_size, <span class="number">128</span>])</span><br><span class="line">        temp = <span class="number">0.80</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">'training'</span></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> range(self.EPOCH):</span><br><span class="line">            <span class="comment"># iters = int(156191//self.batch_size)</span></span><br><span class="line">            iters = <span class="number">50000</span>//self.batch_size</span><br><span class="line">            flag2 = <span class="number">1</span>  <span class="comment"># if epoch&gt;10 else 0</span></span><br><span class="line">            <span class="keyword">for</span> idx <span class="keyword">in</span> range(iters):</span><br><span class="line">                start_t = time.time()</span><br><span class="line">                flag = <span class="number">1</span> <span class="keyword">if</span> idx &lt; <span class="number">4</span> <span class="keyword">else</span> <span class="number">0</span> <span class="comment"># set we use 2*batch_size=200 train data labeled.</span></span><br><span class="line">                batchx, batchl = mnist.train.next_batch(self.batch_size)</span><br><span class="line">                <span class="comment"># batchx, batchl = self.sess.run([batchx, batchl])</span></span><br><span class="line">                g_opt = [self.opt_g, self.g_loss]</span><br><span class="line">                d_opt = [self.opt_d, self.d_loss, self.d_l_1, self.d_l_2]</span><br><span class="line">                feed = &#123;self.x:batchx, self.z:noise, self.label:batchl, self.flag:flag, self.flag2:flag2&#125;</span><br><span class="line">                <span class="comment"># update the Discrimater k times</span></span><br><span class="line">                _, loss_d, d1,d2 = self.sess.run(d_opt, feed_dict=feed)</span><br><span class="line">                <span class="comment"># update the Generator one time</span></span><br><span class="line">                _, loss_g = self.sess.run(g_opt, feed_dict=feed)</span><br><span class="line">                <span class="keyword">print</span> (<span class="string">"[%3f][epoch:%2d/%2d][iter:%4d/%4d],loss_d:%5f,loss_g:%4f, d1:%4f, d2:%4f"</span>%</span><br><span class="line">                       (time.time()-start_t, epoch, self.EPOCH,idx,iters, loss_d, loss_g,d1,d2)), <span class="string">'flag:'</span>,flag</span><br><span class="line">                plot.plot(<span class="string">'d_loss'</span>, loss_d)</span><br><span class="line">                plot.plot(<span class="string">'g_loss'</span>, loss_g)</span><br><span class="line">                <span class="keyword">if</span> ((idx+<span class="number">1</span>) % <span class="number">100</span>) == <span class="number">0</span>:  <span class="comment"># flush plot picture per 1000 iters</span></span><br><span class="line">                    plot.flush()</span><br><span class="line">                plot.tick()</span><br><span class="line">                <span class="keyword">if</span> (idx+<span class="number">1</span>)%<span class="number">500</span>==<span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">print</span> (<span class="string">'images saving............'</span>)</span><br><span class="line">                    img = self.sess.run(self.G_img, feed_dict=feed)</span><br><span class="line">                    save_img.save_images(img, os.getcwd()+<span class="string">'/gen_picture/'</span>+<span class="string">'sample&#123;&#125;_&#123;&#125;.jpg'</span>\</span><br><span class="line">                                         .format(epoch, (idx+<span class="number">1</span>)/<span class="number">500</span>))</span><br><span class="line">                    <span class="keyword">print</span> <span class="string">'images save done'</span></span><br><span class="line">            test_acc = self.test()</span><br><span class="line">            plot.plot(<span class="string">'test acc'</span>, test_acc)</span><br><span class="line">            plot.flush()</span><br><span class="line">            plot.tick()</span><br><span class="line">            <span class="keyword">print</span> <span class="string">'test acc:&#123;&#125;'</span>.format(test_acc), <span class="string">'temp:%3f'</span>%(temp)</span><br><span class="line">            <span class="keyword">if</span> test_acc &gt; temp:</span><br><span class="line">                <span class="keyword">print</span> (<span class="string">'model saving..............'</span>)</span><br><span class="line">                path = os.getcwd() + <span class="string">'/model_saved'</span></span><br><span class="line">                save_path = os.path.join(path, <span class="string">"model.ckpt"</span>)</span><br><span class="line">                self.saver.save(self.sess, save_path=save_path)</span><br><span class="line">                <span class="keyword">print</span> (<span class="string">'model saved...............'</span>)</span><br><span class="line">                temp = test_acc</span><br><span class="line"></span><br><span class="line"><span class="comment"># output = conv2d('Z_cona&#123;&#125;'.format(i), output, 3, 64, stride=1, padding='SAME')</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">(self,name, noise, reuse)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(name,reuse=reuse):</span><br><span class="line">            l = self.batch_size</span><br><span class="line">            output = fc(<span class="string">'g_dc'</span>, noise, <span class="number">2</span>*<span class="number">2</span>*<span class="number">64</span>)</span><br><span class="line">            output = tf.reshape(output, [<span class="number">-1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">64</span>])</span><br><span class="line">            output = tf.nn.relu(self.bn(<span class="string">'g_bn1'</span>,output))</span><br><span class="line">            output = deconv2d(<span class="string">'g_dcon1'</span>,output,<span class="number">5</span>,outshape=[l, <span class="number">4</span>, <span class="number">4</span>, <span class="number">64</span>*<span class="number">4</span>])</span><br><span class="line">            output = tf.nn.relu(self.bn(<span class="string">'g_bn2'</span>,output))</span><br><span class="line"></span><br><span class="line">            output = deconv2d(<span class="string">'g_dcon2'</span>, output, <span class="number">5</span>, outshape=[l, <span class="number">8</span>, <span class="number">8</span>, <span class="number">64</span> * <span class="number">2</span>])</span><br><span class="line">            output = tf.nn.relu(self.bn(<span class="string">'g_bn3'</span>, output))</span><br><span class="line"></span><br><span class="line">            output = deconv2d(<span class="string">'g_dcon3'</span>, output, <span class="number">5</span>, outshape=[l, <span class="number">16</span>, <span class="number">16</span>,<span class="number">64</span> * <span class="number">1</span>])</span><br><span class="line">            output = tf.nn.relu(self.bn(<span class="string">'g_bn4'</span>, output))</span><br><span class="line"></span><br><span class="line">            output = deconv2d(<span class="string">'g_dcon4'</span>, output, <span class="number">5</span>, outshape=[l, <span class="number">32</span>, <span class="number">32</span>, self.dim])</span><br><span class="line">            output = tf.image.resize_images(output, (<span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">            <span class="comment"># output = tf.nn.relu(self.bn('g_bn4', output))</span></span><br><span class="line">            <span class="keyword">return</span> tf.nn.tanh(output)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">discriminator</span><span class="params">(self, name, inputs, reuse)</span>:</span></span><br><span class="line">        l = tf.shape(inputs)[<span class="number">0</span>]</span><br><span class="line">        inputs = tf.reshape(inputs, (l,self.img_size,self.img_size,self.dim))</span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(name,reuse=reuse):</span><br><span class="line">            out = []</span><br><span class="line">            output = conv2d(<span class="string">'d_con1'</span>,inputs,<span class="number">5</span>, <span class="number">64</span>, stride=<span class="number">2</span>, padding=<span class="string">'SAME'</span>) <span class="comment">#14*14</span></span><br><span class="line">            output1 = lrelu(self.bn(<span class="string">'d_bn1'</span>,output))</span><br><span class="line">            out.append(output1)</span><br><span class="line">            <span class="comment"># output1 = tf.contrib.keras.layers.GaussianNoise</span></span><br><span class="line">            output = conv2d(<span class="string">'d_con2'</span>, output1, <span class="number">3</span>, <span class="number">64</span>*<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="string">'SAME'</span>)<span class="comment">#7*7</span></span><br><span class="line">            output2 = lrelu(self.bn(<span class="string">'d_bn2'</span>, output))</span><br><span class="line">            out.append(output2)</span><br><span class="line">            output = conv2d(<span class="string">'d_con3'</span>, output2, <span class="number">3</span>, <span class="number">64</span>*<span class="number">4</span>, stride=<span class="number">1</span>, padding=<span class="string">'VALID'</span>)<span class="comment">#5*5</span></span><br><span class="line">            output3 = lrelu(self.bn(<span class="string">'d_bn3'</span>, output))</span><br><span class="line">            out.append(output3)</span><br><span class="line">            output = conv2d(<span class="string">'d_con4'</span>, output3, <span class="number">3</span>, <span class="number">64</span>*<span class="number">4</span>, stride=<span class="number">2</span>, padding=<span class="string">'VALID'</span>)<span class="comment">#2*2</span></span><br><span class="line">            output4 = lrelu(self.bn(<span class="string">'d_bn4'</span>, output))</span><br><span class="line">            out.append(output4)</span><br><span class="line">            output = tf.reshape(output4, [l, <span class="number">2</span>*<span class="number">2</span>*<span class="number">64</span>*<span class="number">4</span>])<span class="comment"># 2*2*64*4</span></span><br><span class="line">            output = fc(<span class="string">'d_fc'</span>, output, self.num_class)</span><br><span class="line">            <span class="comment"># output = tf.nn.softmax(output)</span></span><br><span class="line">            <span class="keyword">return</span> output, out</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bn</span><span class="params">(self, name, input)</span>:</span></span><br><span class="line">        val = tf.contrib.layers.batch_norm(input, decay=<span class="number">0.9</span>,</span><br><span class="line">                                           updates_collections=<span class="literal">None</span>,</span><br><span class="line">                                           epsilon=<span class="number">1e-5</span>,</span><br><span class="line">                                           scale=<span class="literal">True</span>,</span><br><span class="line">                                           is_training=<span class="literal">True</span>,</span><br><span class="line">                                           scope=name)</span><br><span class="line">        <span class="keyword">return</span> val</span><br><span class="line"></span><br><span class="line">    <span class="comment"># def get_loss(self, logits, layer_out):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(self)</span>:</span></span><br><span class="line">        count = <span class="number">0.</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">'testing................'</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>//self.batch_size):</span><br><span class="line">            testx, textl = mnist.test.next_batch(self.batch_size)</span><br><span class="line">            prediction = self.sess.run(self.prediction, feed_dict=&#123;self.x:testx, self.label:textl&#125;)</span><br><span class="line">            count += np.sum(prediction)</span><br><span class="line">        <span class="keyword">return</span> count/<span class="number">10000.</span></span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;<font color="red">args</font>是传进来的参数，主要包括三个，</p>
<ul>
<li>一个是<strong><em>args.model</em></strong>，选择DCGAN模式还是WGAN-GP模式，二者的不同主要在于损失函数不同和优化器的学习率不同，其他都一样。</li>
<li>第二个参数是<strong><em>args.trainable</em></strong>，训练还是测试，训练时为True，测试是False。</li>
<li><strong><em>Loadmodel</em></strong>表示是否选择加载训练好的权重。 </li>
</ul>
<p>&emsp;&emsp;Build_model函数里面主要包括了网络训练前的准备工作，主要包括损失函数的设计和优化器的设计。下文将详细做出介绍，尤其是损失函数部分。<br>&emsp;&emsp;首先，建立了五个placeholder，flag表示两个标志位，只有0-1两种情况，注意到我num_class是11，也就是做11分类，但是lable的placeholder中shape是(batchsize,10)。为了方便，我将生成器的生成结果和真实数据X级联在一起作为判别器的输入，输出再把他它们结果split分开。<br>&emsp;&emsp;d_regular 表示正则化，这里我将判别器中所有的weights做了l2正则。<br>&emsp;&emsp;监督学习的损失函数使用常见的交叉熵损失函数，对生成器生成的图像的label的one_hot型为：<br>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]<br>&emsp;&emsp;将原始的label扩展到(batchsize，11)后再和生成器生成的假数据的label在第一维度concat到一起得到batchl，另外乘以0.9，做单边标签平滑（one side smoothing），由此计算得到监督学习的损失函数值s_l,。 </p>
<h2 id="生成器G的损失函数"><a href="#生成器G的损失函数" class="headerlink" title="生成器G的损失函数"></a>生成器G的损失函数</h2><p>&emsp;&emsp;生成器G的损失函数包括两部分，一个是来自GAN训练的部分，另外一个是feature matching , 论文中提到的feature matching意思是<font color="blue">特征匹配</font>，主要思想是希望生成器生成的假数据输入到判别器，经过判别器每一层计算的结果和将真实数据X输入到判别器，判别器每一层的结果尽可能的相似，公式如下： </p>
<script type="math/tex; mode=display">\|E_{x\sim Pdata(x)}f(x) - E_{z\sim Pz(z)}f(G(z))\|^2_2</script><p>&emsp;&emsp;其中\(f(x)\)是D的每一层的输出。Feature matching 是指导G进行训练，所以我将他放在了G的损失函数里。</p>
<h2 id="分类器D的损失函数："><a href="#分类器D的损失函数：" class="headerlink" title="分类器D的损失函数："></a>分类器D的损失函数：</h2><p>相比较G的损失函数，D的损失函数就比较麻烦了<br>接下来介绍无监督学习的损失函数实现：<br>在前面介绍的无监督学习的损失函数中，有一部分和GAN的损失函数很相似，所以在代码中我们使用了<br><img src="/images/手把手教你用GAN实现半监督学习/png1-2.png" alt><br>&emsp;&emsp;无监督学习的时候没有标签的指导，此时判别器或者称为分类器D无法正确对输入进行分类，此时只要求D能够区分真假就可以了，由此我们得到了无监督学习的损失un_s，直观上也很好理解，假设输入给判别器D真图像，它结果经过<em>softmax</em>后输出类似下面表格的形式，其中前十个黄色区域表示对0-9的分类概率，最后一个灰色的表示对假图像的分类概率，由于无监督学习中判别器D并不知道具体是哪一类数据，所以干脆D的损失函数最小化输出假图像的概率就可以了，当输入为生成器生成的假图像时，只要最小化D输出为真图像的概率，由此我们得到了un_s.。但是此时有一个问题，即是有监督学习的时候不就没有用了吗，因为这时候应该使用s_l.为了解决这个问题，我使用了一个标志位flag作为控制他们之间的使用，具体代码： </p>
<script type="math/tex; mode=display">flag*s\_i + (1-flag)*un\_s</script><p>&emsp;&emsp;有标签的时候flag是1，表示使用s_l,无监督的时候flag是0，表示使用无监督损失函数。此时已经完成了判别器D损失函数的一部分设计，剩下的一部分和GAN中的D的损失一样，在代码中我给出了两种损失函数，一个是原始GAN的交叉熵损失函数，和DCGAN使用的一样，另外一个是improved wgan论文中使用的损失函数，但是在做了对比之后，我强烈建议使用DCGAN来做，improved wgan的损失函数虽然在生成结果的优化上有很大帮助，但是并不适合半监督学习中。 </p>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>接下来就是训练部分：<br>&emsp;&emsp;此时可能有一个疑问，我们是如何实现只使用200带标签的数据训练的，答案就在flag这个标志位里，在训练部分代码中，当迭代次数小于200的时候，flag=1, 此时表示使用s_l作为损失函数的一部分，当flag=0的时候，un_s起作用而s_l并没有起作用，这时，即使我们feed了正确的标签数据，但是s_l不起作用，就相当于没有使用标签。<br>&emsp;&emsp;flag的作用本来是使用他控制feature matching是否工作的，因为这部分损失相当的大，后来发现影响不大，暂时就放在这里了。 </p>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(self)</span>:</span></span><br><span class="line">       count = <span class="number">0.</span></span><br><span class="line">       <span class="keyword">print</span> <span class="string">'testing................'</span></span><br><span class="line">       <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>//self.batch_size):</span><br><span class="line">           testx, textl = mnist.test.next_batch(self.batch_size)</span><br><span class="line">           prediction = self.sess.run(self.prediction, feed_dict=&#123;self.x:testx, self.label:textl&#125;)</span><br><span class="line">           count += np.sum(prediction)</span><br><span class="line">       <span class="keyword">return</span> count/<span class="number">10000.</span></span><br></pre></td></tr></table></figure>
<h2 id="测试精度结果变化图"><a href="#测试精度结果变化图" class="headerlink" title="测试精度结果变化图"></a>测试精度结果变化图</h2><p><img src="/images/手把手教你用GAN实现半监督学习/jpg1-1.jpg" alt></p>
<h1 id="本文实验代码"><a href="#本文实验代码" class="headerlink" title="本文实验代码"></a>本文实验代码</h1><p>使用GAN实现半监督学习代码<a href="https://github.com/LDOUBLEV/semi-supervised-GAN" target="_blank" rel="noopener">https://github.com/LDOUBLEV/semi-supervised-GAN</a><br>如果感觉有用的话，欢迎star， fork</p>
<h1 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h1><p>&emsp;&emsp;详细代码请以github中为准，另关于结果不理想的问题，可能和之前做的迁移学习有关，下面是最近跑出来的结果，最好的精度是0.95，这个问题有时间会慢慢解决。另：链接中的模型精度是很高的，可以直接调用<br><img src="/images/手把手教你用GAN实现半监督学习/png1-3.png" alt></p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://blog.csdn.net/qq_25737169/article/details/78532719" target="_blank" rel="noopener">手把手教你用GAN实现半监督学习</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/xun-lian-tensorflow-shi-bie-shou-xie-shu-zi.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/xun-lian-tensorflow-shi-bie-shou-xie-shu-zi.html" class="post-title-link" itemprop="url">训练TensorFlow识别手写数字</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-07 08:02:53 / 修改时间：09:28:07" itemprop="dateCreated datePublished" datetime="2019-05-07T08:02:53+08:00">2019-05-07</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">14k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">12 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="TensorFlowSharp安装和使用入门"><a href="#TensorFlowSharp安装和使用入门" class="headerlink" title="TensorFlowSharp安装和使用入门"></a>TensorFlowSharp安装和使用入门</h1><p>(<font color="red">posted @ 2017-11-25 21:31</font>)<br>Tensorflow是一个人工智能框架。TensorflowSharp是对Tensorflow C语言版接口的封装，便于C#开发人员在项目中使用Tensorflow。</p>
<h2 id="一、使用方法"><a href="#一、使用方法" class="headerlink" title="一、使用方法"></a>一、使用方法</h2><p>TensorflowSharp的使用很简单，首先使用NuGet安装TensorflowSharp包，然后新建C#控制台程序，输入下面代码，运行即可。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">// 创建图</span><br><span class="line">var g = new TFGraph();</span><br><span class="line"></span><br><span class="line">// 定义常量</span><br><span class="line">var a = g.Const(<span class="number">2</span>);</span><br><span class="line">var b = g.Const(<span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">// 加法和乘法运算</span><br><span class="line">var add = g.Add(a, b);</span><br><span class="line">var mul = g.Mul(a, b);</span><br><span class="line"></span><br><span class="line">// 创建会话</span><br><span class="line">var sess = new TFSession(g);</span><br><span class="line"></span><br><span class="line">// 计算加法</span><br><span class="line">var result1 = sess.GetRunner().Run(add).GetValue();</span><br><span class="line">Console.WriteLine(<span class="string">"a+b=&#123;0&#125;"</span>, result1);</span><br><span class="line"></span><br><span class="line">// 计算乘法</span><br><span class="line">var result2 = sess.GetRunner().Run(mul).GetValue();</span><br><span class="line">Console.WriteLine(<span class="string">"a*b=&#123;0&#125;"</span>, result2);</span><br><span class="line"></span><br><span class="line">// 关闭会话</span><br><span class="line">sess.CloseSession();</span><br></pre></td></tr></table></figure></p>
<p>运行后输出结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a+b=<span class="number">5</span></span><br><span class="line">a*b=<span class="number">6</span></span><br></pre></td></tr></table></figure></p>
<h2 id="二、注意事项"><a href="#二、注意事项" class="headerlink" title="二、注意事项"></a>二、注意事项</h2><ol>
<li>国内目前无法访问Tensorflow官网，但是可以访问谷歌提供的Tensorflow官网镜像。</li>
<li>国内使用NuGet安装TensorflowSharp很容易失败，可以直接从Nuget官网下载，然后改后缀名zip，解压后手工安装。</li>
<li>TensorflowSharp项目使用的.net版本必须高于4.6.1，本教程使用的版本是4.7.0，可以在属性选项卡中设置。</li>
<li>TensorflowSharp项目必须使用64位CPU，需要在属性选项卡生成中，去掉首选32位的勾选。</li>
<li>手动安装TensorflowSharp，处理要引用TensorFlowSharp.dll，还要将libtensorflow.dll复制到每个项目的输出目录。</li>
</ol>
<h2 id="三、相关网站"><a href="#三、相关网站" class="headerlink" title="三、相关网站"></a>三、相关网站</h2><p>Tensorflow教程：<a href="https://github.com/tengge1/learn-tensorflow-sharp" target="_blank" rel="noopener">https://github.com/tengge1/learn-tensorflow-sharp</a><br>Tensorflow官网：<a href="http://www.tensorflow.org" target="_blank" rel="noopener">http://www.tensorflow.org</a><br>Google Tensorflow镜像：<a href="https://tensorflow.google.cn/" target="_blank" rel="noopener">https://tensorflow.google.cn/</a><br>Tensorflow开源项目：<a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow</a><br>TensorflowSharp开源项目：<a href="https://github.com/migueldeicaza/TensorFlowSharp" target="_blank" rel="noopener">https://github.com/migueldeicaza/TensorFlowSharp</a><br>TensorflowSharp NuGet主页：<a href="https://www.nuget.org/packages/TensorFlowSharp/" target="_blank" rel="noopener">https://www.nuget.org/packages/TensorFlowSharp/</a><br>Tensorflow中文社区：<a href="http://www.tensorfly.cn/" target="_blank" rel="noopener">http://www.tensorfly.cn/</a></p>
<h1 id="03-使用TensorFlow做计算题"><a href="#03-使用TensorFlow做计算题" class="headerlink" title="03 使用TensorFlow做计算题"></a>03 使用TensorFlow做计算题</h1><p>我们使用Tensorflow，计算<code>((a+b)*c)^2/a</code>，然后求平方根。看代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入储存容器</span></span><br><span class="line">a = tf.placeholder(tf.float16)</span><br><span class="line">b = tf.placeholder(tf.float16)</span><br><span class="line">c = tf.placeholder(tf.float16)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算</span></span><br><span class="line">d = tf.add(a, b) <span class="comment">#加法</span></span><br><span class="line">e = tf.multiply(d, c) <span class="comment">#乘法</span></span><br><span class="line">f = tf.pow(e, <span class="number">2</span>) <span class="comment">#平方</span></span><br><span class="line">g = tf.divide(f, a) <span class="comment">#除法</span></span><br><span class="line">h = tf.sqrt(g) <span class="comment">#平方根</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 会话</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 赋值</span></span><br><span class="line">feed_dict= &#123;a:<span class="number">1</span>, b:<span class="number">2</span>, c:<span class="number">3</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算</span></span><br><span class="line">result = sess.run(h, feed_dict= feed_dict)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭会话</span></span><br><span class="line">sess.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure></p>
<p>这里让a=1，b=2，c=3，如果输出9.0，证明运行成功。<br>Tensorflow做计算的方法是，先把计算的式子构建一个图，然后把这个图和赋值在cpu上一起运行，计算速度比较快。</p>
<h1 id="04-TensorFlow中的常量、变量和数据类型"><a href="#04-TensorFlow中的常量、变量和数据类型" class="headerlink" title="04 TensorFlow中的常量、变量和数据类型"></a>04 TensorFlow中的常量、变量和数据类型</h1><p>打开Python Shell，先输入<code>import tensorflow as tf</code>，然后可以执行以下命令。<br>Tensorflow中的常量创建方法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hello = tf.constant(<span class="string">'Hello,world!'</span>, dtype=tf.string)</span><br></pre></td></tr></table></figure></p>
<p>其中，’Hello,world!’是常量初始值；tf.string是常量类型，可以省略。常量和变量都可以去构建Tensorflow中的图。</p>
<p>Tensorflow中变量的创建方法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = tf.Variable(<span class="number">10</span>, dtype=tf.int32)</span><br></pre></td></tr></table></figure></p>
<p>其中，10是变量初始值，tf.int32是变量的类型。<br>Tensorflow中，主要有以下几种数据类型。<br>tf.int8：8位整数。<br>tf.int16：16位整数。<br>tf.int32：32位整数。<br>tf.int64：64位整数。</p>
<p>tf.uint8：8位无符号整数。<br>tf.uint16：16位无符号整数。</p>
<p>tf.float16：16位浮点数。<br>tf.float32：32位浮点数。<br>tf.float64：64位浮点数。<br>tf.double：等同于tf.float64。</p>
<p>tf.string：字符串。</p>
<p>tf.bool：布尔型。</p>
<p>tf.complex64：64位复数。<br>tf.complex128：128位复数。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="http://wiki.jikexueyuan.com/project/tensorflow-zh/resources/dims_types.html" target="_blank" rel="noopener">《张量的阶、形状、数据类型》</a></li>
</ul>
<h1 id="05-TensorFlow中变量的初始化"><a href="#05-TensorFlow中变量的初始化" class="headerlink" title="05 TensorFlow中变量的初始化"></a>05 TensorFlow中变量的初始化</h1><p>打开Python Shell，输入<strong>import tensorflow as tf</strong>，然后可以执行以下代码。<br>1、创建一个<code>2*3</code>的矩阵，并让所有元素的值为0.（类型为tf.float）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = tf.zeros([<span class="number">2</span>,<span class="number">3</span>], dtype = tf.float32)</span><br></pre></td></tr></table></figure></p>
<p>2、创建一个<code>3*4</code>的矩阵，并让所有元素的值为1.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b = tf.ones([<span class="number">3</span>,<span class="number">4</span>])</span><br></pre></td></tr></table></figure></p>
<p>3、创建一个<code>1*10</code>的矩阵，使用2来填充。（类型为tf.int32，可忽略）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c = tf.constant(<span class="number">2</span>, dtype=tf.int32, shape=[<span class="number">1</span>,<span class="number">10</span>])</span><br></pre></td></tr></table></figure></p>
<p>4、创建一个<code>1*10</code>的矩阵，其中的元素符合正态分布，平均值是20，标准偏差是3.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d = tf.random_normal([<span class="number">1</span>,<span class="number">10</span>],mean = <span class="number">20</span>, stddev = <span class="number">3</span>)</span><br></pre></td></tr></table></figure></p>
<p>上面所有的值都可以用来初始化变量。例如用0.01来填充一个<code>1*2</code>的矩阵来初始化一个叫bias的变量。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bias = tf.Variable(tf.zeros([<span class="number">1</span>,<span class="number">2</span>]) + <span class="number">0.01</span>)</span><br></pre></td></tr></table></figure></p>
<p>如果你想查看这些量具体的值，可以在Session中执行它并输出。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sess = tf.Session()</span><br><span class="line">print(sess.run(d))</span><br></pre></td></tr></table></figure></p>
<p>这里，我得到了以下的值：<br>[[ 22.44503784  18.19544983  17.89671898  17.67314911  19.45074844<br>   18.6805439   18.56541443  16.59041977  22.11240005  19.12819099]]。它就是上面4我们创建的量的值。</p>
<h1 id="参考文献-1"><a href="#参考文献-1" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="http://blog.sina.com.cn/s/blog_8b2a28790102wnkh.html" target="_blank" rel="noopener">《Tensorflow学习笔记（3）》</a></li>
</ul>
<h1 id="06-使用TensorFlow拟合x与y之间的关系"><a href="#06-使用TensorFlow拟合x与y之间的关系" class="headerlink" title="06 使用TensorFlow拟合x与y之间的关系"></a>06 使用TensorFlow拟合x与y之间的关系</h1><p>看代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#构造输入数据（我们用神经网络拟合x_data和y_data之间的关系）</span></span><br><span class="line">x_data = np.linspace(<span class="number">-1</span>,<span class="number">1</span>,<span class="number">300</span>)[:, np.newaxis] <span class="comment">#-1到1等分300份形成的二维矩阵</span></span><br><span class="line">noise = np.random.normal(<span class="number">0</span>,<span class="number">0.05</span>, x_data.shape) <span class="comment">#噪音，形状同x_data在0-0.05符合正态分布的小数</span></span><br><span class="line">y_data = np.square(x_data)<span class="number">-0.5</span>+noise <span class="comment">#x_data平方，减0.05，再加噪音值</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#输入层（1个神经元）</span></span><br><span class="line">xs = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>]) <span class="comment">#占位符，None表示n*1维矩阵，其中n不确定</span></span><br><span class="line">ys = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>]) <span class="comment">#占位符，None表示n*1维矩阵，其中n不确定</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#隐层（10个神经元）</span></span><br><span class="line">W1 = tf.Variable(tf.random_normal([<span class="number">1</span>,<span class="number">10</span>])) <span class="comment">#权重，1*10的矩阵，并用符合正态分布的随机数填充</span></span><br><span class="line">b1 = tf.Variable(tf.zeros([<span class="number">1</span>,<span class="number">10</span>])+<span class="number">0.1</span>) <span class="comment">#偏置，1*10的矩阵，使用0.1填充</span></span><br><span class="line">Wx_plus_b1 = tf.matmul(xs,W1) + b1 <span class="comment">#矩阵xs和W1相乘，然后加上偏置</span></span><br><span class="line">output1 = tf.nn.relu(Wx_plus_b1) <span class="comment">#激活函数使用tf.nn.relu</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#输出层（1个神经元）</span></span><br><span class="line">W2 = tf.Variable(tf.random_normal([<span class="number">10</span>,<span class="number">1</span>]))</span><br><span class="line">b2 = tf.Variable(tf.zeros([<span class="number">1</span>,<span class="number">1</span>])+<span class="number">0.1</span>)</span><br><span class="line">Wx_plus_b2 = tf.matmul(output1,W2) + b2</span><br><span class="line">output2 = Wx_plus_b2</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失</span></span><br><span class="line">loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-output2),reduction_indices=[<span class="number">1</span>])) <span class="comment">#在第一维上，偏差平方后求和，再求平均值，来计算损失</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss) <span class="comment"># 使用梯度下降法，设置步长0.1，来最小化损失</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化</span></span><br><span class="line">init = tf.global_variables_initializer() <span class="comment">#初始化所有变量</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init) <span class="comment">#变量初始化</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#训练</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>): <span class="comment">#训练1000次</span></span><br><span class="line">    _,loss_value = sess.run([train_step,loss],feed_dict=&#123;xs:x_data,ys:y_data&#125;) <span class="comment">#进行梯度下降运算，并计算每一步的损失</span></span><br><span class="line">    <span class="keyword">if</span>(i%<span class="number">50</span>==<span class="number">0</span>):</span><br><span class="line">        print(loss_value) <span class="comment"># 每50步输出一次损失</span></span><br></pre></td></tr></table></figure></p>
<p>输出：<br>0.405348<br>0.00954485<br>0.0068925<br>0.00551958<br>0.00471453<br>0.00425206<br>0.00400382<br>0.00381883<br>0.00367445<br>0.00353349<br>0.00341325<br>0.00330487<br>0.00321128<br>0.00313468<br>0.0030646<br>0.0030014<br>0.00294802<br>0.00290179<br>0.0028618<br>0.00282344<br>可以看到，随机训练的进行，损失越来越小，证明拟合越来越好。</p>
<h1 id="参考文献-2"><a href="#参考文献-2" class="headerlink" title="参考文献"></a>参考文献</h1><ol>
<li><a href="http://blog.csdn.net/jerry81333/article/details/53004903" target="_blank" rel="noopener">《Tensorflow 自带可视化Tensorboard使用方法 附项目代码》</a></li>
<li><a href="http://blog.csdn.net/qq_32166627/article/details/52734387" target="_blank" rel="noopener">《tensorflow学习（六）：tensorflow中的tf.reduce_mean()这类函数》</a></li>
</ol>
<h1 id="07-训练TensorFlow识别手写数字"><a href="#07-训练TensorFlow识别手写数字" class="headerlink" title="07 训练TensorFlow识别手写数字"></a>07 训练TensorFlow识别手写数字</h1><p>打开Python Shell，输入以下代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取数据（如果存在就读取，不存在就下载完再读取）</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data/"</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入</span></span><br><span class="line">x = tf.placeholder(<span class="string">"float"</span>, [<span class="literal">None</span>, <span class="number">784</span>]) <span class="comment">#输入占位符（每张手写数字784个像素点）</span></span><br><span class="line">y_ = tf.placeholder(<span class="string">"float"</span>, [<span class="literal">None</span>,<span class="number">10</span>]) <span class="comment">#输入占位符（这张手写数字具体代表的值，0-9对应矩阵的10个位置）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算分类softmax会将xW+b分成10类，对应0-9</span></span><br><span class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>,<span class="number">10</span>])) <span class="comment">#权重</span></span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>])) <span class="comment">#偏置</span></span><br><span class="line">y = tf.nn.softmax(tf.matmul(x,W) + b) <span class="comment"># 输入矩阵x与权重矩阵W相乘，加上偏置矩阵b，然后求softmax（sigmoid函数升级版，可以分成多类）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算偏差和</span></span><br><span class="line">cross_entropy = -tf.reduce_sum(y_*tf.log(y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用梯度下降法（步长0.01），来使偏差和最小</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化变量</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>): <span class="comment"># 训练10次</span></span><br><span class="line">  batch_xs, batch_ys = mnist.train.next_batch(<span class="number">100</span>) <span class="comment"># 随机取100个手写数字图片</span></span><br><span class="line">  sess.run(train_step, feed_dict=&#123;x: batch_xs, y_: batch_ys&#125;) <span class="comment"># 执行梯度下降算法，输入值x：batch_xs，输入值y：batch_ys</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算训练精度</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y,<span class="number">1</span>), tf.argmax(y_,<span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</span><br><span class="line">print(sess.run(accuracy, feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels&#125;)) <span class="comment">#运行精度图，x和y_从测试手写图片中取值</span></span><br></pre></td></tr></table></figure></p>
<p>执行该段代码，输出0.8002。训练10次得到80.02%的识别准确度，还是可以的。<br>说明：由于网络原因，手写数字图片可能无法下载，可以直接下载本人做好的程序，里面已经包含了手写图片资源和py脚本。(链接已失效)</p>
<h1 id="参考文献-3"><a href="#参考文献-3" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://www.cnblogs.com/tengge/p/6363586.html" target="_blank" rel="noopener">07 训练TensorFlow识别手写数字</a></li>
<li><a href="http://www.tensorfly.cn/tfdoc/tutorials/mnist_beginners.html" target="_blank" rel="noopener">《面向机器学习初学者的 MNIST 初级教程》</a></li>
</ul>
<h1 id="10-TensorFlow中模型保存与读取"><a href="#10-TensorFlow中模型保存与读取" class="headerlink" title="10 TensorFlow中模型保存与读取"></a>10 TensorFlow中模型保存与读取</h1><p>我们的模型训练出来想给别人用，或者是我今天训练不完，明天想接着训练，怎么办？这就需要模型的保存与读取。看代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment">#输入数据</span></span><br><span class="line">x_data = np.linspace(<span class="number">-1</span>,<span class="number">1</span>,<span class="number">300</span>)[:, np.newaxis]</span><br><span class="line">noise = np.random.normal(<span class="number">0</span>,<span class="number">0.05</span>, x_data.shape)</span><br><span class="line">y_data = np.square(x_data)<span class="number">-0.5</span>+noise</span><br><span class="line"></span><br><span class="line"><span class="comment">#输入层</span></span><br><span class="line">xs = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>])</span><br><span class="line">ys = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#隐层</span></span><br><span class="line">W1 = tf.Variable(tf.random_normal([<span class="number">1</span>,<span class="number">10</span>]))</span><br><span class="line">b1 = tf.Variable(tf.zeros([<span class="number">1</span>,<span class="number">10</span>])+<span class="number">0.1</span>)</span><br><span class="line">Wx_plus_b1 = tf.matmul(xs,W1) + b1</span><br><span class="line">output1 = tf.nn.relu(Wx_plus_b1)</span><br><span class="line"></span><br><span class="line"><span class="comment">#输出层</span></span><br><span class="line">W2 = tf.Variable(tf.random_normal([<span class="number">10</span>,<span class="number">1</span>]))</span><br><span class="line">b2 = tf.Variable(tf.zeros([<span class="number">1</span>,<span class="number">1</span>])+<span class="number">0.1</span>)</span><br><span class="line">Wx_plus_b2 = tf.matmul(output1,W2) + b2</span><br><span class="line">output2 = Wx_plus_b2</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失</span></span><br><span class="line">loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-output2),reduction_indices=[<span class="number">1</span>]))</span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">#模型保存加载工具</span></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"><span class="comment">#判断模型保存路径是否存在，不存在就创建</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">'tmp/'</span>):</span><br><span class="line">    os.mkdir(<span class="string">'tmp/'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line"><span class="keyword">if</span> os.path.exists(<span class="string">'tmp/checkpoint'</span>): <span class="comment">#判断模型是否存在</span></span><br><span class="line">    saver.restore(sess, <span class="string">'tmp/model.ckpt'</span>) <span class="comment">#存在就从模型中恢复变量</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    init = tf.global_variables_initializer() <span class="comment">#不存在就初始化变量</span></span><br><span class="line">    sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    _,loss_value = sess.run([train_step,loss], feed_dict=&#123;xs:x_data,ys:y_data&#125;)</span><br><span class="line">    <span class="keyword">if</span>(i%<span class="number">50</span>==<span class="number">0</span>): <span class="comment">#每50次保存一次模型</span></span><br><span class="line">        save_path = saver.save(sess, <span class="string">'tmp/model.ckpt'</span>) <span class="comment">#保存模型到tmp/model.ckpt，注意一定要有一层文件夹，否则保存不成功！！！</span></span><br><span class="line">        print(<span class="string">"模型保存：%s 当前训练损失：%s"</span>%(save_path, loss_value))</span><br></pre></td></tr></table></figure></p>
<p>大家第一次训练得到：</p>
<p>模型保存：tmp/model.ckpt 当前训练损失：1.35421<br>模型保存：tmp/model.ckpt 当前训练损失：0.011808<br>模型保存：tmp/model.ckpt 当前训练损失：0.00916655<br>模型保存：tmp/model.ckpt 当前训练损失：0.00690887<br>模型保存：tmp/model.ckpt 当前训练损失：0.00575491<br>模型保存：tmp/model.ckpt 当前训练损失：0.00526401<br>模型保存：tmp/model.ckpt 当前训练损失：0.00498503<br>模型保存：tmp/model.ckpt 当前训练损失：0.00478226<br>模型保存：tmp/model.ckpt 当前训练损失：0.0046346<br>模型保存：tmp/model.ckpt 当前训练损失：0.00454276<br>模型保存：tmp/model.ckpt 当前训练损失：0.00446402<br>模型保存：tmp/model.ckpt 当前训练损失：0.00436883<br>模型保存：tmp/model.ckpt 当前训练损失：0.00427732<br>模型保存：tmp/model.ckpt 当前训练损失：0.00418589<br>模型保存：tmp/model.ckpt 当前训练损失：0.00409241<br>模型保存：tmp/model.ckpt 当前训练损失：0.00400956<br>模型保存：tmp/model.ckpt 当前训练损失：0.00392799<br>模型保存：tmp/model.ckpt 当前训练损失：0.00383506<br>模型保存：tmp/model.ckpt 当前训练损失：0.00373741<br>模型保存：tmp/model.ckpt 当前训练损失：0.00366922</p>
<pre><code>第二次继续训练，得到：
</code></pre><p>模型保存：tmp/model.ckpt 当前训练损失：0.00412003<br>模型保存：tmp/model.ckpt 当前训练损失：0.00388735<br>模型保存：tmp/model.ckpt 当前训练损失：0.00382827<br>模型保存：tmp/model.ckpt 当前训练损失：0.00379988<br>模型保存：tmp/model.ckpt 当前训练损失：0.00378107<br>模型保存：tmp/model.ckpt 当前训练损失：0.003764<br>模型保存：tmp/model.ckpt 当前训练损失：0.00375149<br>模型保存：tmp/model.ckpt 当前训练损失：0.00374324<br>模型保存：tmp/model.ckpt 当前训练损失：0.00373386<br>模型保存：tmp/model.ckpt 当前训练损失：0.00372364<br>模型保存：tmp/model.ckpt 当前训练损失：0.00371543<br>模型保存：tmp/model.ckpt 当前训练损失：0.00370875<br>模型保存：tmp/model.ckpt 当前训练损失：0.00370262<br>模型保存：tmp/model.ckpt 当前训练损失：0.00369697<br>模型保存：tmp/model.ckpt 当前训练损失：0.00369161<br>模型保存：tmp/model.ckpt 当前训练损失：0.00368653<br>模型保存：tmp/model.ckpt 当前训练损失：0.00368169<br>模型保存：tmp/model.ckpt 当前训练损失：0.00367714<br>模型保存：tmp/model.ckpt 当前训练损失：0.00367274<br>模型保存：tmp/model.ckpt 当前训练损失：0.00366843<br>可以看到，第二次训练是在第一次训练的基础上继续训练的。于是，我们可以把我们想要的模型保存下来，慢慢训练。</p>
<h1 id="参考文献-4"><a href="#参考文献-4" class="headerlink" title="参考文献"></a>参考文献</h1><ol>
<li>《TensorFlow使用指南》：<a href="http://www.tensorfly.cn/tfdoc/tutorials/mnist_tf.html" target="_blank" rel="noopener">http://www.tensorfly.cn/tfdoc/tutorials/mnist_tf.html</a></li>
<li>TensorFlow中模型保存与读取：<a href="https://www.cnblogs.com/tengge/p/6379893.html" target="_blank" rel="noopener">https://www.cnblogs.com/tengge/p/6379893.html</a></li>
</ol>
<h1 id="11-使用TensorBoard显示图片"><a href="#11-使用TensorBoard显示图片" class="headerlink" title="11 使用TensorBoard显示图片"></a>11 使用TensorBoard显示图片</h1><p>首先，下载一张png格式的图片（注意：只支持png格式），命名为1.png。然后，打开PythonShell，输入以下代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取图片数据</span></span><br><span class="line">file = open(<span class="string">'1.png'</span>, <span class="string">'rb'</span>)</span><br><span class="line">data = file.read()</span><br><span class="line">file.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图片处理</span></span><br><span class="line">image = tf.image.decode_png(data, channels=<span class="number">4</span>)</span><br><span class="line">image = tf.expand_dims(image, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加到日志中</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">writer = tf.summary.FileWriter(<span class="string">'logs'</span>)</span><br><span class="line">summary_op = tf.summary.image(<span class="string">"image1"</span>, image)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行并写入日志</span></span><br><span class="line">summary = sess.run(summary_op)</span><br><span class="line">writer.add_summary(summary)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭</span></span><br><span class="line">writer.close()</span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;然后，在相同目录打开cmd，输入<strong>tensorboard —logdir=logs</strong>，然后打开浏览器输入<code>http://localhost:6006/</code>。在Tensorboard的Images标签页，就可以看到我们的png图片了。<br><img src="/images/训练TensorFlow识别手写数字/tensorboard.png" alt></p>
<h2 id="参考文献-5"><a href="#参考文献-5" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li><a href="https://www.cnblogs.com/tengge/p/6390148.html" target="_blank" rel="noopener">11 使用TensorBoard显示图片</a></li>
</ul>
<h1 id="12-使用卷积神经网络识别手写数字"><a href="#12-使用卷积神经网络识别手写数字" class="headerlink" title="12 使用卷积神经网络识别手写数字"></a>12 使用卷积神经网络识别手写数字</h1><p>看代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载训练和测试数据</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST_data/'</span>, one_hot = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建session</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 占位符</span></span><br><span class="line">x = tf.placeholder(tf.float32, shape=[<span class="literal">None</span>, <span class="number">784</span>]) <span class="comment"># 每张图片28*28，共784个像素</span></span><br><span class="line">y_ = tf.placeholder(tf.float32, shape=[<span class="literal">None</span>, <span class="number">10</span>]) <span class="comment"># 输出为0-9共10个数字，其实就是把图片分为10类</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 权重初始化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">    initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>) <span class="comment"># 使用截尾正态分布的随机数初始化权重，标准偏差是0.1（噪音）</span></span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">    initial = tf.constant(<span class="number">0.1</span>, shape = shape) <span class="comment"># 使用一个小正数初始化偏置，避免出现偏置总为0的情况</span></span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 卷积和集合</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, W)</span>:</span> <span class="comment"># 计算2d卷积</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.conv2d(x, W, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span><span class="params">(x)</span>:</span> <span class="comment"># 计算最大集合</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一层卷积</span></span><br><span class="line">W_conv1 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>]) <span class="comment"># 为每个5*5小块计算32个特征</span></span><br><span class="line">b_conv1 = bias_variable([<span class="number">32</span>])</span><br><span class="line"></span><br><span class="line">x_image = tf.reshape(x, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>]) <span class="comment"># 将图片像素转换为4维tensor，其中二三维是宽高，第四维是像素</span></span><br><span class="line">h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)</span><br><span class="line">h_pool1 = max_pool_2x2(h_conv1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二层卷积</span></span><br><span class="line">W_conv2 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">64</span>])</span><br><span class="line">b_conv2 = bias_variable([<span class="number">64</span>])</span><br><span class="line"></span><br><span class="line">h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)</span><br><span class="line">h_pool2 = max_pool_2x2(h_conv2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 密集层</span></span><br><span class="line">W_fc1 = weight_variable([<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>, <span class="number">1024</span>]) <span class="comment"># 创建1024个神经元对整个图片进行处理</span></span><br><span class="line">b_fc1 = bias_variable([<span class="number">1024</span>])</span><br><span class="line"></span><br><span class="line">h_pool2_flat = tf.reshape(h_pool2, [<span class="number">-1</span>, <span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>])</span><br><span class="line">h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 退出（为了减少过度拟合，在读取层前面加退出层，仅训练时有效）</span></span><br><span class="line">keep_prob = tf.placeholder(tf.float32)</span><br><span class="line">h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取层（最后我们加一个像softmax表达式那样的层）</span></span><br><span class="line">W_fc2 = weight_variable([<span class="number">1024</span>, <span class="number">10</span>])</span><br><span class="line">b_fc2 = bias_variable([<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测类和损失函数</span></span><br><span class="line">cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv)) <span class="comment"># 计算偏差平均值</span></span><br><span class="line">train_step = tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(cross_entropy) <span class="comment"># 每一步训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y_conv,<span class="number">1</span>), tf.argmax(y_,<span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    batch = mnist.train.next_batch(<span class="number">50</span>)</span><br><span class="line">    <span class="keyword">if</span> i%<span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        train_accuracy = accuracy.eval(feed_dict=&#123; x:batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>], keep_prob: <span class="number">1.0</span>&#125;, session = sess) <span class="comment"># 每10次训练计算一次精度</span></span><br><span class="line">        print(<span class="string">"步数 %d, 精度 %g"</span>%(i, train_accuracy))</span><br><span class="line">    train_step.run(feed_dict=&#123;x: batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>], keep_prob: <span class="number">0.5</span>&#125;, session = sess)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭</span></span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure></p>
<p>执行上面的代码后输出：</p>
<p>Extracting MNIST_data/train-images-idx3-ubyte.gz<br>Extracting MNIST_data/train-labels-idx1-ubyte.gz<br>Extracting MNIST_data/t10k-images-idx3-ubyte.gz<br>Extracting MNIST_data/t10k-labels-idx1-ubyte.gz<br>步数 0, 精度 0.12<br>步数 10, 精度 0.34<br>步数 20, 精度 0.52<br>步数 30, 精度 0.56<br>步数 40, 精度 0.6<br>步数 50, 精度 0.74<br>步数 60, 精度 0.74<br>步数 70, 精度 0.78<br>步数 80, 精度 0.82</p>
<p>……….</p>
<p>步数 900, 精度 0.96<br>步数 910, 精度 0.98<br>步数 920, 精度 0.96<br>步数 930, 精度 0.98<br>步数 940, 精度 0.98<br>步数 950, 精度 0.9<br>步数 960, 精度 0.98<br>步数 970, 精度 0.9<br>步数 980, 精度 1<br>步数 990, 精度 0.9<br>&emsp;&emsp;可以看到，使用卷积神经网络训练1000次可以让精度达到95%以上，据说训练20000次精度可以达到99.2%以上。由于CPU不行，太耗时间，就不训练那么多了。大家可以跟使用softmax训练识别手写数字进行对比。<a href="http://www.cnblogs.com/tengge/p/6363586.html" target="_blank" rel="noopener">《07 训练Tensorflow识别手写数字》</a></p>
<h1 id="参考文献-6"><a href="#参考文献-6" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://www.cnblogs.com/tengge/p/6920144.html" target="_blank" rel="noopener">12 使用卷积神经网络识别手写数字</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/windows-xi-tong-xia-tensorboard-xian-shi-kong-bai-de-wen-ti.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/windows-xi-tong-xia-tensorboard-xian-shi-kong-bai-de-wen-ti.html" class="post-title-link" itemprop="url">Windows系统下Tensorboard显示空白的问题</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-04-26 22:13:14 / 修改时间：22:24:32" itemprop="dateCreated datePublished" datetime="2019-04-26T22:13:14+08:00">2019-04-26</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">262</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">1 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Tensorboard显示空白，或者graphs中显示“No graph definition files were found”，在数据正确的前提下，最可能是路径的问题。<br>Windows 下通过cmd启动tensorboard，采用如下两种方法可以避免路径造成的问题（假设文件在D盘的logs文件夹下）：<br>1.文件夹之间使用 // 分割<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;tensorboard --logdir=D://logs</span><br></pre></td></tr></table></figure></p>
<p>2.将路径直接切换到文件的上一级目录下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;cd D:</span><br><span class="line">&gt;tensorboard --logdir=logs</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/ji-qi-xue-xi-chang-jian-chu-li-fang-fa.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/ji-qi-xue-xi-chang-jian-chu-li-fang-fa.html" class="post-title-link" itemprop="url">机器学习常见处理方法</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-04-24 20:14:47 / 修改时间：20:31:55" itemprop="dateCreated datePublished" datetime="2019-04-24T20:14:47+08:00">2019-04-24</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">1.5k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">1 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="img-size-mnist-train-images-0-shape-0"><a href="#img-size-mnist-train-images-0-shape-0" class="headerlink" title="img_size = mnist.train.images[0].shape[0]"></a>img_size = mnist.train.images[0].shape[0]</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#%matplotlib inline</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">"TensorFlow Version: &#123;&#125;"</span>.format(tf.__version__))</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'./MNIST_data/'</span>)</span><br><span class="line"></span><br><span class="line">i = <span class="number">10</span></span><br><span class="line">img = mnist.train.images[i]</span><br><span class="line">plt.imshow(img.reshape((<span class="number">28</span>, <span class="number">28</span>)), cmap=<span class="string">'Greys_r'</span>)</span><br><span class="line">print(<span class="string">"Label: &#123;&#125;"</span>.format(mnist.train.labels[i]))</span><br><span class="line">img_size = mnist.train.images[<span class="number">10</span>].shape[<span class="number">0</span>]</span><br><span class="line">print(img_size)</span><br><span class="line">print(img.shape)</span><br></pre></td></tr></table></figure>
<p>执行上述语句返回的结果为：<br>Label: 0<br>784<br>(784,)<br><img src="/images/机器学习常见处理方法/img1-1.png" alt></p>
<h1 id="hidden1-tf-layers-dense-noise-img-n-units"><a href="#hidden1-tf-layers-dense-noise-img-n-units" class="headerlink" title="hidden1 = tf.layers.dense(noise_img, n_units)"></a>hidden1 = tf.layers.dense(noise_img, n_units)</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_generator</span><span class="params">(noise_img, n_units, out_dim, reuse=False, alpha=<span class="number">0.01</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    生成器</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    noise_img: 生成器的输入</span></span><br><span class="line"><span class="string">    n_units: 隐层单元个数</span></span><br><span class="line"><span class="string">    out_dim: 生成器输出tensor的size，这里应该为32*32=784</span></span><br><span class="line"><span class="string">    alpha: leaky ReLU系数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">"generator"</span>, reuse=reuse):</span><br><span class="line">        <span class="comment"># hidden layer</span></span><br><span class="line">        hidden1 = tf.layers.dense(noise_img, n_units)</span><br><span class="line">        <span class="comment"># leaky ReLU</span></span><br><span class="line">        hidden1 = tf.maximum(alpha * hidden1, hidden1)</span><br><span class="line">        <span class="comment"># dropout</span></span><br><span class="line">        hidden1 = tf.layers.dropout(hidden1, rate=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># logits &amp; outputs</span></span><br><span class="line">        logits = tf.layers.dense(hidden1, out_dim)</span><br><span class="line">        outputs = tf.tanh(logits)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> logits, outputs</span><br></pre></td></tr></table></figure>
<p>上述代码中的”<code>hidden1 = tf.layers.dense(noise_img, n_units)</code>“<br>其中：<br>&emsp;noise_img-表示输入层的单元个数，这里使用了占位符表示，但要表明单元大小，个数为None<br>&emsp;n_units-表示第一个隐藏层中神经元个数，<br>这里的函数，表示是全连接，将输入层的神经元全部与第一个隐藏层的神经元，进行全连接。</p>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/python-pi-liang-xiu-gai-wen-jian-ming.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/python-pi-liang-xiu-gai-wen-jian-ming.html" class="post-title-link" itemprop="url">Python 批量修改文件名</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-04-22 11:09:18" itemprop="dateCreated datePublished" datetime="2019-04-22T11:09:18+08:00">2019-04-22</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-04-23 14:52:29" itemprop="dateModified" datetime="2019-04-23T14:52:29+08:00">2019-04-23</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/数据集处理/" itemprop="url" rel="index"><span itemprop="name">数据集处理</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">960</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">1 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Python-批量修改文件名"><a href="#Python-批量修改文件名" class="headerlink" title="Python 批量修改文件名"></a>Python 批量修改文件名</h1><p><a href="http://www.runoob.com/python3/python3-os-file-methods.html" target="_blank" rel="noopener">原文: Python3 OS 文件/目录方法</a><br><strong>批量修改文件名</strong><br>python 对文件进行批量改名用到的是 os 模块中的 listdir 方法和 rename 方法。</p>
<ul>
<li>os.listdir(dir) : 获取指定目录下的所有子目录和文件名</li>
<li>os.rename(原文件名，新文件名）: 对文件或目录改名</li>
</ul>
<p>把混乱的文件名改成有序的文件名:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">path=input(<span class="string">'请输入文件路径(结尾加上/)：'</span>)       </span><br><span class="line"></span><br><span class="line"><span class="comment">#获取该目录下所有文件，存入列表中</span></span><br><span class="line">f=os.listdir(path)</span><br><span class="line"></span><br><span class="line">n=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> f:</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#设置旧文件名（就是路径+文件名）</span></span><br><span class="line">    oldname=path+f[n]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#设置新文件名</span></span><br><span class="line">    newname=path+<span class="string">'a'</span>+str(n+<span class="number">1</span>)+<span class="string">'.JPG'</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#用os模块中的rename方法对文件改名</span></span><br><span class="line">    os.rename(oldname,newname)</span><br><span class="line">    print(oldname,<span class="string">'======&gt;'</span>,newname)</span><br><span class="line">    </span><br><span class="line">    n+=<span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<p><img src="/images/Python-批量修改文件名/img1-1.png" alt="img1-1.png"><br><img src="/images/Python-批量修改文件名/img1-2.png" alt="img1-2.png"></p>
<h1 id="参考地址"><a href="#参考地址" class="headerlink" title="参考地址"></a>参考地址</h1><p><a href="http://www.runoob.com/note/27030" target="_blank" rel="noopener">Python 批量修改文件名</a><br><a href="http://www.runoob.com/python/att-string-endswith.html" target="_blank" rel="noopener">Python endswith()方法</a></p>
<p>搜索内容：img_rgb = img_bgr[…, ::-1]<br><a href="https://www.jianshu.com/p/bd20afad708c" target="_blank" rel="noopener">opencv-python几何变换</a><br><a href="https://www.cnblogs.com/pakfahome/p/3917143.html" target="_blank" rel="noopener">Python中cv2库和matplotlib库色彩空间排布不一致</a><br><a href="https://www.programcreek.com/python/example/71304/cv2.COLOR_BGR2RGB" target="_blank" rel="noopener">Python cv2.COLOR_BGR2RGB() Examples</a><br><a href="https://blog.csdn.net/yuanlulu/article/details/79982347" target="_blank" rel="noopener">opencv-python的格式转换 RGB与BGR互转</a><br>[opencv-python的格式转换 RGB与BGR互转]</p>
<p><a href="https://blog.csdn.net/u011961856/article/details/76850335" target="_blank" rel="noopener">tensorflow 加载部分变量</a><br><a href="https://wiki.jikexueyuan.com/project/tensorflow-zh/how_tos/variables.html" target="_blank" rel="noopener">变量:创建、初始化、保存和加载</a><br><a href="https://blog.csdn.net/b876144622/article/details/79962727" target="_blank" rel="noopener">tensorflow 恢复部分参数、加载指定参数</a><br><a href="https://zhuanlan.zhihu.com/p/46128750" target="_blank" rel="noopener">TensorFlow学习笔记(9):模型存储与加载</a>北京大学 软件工程博士在读<br><a href="https://www.jb51.net/article/144581.htm" target="_blank" rel="noopener">tensorflow 加载部分变量的实例讲解</a><br><a href="https://blog.csdn.net/leviopku/article/details/78510977" target="_blank" rel="noopener">TensorFlow中对训练后的神经网络参数（权重、偏置）提取</a><br><a href="https://juejin.im/post/59e43b5b6fb9a0452a3b5f4f" target="_blank" rel="noopener">Keras 中构建神经网络的 5 个步骤</a><br><a href="https://github.com/strivebo/tensorflow-learning/blob/master/Notes/08-%E4%BF%9D%E5%AD%98%E5%92%8C%E8%BD%BD%E5%85%A5%E6%A8%A1%E5%9E%8B%EF%BC%8C%E4%BD%BF%E7%94%A8Google%E7%9A%84%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E7%BD%91%E7%BB%9Cinception-v3%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB.md" target="_blank" rel="noopener">08-保存和载入模型，使用Google的图像识别网络inception-v3进行图像识别.md</a></p>
<p><a href="https://blog.csdn.net/CoderPai/article/details/80302371" target="_blank" rel="noopener">TensorFlow-变量保存和恢复</a></p>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/eclipse-zuo-wei-python-de-kai-fa-gong-ju.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/eclipse-zuo-wei-python-de-kai-fa-gong-ju.html" class="post-title-link" itemprop="url">eclipse作为Python的开发工具</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-04-21 18:34:54" itemprop="dateCreated datePublished" datetime="2019-04-21T18:34:54+08:00">2019-04-21</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-04-23 21:08:06" itemprop="dateModified" datetime="2019-04-23T21:08:06+08:00">2019-04-23</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Machine-Learning/Eclipse/" itemprop="url" rel="index"><span itemprop="name">Eclipse</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">2.7k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">2 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Eclipse是一款基于Java的可扩展开发平台。其官方下载中包括J2EE方向版本、Java方向版本、C/C++方向版本、移动应用方向版本等诸多版本。除此之外，Eclipse还可以通过安装插件的方式进行诸如Python、Android、PHP等语言的开发。</p>
<p>其中PyDev是一个功能强大的 Eclipse插件，使用户可用 Eclipse 来进行 Python 应用程序的开发和调试。PyDev 插件的出现方便了众多的 Python 开发人员，它提供了一些很好的功能，如：语法错误提示、源代码编辑助手、Quick Outline、Globals Browser、Hierarchy View、运行和调试等等。</p>
<p>本文将介绍eclipse的pydev插件的安装与配置。 </p>
<h1 id="安装准备"><a href="#安装准备" class="headerlink" title="安装准备"></a>安装准备</h1><p>配置Python的系统环境变量PATH=D:\Python34（即python的安装目录）<br>显示python的版本，用来测试python的环境是否配置好 , 命令：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Python</span><br></pre></td></tr></table></figure></p>
<p>安装python的第三方库<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install pandas</span><br><span class="line">pip install PyMySql</span><br></pre></td></tr></table></figure></p>
<p><img src="/images/eclipse作为Python的开发工具/img1-4.png" alt><br>用来测试python运行时会不会出错，没报错就说明程序可以运行。</p>
<h1 id="安装教程"><a href="#安装教程" class="headerlink" title="安装教程"></a>安装教程</h1><pre><code>1. 首先下载jdk，安装，配置环境变量；
2. 再下载eclipse，配置编译器；
3. 写一个helloworld；（具体过程请专门看教程。）
</code></pre><p>这样，基础环境就搭好了。下面安装PyDev，有两种安装方法，分别介绍之：</p>
<h2 id="简易在线安装"><a href="#简易在线安装" class="headerlink" title="简易在线安装"></a>简易在线安装</h2><p>这是官网安装，下载安装很方便，但可能由于网络原因用时过长或失败。</p>
<p>官网安装过程如下：</p>
<h3 id="安装Pydev"><a href="#安装Pydev" class="headerlink" title="安装Pydev"></a>安装Pydev</h3><ul>
<li>Help - Install New Software<br><img src="/images/eclipse作为Python的开发工具/img1-1.png" alt><br>(1)点击 - Add<br>(2)输入 Name 和 Location，Name 随意，Location 为 <a href="http://pydev.org/updates" target="_blank" rel="noopener">http://pydev.org/updates</a> ； 点击OK<br>把【connect all update sites during install to find required software】的勾选去掉，否则在安装新插件时会联网寻找所有可能的更新站点搜索，导致安装时间不可预估，并可能导致安装失败。</li>
</ul>
<p>确定后可以看到一个Pending过程，然后得到如下图所示的插件：<br><img src="/images/eclipse作为Python的开发工具/img1-2.png" alt><br>勾选后，点击Next进行安装。</p>
<p>不过，由于网络的原因，这种方法安装PyDev极有可能失败，提示网络连接错误等。需要vpn。</p>
<h3 id="eclipse和python关联："><a href="#eclipse和python关联：" class="headerlink" title="eclipse和python关联："></a>eclipse和python关联：</h3><p>eclipse菜单 -&gt; Windows -&gt;Preferences -&gt; PyDev-&gt; Interpreters - Python Interpreter.<br>点击New按钮,选择python.exe的路径(第1步安装Python的路径),打开后显示出一个包含很多复选框的窗口,点OK结束！<br><img src="/images/eclipse作为Python的开发工具/img1-5.png" alt></p>
<h2 id="离线安装"><a href="#离线安装" class="headerlink" title="离线安装"></a>离线安装</h2><p>通常官网安装并不如人意，你懂的… 推荐离线安装，步骤如下</p>
<ol>
<li>下载PyDev离线安装包，我的云盘地址： <a href="http://pan.baidu.com/s/1pJ1HQKb" target="_blank" rel="noopener">http://pan.baidu.com/s/1pJ1HQKb</a></li>
<li>将解压后的features和plugins两个文件夹分别拷贝到Eclipse安装目录下的features和plugins目录中</li>
</ol>
<h1 id="PyDev的配置"><a href="#PyDev的配置" class="headerlink" title="PyDev的配置"></a>PyDev的配置</h1><p>不论官网安装还是离线安装，都需要配置PyDev，步骤如下</p>
<ol>
<li><p>启动Eclipse，打开window-&gt;Preferences</p>
</li>
<li><p>选择Interpreter-Python，然后选择New</p>
</li>
<li><p>点击【New】，添加一个系统里已有的Python解释器的位置。确定后会经过短暂的处理，得到它的Libraries、Buildins等。<br>(我写的地址是提前安装好的annaconda。)</p>
</li>
<li><p>最后，单击Reference界面下的 OK ; 等待后即可在Eclipse中写Python了。　</p>
</li>
</ol>
<h1 id="例子-实战"><a href="#例子-实战" class="headerlink" title="例子 实战"></a>例子 实战</h1><p>前面就已经配置好了Python的开发环境，下面新建一个项目，来测试一下，确实可以运行。</p>
<p>点击【File】-【New】-【Other】，找到【PyDev】，选择【PyDev Project】，点击Next。取一个项目名称，比如helloPython，如下图所示：<br><img src="/images/eclipse作为Python的开发工具/img1-3.png" alt></p>
<p>点击【Finish】，完成项目创建。然后你会进入PyDev视图，进行Python开发。</p>
<p>右键项目的src目录，选择【New】-【PyDev Package】，创建一个Python包，此处也命名为helloPython。</p>
<p>再右键该package，【New】-【PyDev Module】（python的module 就是java的calss），此处也命名为helloPython。 （pydev提供了一些模板，这边暂选 Empty）</p>
<p>双击打开 helloPython .py，添加如下代码。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span><span class="string">'hello python!'</span></span><br></pre></td></tr></table></figure></p>
<p>右键项目，选择【Run As】-【Python Run】，或Ctrl+F11运行项目。</p>
<p>此时，可以在下方的console窗口，看到项目的运行结果。</p>
<h1 id="PyDev的注释快捷键"><a href="#PyDev的注释快捷键" class="headerlink" title="PyDev的注释快捷键"></a>PyDev的注释快捷键</h1><p>个人认为，PyDev是很好用的python编辑器。使用起来的确得心应手，建议初学者多尝试用用。</p>
<p>下面从网上整理了一些PyDev的快捷键，和大家分享分享：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Ctrl+3 行注释</span><br><span class="line"></span><br><span class="line">Ctr+\ 去行注释</span><br><span class="line">Ctrl+Shift+3 去行注释</span><br><span class="line"></span><br><span class="line">Ctrl+4 块注释</span><br><span class="line">Ctrl+5 去块注释</span><br><span class="line"></span><br><span class="line">Ctrl+9 折叠全部</span><br><span class="line">Ctrl+0 展开全部</span><br><span class="line"></span><br><span class="line">Ctrl+- 折叠</span><br><span class="line">Ctrl+= 展开</span><br><span class="line"></span><br><span class="line">Ctrl+Shift+Up 上一函数</span><br><span class="line">Ctrl+Shift+Down 下一函数</span><br><span class="line"></span><br><span class="line">Ctrl+Shift+O 整理导入顺序</span><br></pre></td></tr></table></figure></p>
<h1 id="tensorflow中所安装的模块"><a href="#tensorflow中所安装的模块" class="headerlink" title="tensorflow中所安装的模块"></a>tensorflow中所安装的模块</h1><ol>
<li><p>Python安装cv2模块</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install opencv-python</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装 captcha</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install captcha</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><p><a href="https://www.python.org/dev/peps/pep-0263/" target="_blank" rel="noopener">PEP 263 — Defining Python Source Code Encodings</a></p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://www.52pojie.cn/thread-866403-1-1.html" target="_blank" rel="noopener">Eclipse环境安装Python插件PyDev</a></p>
<h1 id="其他网址"><a href="#其他网址" class="headerlink" title="其他网址"></a>其他网址</h1><p><a href="http://www.spiderpy.cn/blog/detail/32" target="_blank" rel="noopener">使用captcha模块生成图形验证码</a><br><a href="http://blog.ku-cat.com/2018/04/23/python-captcha/" target="_blank" rel="noopener">python使用captcha模块生成图形验证码</a></p>
<p><a href="https://www.jianshu.com/p/47f0319028f2" target="_blank" rel="noopener">【简书】1.CNN图片单标签分类（基于TensorFlow实现基础VGG16网络）</a><br><a href="https://www.jianshu.com/p/596db72a7e00" target="_blank" rel="noopener">【简书】2.CNN图片多标签分类（基于TensorFlow实现验证码识别OCR）</a><br><a href="https://blog.csdn.net/javastart/article/details/88087966" target="_blank" rel="noopener">【CSDN】2.CNN图片多标签分类（基于TensorFlow实现验证码识别OCR）</a></p>
<p><a href="https://blog.csdn.net/xijuezhu8128/article/details/79556878" target="_blank" rel="noopener">Tensorflow制作并用CNN训练自己的数据集</a></p>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/tensorflow-xue-xi-zhi-shi-dian-zong-jie.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/tensorflow-xue-xi-zhi-shi-dian-zong-jie.html" class="post-title-link" itemprop="url">TensorFlow学习知识点总结</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-04-19 09:06:42" itemprop="dateCreated datePublished" datetime="2019-04-19T09:06:42+08:00">2019-04-19</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-04-20 09:13:21" itemprop="dateModified" datetime="2019-04-20T09:13:21+08:00">2019-04-20</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/TensorFlow/" itemprop="url" rel="index"><span itemprop="name">TensorFlow</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">11k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">10 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="tf-equal-函数"><a href="#tf-equal-函数" class="headerlink" title="tf.equal()函数"></a>tf.equal()函数</h1><p>tensorflow 中tf.equal()用法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.equal(A, B，name=None)</span><br></pre></td></tr></table></figure></p>
<ul>
<li>对于单个变量，如果A==B,则返回true,否则返回false;</li>
<li>对于数组，会迭代的比较A[i]和B[i]，对应相等的则返回true,否则返回false<br>&emsp;&emsp;是对比这两个矩阵或者向量的相等的元素，如果是相等的那就返回True，否则返回False，返回的值的矩阵维度和A是一样的<br>&emsp;&emsp;equal，相等的意思。顾名思义，就是判断，A, B 是不是相等，它的判断方法不是整体判断，<br>&emsp;&emsp;而是逐个元素进行判断，如果相等就是True，不相等，就是False。<br>&emsp;&emsp;由于是逐个元素判断，所以A，B 的维度要一致。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"> </span><br><span class="line">A = [[<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]]</span><br><span class="line">B = [[<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>]]</span><br><span class="line"> </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(tf.equal(A, B)))</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>输出：<br>&emsp;&emsp;[[ True  True  True False False]]</p>
<h1 id="tf-cast-函数"><a href="#tf-cast-函数" class="headerlink" title="tf.cast()函数"></a>tf.cast()函数</h1><p>tf.cast(a, dtype=tf.float32)<br><strong>将a的类型转换成tf.float32 </strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">b = [<span class="number">1</span>, <span class="number">5</span>, <span class="number">3</span>]</span><br><span class="line">sess = tf.Session()</span><br><span class="line"><span class="keyword">with</span> sess.as_default():</span><br><span class="line">    acc = sess.run(tf.equal(a, b))</span><br><span class="line">    print(acc)　　</span><br><span class="line">    print(sess.run(tf.reduce_mean(tf.cast(acc, dtype=tf.float32))))</span><br></pre></td></tr></table></figure></p>
<p>运行结果如下图所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">True</span>]</span><br><span class="line"><span class="number">0.6666667</span></span><br></pre></td></tr></table></figure></p>
<p>代码解释：<br>假设a是输入的y_hat, b是预测的y<br>&emsp;&emsp;tf.equal(a, b)会比较每一个y和y_hat 是否相等<br>&emsp;&emsp;tf.cast(acc, dtype=tf.float32)将比较的结果转换成tf.float32类型<br>&emsp;&emsp;tf.reduce_mean()求所有tf.float32类型结果的均值 </p>
<h1 id="tf-argmax-函数"><a href="#tf-argmax-函数" class="headerlink" title="tf.argmax()函数"></a>tf.argmax()函数</h1><h2 id="tf-argmax-vector-1"><a href="#tf-argmax-vector-1" class="headerlink" title="tf.argmax(vector, 1)"></a>tf.argmax(vector, 1)</h2><p>&emsp;&emsp;返回的是vector中的最大值的索引号，如果vector是一个向量，那就返回一个值，如果是一个矩阵，那就返回一个向量，这个向量的每一个维度都是相对应矩阵行的最大值元素的索引号。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"> </span><br><span class="line">A = [[<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]]</span><br><span class="line">B = [[<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>], [<span class="number">2</span>,<span class="number">4</span>,<span class="number">1</span>]]</span><br><span class="line"> </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(tf.argmax(A, <span class="number">1</span>)))</span><br><span class="line">    print(sess.run(tf.argmax(B, <span class="number">1</span>)))</span><br></pre></td></tr></table></figure></p>
<p>运行结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(tf14) zhangkf@Ubuntu2:~/lenet5$ python one.py </span><br><span class="line">[<span class="number">4</span>]</span><br><span class="line">[<span class="number">2</span> <span class="number">1</span>]</span><br></pre></td></tr></table></figure></p>
<h2 id="tf-equal"><a href="#tf-equal" class="headerlink" title="tf.equal()"></a>tf.equal()</h2><p>tf.equal(A, B)是对比这两个矩阵或者向量的相等的元素，如果是相等的那就返回True，否则返回False，返回的值的矩阵维度和A是一样的<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"> </span><br><span class="line">A = [[<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]]</span><br><span class="line">B = [[<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>]]</span><br><span class="line"> </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(tf.equal(A, B)))</span><br></pre></td></tr></table></figure></p>
<p>运行结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(tf14) zhangkf@Ubuntu2:~/lenet5$ python one.py </span><br><span class="line">[[ <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span> <span class="literal">False</span> <span class="literal">False</span>]]</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"> </span><br><span class="line">A = [[<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]]</span><br><span class="line">B = [[<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">3</span>]]</span><br><span class="line"> </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(tf.equal(A, B)))</span><br></pre></td></tr></table></figure>
<p>运行结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(tf14) zhangkf@Ubuntu2:~/lenet5$ python one.py </span><br><span class="line">[[ <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span> <span class="literal">False</span> <span class="literal">False</span>]</span><br><span class="line"> [<span class="literal">False</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span> <span class="literal">False</span>]]</span><br></pre></td></tr></table></figure></p>
<h2 id="二者结合起来"><a href="#二者结合起来" class="headerlink" title="二者结合起来"></a>二者结合起来</h2><p>在测试模型的准确率的时候，通常二者结合在一起。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">correct_prediction=tf.equal(tf.getmax(y,<span class="number">1</span>),tf.getmax(y_,<span class="number">1</span>))</span><br><span class="line">accuracy=tf.reduce_mean(tf.cast(corrcet_prediction,tf.float32))<span class="comment">#求平均获取准确率</span></span><br></pre></td></tr></table></figure></p>
<h1 id="tf-argmax-与-tf-arg-max"><a href="#tf-argmax-与-tf-arg-max" class="headerlink" title="tf.argmax 与 tf.arg_max"></a>tf.argmax 与 tf.arg_max</h1><p>tf.argmax 与 tf.arg_max 用法相同，下面介绍 tf.argmax 用法 </p>
<h2 id="tf-argmax"><a href="#tf-argmax" class="headerlink" title="tf.argmax"></a>tf.argmax</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">argmax</span><span class="params">(input,</span></span></span><br><span class="line"><span class="function"><span class="params">           axis=None,</span></span></span><br><span class="line"><span class="function"><span class="params">           name=None,</span></span></span><br><span class="line"><span class="function"><span class="params">           dimension=None,</span></span></span><br><span class="line"><span class="function"><span class="params">           output_type=dtypes.int64)</span></span></span><br><span class="line"><span class="function"><span class="title">numpy</span>.<span class="title">argmax</span><span class="params">(a, axis=None, out=None)</span> </span></span><br><span class="line"><span class="function">返回沿轴<span class="title">axis</span>最大值的索引。</span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="title">Parameters</span>:</span> </span><br><span class="line">input: array_like，数组</span><br><span class="line">axis : int, 可选，默认情况下，索引的是平铺的数组，否则沿指定的轴。 </span><br><span class="line">out : array, 可选 如果提供，结果以合适的形状和类型被插入到此数组中。 </span><br><span class="line"> </span><br><span class="line">Returns: </span><br><span class="line">index_array : ndarray of ints </span><br><span class="line">索引数组。它具有与a.shape相同的形状，其中axis被移除。</span><br></pre></td></tr></table></figure>
<p>tf.argmax() 与 numpy.argmax() 方法的用法是一致的</p>
<p>axis = 0 的时候返回每一列最大值的位置索引<br>axis = 1 的时候返回每一行最大值的位置索引<br>axis = 2、3、4 …，即为多维张量时，同理推断</p>
<p><strong>例子</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.arange(<span class="number">6</span>).reshape(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.argmax(a)</span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.argmax(a, axis=<span class="number">0</span>)  <span class="comment">#0代表列</span></span><br><span class="line">array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.argmax(a, axis=<span class="number">1</span>)  <span class="comment">#1代表行</span></span><br><span class="line">array([<span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = np.arange(<span class="number">6</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b[<span class="number">1</span>] = <span class="number">5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">array([<span class="number">0</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.argmax(b)  <span class="comment">#只返回第一次出现的最大值的索引</span></span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<h2 id="tf-arg-max"><a href="#tf-arg-max" class="headerlink" title="tf.arg_max()"></a>tf.arg_max()</h2><p>&emsp;&emsp;The following is the source code of argmax<br>&emsp;&emsp;(from <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_ops.py" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_ops.py</a>).<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pylint: disable=redefined-builtin</span></span><br><span class="line"><span class="comment"># TODO(aselle): deprecate arg_max</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">argmax</span><span class="params">(input, axis=None, name=None, dimension=None)</span>:</span></span><br><span class="line">  <span class="keyword">if</span> dimension <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">if</span> axis <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">"Cannot specify both 'axis' and 'dimension'"</span>)</span><br><span class="line">    axis = dimension</span><br><span class="line">  <span class="keyword">elif</span> axis <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    axis = <span class="number">0</span></span><br><span class="line">  <span class="keyword">return</span> gen_math_ops.arg_max(input, axis, name)</span><br></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;As you can see, argmax is using arg_max inside. Also from the code, I recommend using argmax because arg_max could be deprecated soon.  </p>
<p>Python获取文件夹下的文件和子文件夹<br>笔者小白在写代码的时候遇到的这样的问题，就是说需要根据文件夹的路径获取该文件夹下面的所有的文件和子文件夹。这里就介绍python的os模块中的两个函数：os.walk() 、os.listdir()。</p>
<h1 id="os-walk"><a href="#os-walk" class="headerlink" title="os.walk()"></a>os.walk()</h1><p>该函数的原型是：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">os.walk(top, topdown=Ture, onerror=<span class="literal">None</span>, followlinks=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></p>
<p>该函数没有返回值。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">参数</span><br><span class="line"> 1. top -- 根目录下的每一个文件夹(包含它自己), 产生3-元组 (dirpath, dirnames, filenames)【文件夹路径, 文件夹名字, 文件名】。</span><br><span class="line"> 2. topdown --可选，为True或者没有指定, 一个目录的的3-元组将比它的任何子文件夹的3-元组先产生 (目录自上而下)。如果topdown为 False, 一个目录的3-元组将比它的任何子文件夹的3-元组后产生 (目录自下而上)。</span><br><span class="line"> 3. onerror -- 可选，是一个函数; 它调用时有一个参数, 一个OSError实例。报告这错误后，继续walk,或者抛出exception终止walk。</span><br><span class="line"> 4. followlinks -- 设置为 true，则通过软链接访问目录。</span><br></pre></td></tr></table></figure></p>
<p> 函数执行之后得到一个三元tupple（dirpath， dirnames， filenams。</p>
<ul>
<li>dirpath：string，是当前目录的路径；</li>
<li>dirnames：list， 是当前路径下所有的子文件夹名字；</li>
<li>filenames：list， 是当前路径下所有的非目录子文件的名字。<br>要获取完整的路径，dirnames和filenames是不包含路径信息的，可以使用<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">os.path.join(dirpath, dirnames)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>获得文件的完整路径。<br>代码示例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(<span class="string">"."</span>, topdown=<span class="literal">False</span>):</span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> files:</span><br><span class="line">        print(os.path.join(root, name))</span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> dirs:</span><br><span class="line">        print(os.path.join(root, name))</span><br></pre></td></tr></table></figure></p>
<p>当需要特定类型的文件时，代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-   </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">file_name</span><span class="params">(file_dir)</span>:</span>   </span><br><span class="line">    L=[]   </span><br><span class="line">    <span class="keyword">for</span> dirpath, dirnames, filenames <span class="keyword">in</span> os.walk(file_dir):  </span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> filenames :  </span><br><span class="line">            <span class="keyword">if</span> os.path.splitext(file)[<span class="number">1</span>] == <span class="string">'.jpg'</span>:  </span><br><span class="line">                L.append(os.path.join(dirpath, file))  </span><br><span class="line">    <span class="keyword">return</span> L</span><br></pre></td></tr></table></figure></p>
<p>其中os.path.splitext()函数将路径拆分为文件名+扩展名，例如os.path.splitext(“E:/lena.jpg”)将得到”E:/lena“+”.jpg”。</p>
<h1 id="os-listdir"><a href="#os-listdir" class="headerlink" title="os.listdir()"></a>os.listdir()</h1><p>os.listdir()函数返回指定路径下的文件和文件夹列表。<br>代码示例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os, sys</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开文件</span></span><br><span class="line">path = <span class="string">"/var/www/html/"</span></span><br><span class="line">dirs = os.listdir( path )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出所有文件和文件夹</span></span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> dirs:</span><br><span class="line">   <span class="keyword">print</span> file</span><br></pre></td></tr></table></figure></p>
<p>python 遍历文件夹及子文件夹<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">EnumPathFiles</span><span class="params">(path, callback)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(path):</span><br><span class="line">        print(<span class="string">'Error:"'</span>,path,<span class="string">'" is not a directory or does not exist.'</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    list_dirs = os.walk(path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> list_dirs:</span><br><span class="line">        <span class="keyword">for</span> d <span class="keyword">in</span> dirs:</span><br><span class="line">            EnumPathFiles(os.path.join(root, d), callback)</span><br><span class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> files:</span><br><span class="line">            callback(root, f)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">callbakc1</span><span class="params">(path, filename)</span>:</span></span><br><span class="line">    print(path+<span class="string">'\\'</span>+filename)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    EnumPathFiles(<span class="string">r'D:\Projects\python'</span>, callbakc1)</span><br></pre></td></tr></table></figure></p>
<p>python 遍历目录(包括子目录)下所有文件<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">list_all_files</span><span class="params">(rootdir)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> os</span><br><span class="line">    _files = []</span><br><span class="line">    list = os.listdir(rootdir) <span class="comment">#列出文件夹下所有的目录与文件</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,len(list)):</span><br><span class="line">           path = os.path.join(rootdir,list[i])</span><br><span class="line">           <span class="keyword">if</span> os.path.isdir(path):</span><br><span class="line">              _files.extend(list_all_files(path))</span><br><span class="line">           <span class="keyword">if</span> os.path.isfile(path):</span><br><span class="line">              _files.append(path)</span><br><span class="line">    <span class="keyword">return</span> _files</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">_fs = list_all_files(<span class="string">'./资料'</span>)</span><br><span class="line"><span class="comment">#将第一阶段的文件遍历出来</span></span><br><span class="line">_k = filter(<span class="keyword">lambda</span> x:re.compile(<span class="string">r'stage2.txt'</span>).search(x),_fs)</span><br><span class="line">```    </span><br><span class="line"></span><br><span class="line">python 便利文件夹，返回所有文件夹及其子文件夹</span><br><span class="line">``` python </span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># File Name:aa.py</span></span><br><span class="line"><span class="comment"># Author: biolxy</span></span><br><span class="line"><span class="comment"># E-mail:biolxy@aliyun.com</span></span><br><span class="line"><span class="comment"># Created Time:Wed 14 Mar 2018 07:06:03 PM PDT</span></span><br><span class="line"><span class="comment"># python getDir.py /home/user/soft   返回/home/user/soft 下所有文件夹及子文件夹名字</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"> </span><br><span class="line">fistr_dir = os.path.abspath(sys.argv[<span class="number">1</span>])</span><br><span class="line"><span class="comment">#print("fistr_dir is:\t&#123;&#125;".format(fistr_dir))</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_all_dir_from_dir</span><span class="params">(dir)</span>:</span></span><br><span class="line">    <span class="comment"># 遍历文件夹，输出文件夹及子文件夹</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(dir):</span><br><span class="line">        path_dir = os.path.abspath(dir)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> os.listdir(path_dir):</span><br><span class="line">            path_i = os.path.join(path_dir, i)</span><br><span class="line">            <span class="keyword">if</span> os.path.isdir(path_i):</span><br><span class="line">                print(path_i)</span><br><span class="line">                get_all_dir_from_dir(path_i)</span><br><span class="line"> </span><br><span class="line">get_all_dir_from_dir(fistr_dir)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python getDir.py /home/user/soft</span><br></pre></td></tr></table></figure>
<p>注意，如果你没有改文件夹的访问权限，改脚本无法显示该文件夹</p>
<p>来源：<br>从网上下载了一个听书课程，里边是按照时间顺序放在文件夹中，一级目录嵌套一级目录，具体的mp3文件放在三级目录中，通过编写py函数，实现对目录中文件的遍历并拷贝出指定的文件，此处是mp3文件。</p>
<p>编程思路：<br>人都是惰性了，刚想到这个问题，第一时间是简单的一层一层的遍历，但是问题是不知道多少层，同时希望程序有一定的健壮性。就想到了递归思想。</p>
<p>具体编程实现<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"> </span><br><span class="line">file = <span class="string">"D:/BaiduNetdiskDownload/2017-10"</span></span><br><span class="line">todir = <span class="string">"C:/mp3File"</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">searchMp3</span><span class="params">(path)</span>:</span></span><br><span class="line">  <span class="keyword">for</span> item <span class="keyword">in</span> os.listdir(path):</span><br><span class="line">    subFile = path+<span class="string">"/"</span>+item</span><br><span class="line">    <span class="keyword">if</span> os.path.isdir(subFile):</span><br><span class="line">      searchMp3(subFile)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">if</span> os.path.splitext(subFile)[<span class="number">1</span>] ==<span class="string">".mp3"</span>:</span><br><span class="line">        shutil.copy(subFile ,todir)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:  </span><br><span class="line">  searchMp3(file)</span><br></pre></td></tr></table></figure></p>
<p>假设FILE文件夹中有三个文件夹分别是file1,file2。file1中有文件夹sf1和sf2.file2中有sf3和sf4。sf1-4中分别各有一个MP3文件，分别是m1.mp3—-m4.mp3。</p>
<p>path是FILE路径。开始循环：</p>
<p>subFile = path/file1 因为subFile也是文件，此时把 subFile作为path传递给searchFile函数，记住，此时第一次循环还没有结束。此时path路径下面也有两个子文件，此时，subFile = path/file1/sf1。当然sf1也是文件，把此时的subFile当做参数传给searchMp3函数，记住，此时path/file下面还没有遍历完成。把path/file1/sf1当做path，此时，文件中有一个m1.mp3文件。不是文件夹，执行else语句，判断文件后缀是mp3则移动都指定目录。此时开始执行subFile = path/file1/sf2。同样的执行else语句。此时开始执行 subFile = path/file2同样的遍历过程。最后把所有的指定文件都遍历出来。如果还不理解，可以自己画图，更好的理解整个过程。 </p>
<h1 id="tf-one-hot"><a href="#tf-one-hot" class="headerlink" title="tf.one_hot()"></a>tf.one_hot()</h1><p>tensorflow中tf.one_hot()函数的作用是将一个值化为一个概率分布的向量，一般用于分类问题。(<a href="https://blog.csdn.net/wenqiwenqi123/article/details/78055740" target="_blank" rel="noopener">参考地址</a>)<br>具体用法以及作用见以下代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"> </span><br><span class="line">SIZE=<span class="number">6</span></span><br><span class="line">CLASS=<span class="number">8</span></span><br><span class="line">label1=tf.constant([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>])</span><br><span class="line">sess1=tf.Session()</span><br><span class="line">print(<span class="string">'label1:'</span>,sess1.run(label1))</span><br><span class="line">b = tf.one_hot(label1,CLASS,<span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    sess.run(b)</span><br><span class="line">    print(<span class="string">'after one_hot'</span>,sess.run(b))</span><br></pre></td></tr></table></figure></p>
<p>最后的输出为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">label1: [<span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">6</span> <span class="number">7</span>]</span><br><span class="line">after one_hot:</span><br><span class="line"></span><br><span class="line"> [[<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>]]</span><br></pre></td></tr></table></figure></p>
<p><strong>tf.one_hot（）使用</strong><br>(<a href="https://blog.csdn.net/m0_37561765/article/details/78207508" target="_blank" rel="noopener">参考地址</a>)tf.one_hot在看conditionGAN的时候注意到label的输入要把它转换成one-hot形式，再与噪声z进行tf.concat输入，之前看的时候忽略了，现在再看才算明白为什么。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tf.one_hot(</span><br><span class="line">    indices,<span class="comment">#输入，这里是一维的</span></span><br><span class="line">    depth,<span class="comment"># one hot dimension.</span></span><br><span class="line">    on_value=<span class="literal">None</span>,<span class="comment">#output 默认1</span></span><br><span class="line">    off_value=<span class="literal">None</span>,<span class="comment">#output 默认0</span></span><br><span class="line">    axis=<span class="literal">None</span>,<span class="comment">#根据我的实验，默认为1</span></span><br><span class="line">    dtype=<span class="literal">None</span>,</span><br><span class="line">    name=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p>代码示例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">z=np.random.randint(<span class="number">0</span>,<span class="number">10</span>,size=[<span class="number">10</span>])</span><br><span class="line">y=tf.one_hot(z,<span class="number">10</span>,on_value=<span class="number">1</span>,off_value=<span class="literal">None</span>,axis=<span class="number">0</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session()<span class="keyword">as</span> sess:</span><br><span class="line">    print(z)</span><br><span class="line">    print(sess.run(y))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[<span class="number">5</span> <span class="number">7</span> <span class="number">7</span> <span class="number">0</span> <span class="number">5</span> <span class="number">5</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">[[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]]</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"2"</span></span><br><span class="line">z=np.random.randint(<span class="number">0</span>,<span class="number">10</span>,size=[<span class="number">10</span>])</span><br><span class="line">y=tf.one_hot(z,<span class="number">10</span>,on_value=<span class="number">1</span>,off_value=<span class="literal">None</span>)</span><br><span class="line">y1=tf.one_hot(z,<span class="number">10</span>,on_value=<span class="number">1</span>,off_value=<span class="literal">None</span>,axis=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session()<span class="keyword">as</span> sess:</span><br><span class="line">    print(z)</span><br><span class="line">    print(sess.run(y))</span><br><span class="line">    print(<span class="string">"axis=1按行排"</span>, sess.run(y1))</span><br><span class="line"></span><br><span class="line">    [<span class="number">6</span> <span class="number">3</span> <span class="number">4</span> <span class="number">9</span> <span class="number">6</span> <span class="number">5</span> <span class="number">5</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span>]</span><br><span class="line">[[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]]</span><br><span class="line">axis=<span class="number">1</span>按行排 [[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]]</span><br></pre></td></tr></table></figure>
<p> 感觉实际用的时候可以不传入axis值。可以看到经过one-hot的处理，输入的维度变成了10×depth，值也变成了0和1.</p>
<p>下面说在condition GAN中要输入标签信息y，怎样处理的。<br>y是mnist的标签值，0和10之间的整数，尺寸为[BATCH],经过one-hot处理后维度变成了[BATCH，10]值也是0和1，此时再与噪声z按列（axis=1）连接，变成条件GAN的输入。因此one-hot操作是必须的，这个处理在infoGAN中将z，categorical latent code、continuous latent code连接在一起输入也要用到。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y = tf.one_hot(y, <span class="number">10</span>, name=<span class="string">'label_onehot'</span>)</span><br><span class="line">z = tf.random_uniform([BATCH, <span class="number">100</span>], <span class="number">-1</span>, <span class="number">1</span>, name=<span class="string">'z_train'</span>)</span><br><span class="line">tf.concat([z, y], <span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<p>【<a href="https://blog.csdn.net/qq_35203425/article/details/79997271" target="_blank" rel="noopener">参考3</a>】tensorflow中将label索引转换成one-hot形式<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">index=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">one_hot=tf.one_hot(index,<span class="number">5</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line"> </span><br><span class="line">    print(sess.run(one_hot))</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span>]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/ji-yu-python-de-xiao-yuan-wang-zi-dong-deng-lu.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/ji-yu-python-de-xiao-yuan-wang-zi-dong-deng-lu.html" class="post-title-link" itemprop="url">基于Python的校园网自动登录</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-04-09 12:25:57 / 修改时间：13:39:59" itemprop="dateCreated datePublished" datetime="2019-04-09T12:25:57+08:00">2019-04-09</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">3.4k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">3 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>搞了几天终于把这个搞出来了，代码不到50行，要是别的网站很好模拟，但是这个稍微有点麻烦，抓包工具用了很多，httpfox没有抓全，wireshark抓的又太多不好分析，最后还是使用神器fiddle才把它搞出来。</p>
<h1 id="工具"><a href="#工具" class="headerlink" title="工具"></a>工具</h1><ul>
<li>火狐浏览器+firedebug插件，debug插件可在浏览器附加组件中添加，其他浏览器也可以，只要有可以监控浏览器的网络行为插件即可。（<font color="red">notes:这里没有使用到firedebug，而是使用火狐浏览器自带的审查工具</font>）</li>
<li>Python+requests包</li>
</ul>
<h1 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h1><p>打开火狐浏览器，输入网址”<code>http://211.85.192.115/srun_portal_pc.php?ac_id=1&amp;</code>“，打开校园网登录页面，如下：<br><img src="/images/基于Python的校园网自动登录/img1-1.png" alt><br>登录账号和密码，显示登录成功<br><img src="/images/基于Python的校园网自动登录/img1-2.png" alt><br>右键单击【审查元素】-【网络】<br><img src="/images/基于Python的校园网自动登录/img1-3.png" alt><br>构造请求头<br><img src="/images/基于Python的校园网自动登录/img1-4.png" alt><br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 构造头部信息 注意Cookie可能十分重要，而且Cookie会有过期时间（我们学校过期时间是1个月），过期之后，可能需要复制新的Cookie替换。</span><br><span class="line">post_header = &#123;</span><br><span class="line">   #'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36',</span><br><span class="line">   'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0',</span><br><span class="line">   'Accept': '*/*',</span><br><span class="line">   #'Accept-Language': 'zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3',</span><br><span class="line">   'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',</span><br><span class="line">   'Accept-Encoding': 'gzip, deflate',</span><br><span class="line">   #'Content-Type': 'application/x-www-form-urlencoded',</span><br><span class="line">   'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',</span><br><span class="line">   'X-Requested-With': 'XMLHttpRequest',</span><br><span class="line"></span><br><span class="line">   #'Origin': 'http://wlrz.fudan.edu.cn',</span><br><span class="line">   'Referer': 'http://211.85.192.115/srun_portal_pc.php?ac_id=1&amp;',</span><br><span class="line">   #'Content-Length': '112',</span><br><span class="line">   'Content-Length': '104',</span><br><span class="line">   #'Cookie': 'login=YUtl4F5w2GWDfWUA8O0nj3eCm7TrrFp%252FtbchCKzbO84IQczKx%252Fyc5mYGG7s6FQxsyiZbjwUIcJ2ECcqXWO%252BzwX85KrsMq0MDW7tX1eoOzS00eusx19E0245ORqeeZHVwBzEd1DGI%253D',</span><br><span class="line">   'Cookie': 'login=请自己获得，这里不提供',</span><br><span class="line">   #'Host': 'wlrz.fudan.edu.cn',</span><br><span class="line">   'Host': '211.85.192.115',</span><br><span class="line">   'Connection': 'keep-alive',</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>构造发送数据<br><img src="/images/基于Python的校园网自动登录/img1-5.png" alt><br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">#此处根据自己校园网Form Data中发送的数据进行更改</span><br><span class="line">action = 'login'</span><br><span class="line">username = '学号'</span><br><span class="line">#password = '加密的密码'</span><br><span class="line">password = '密码xxx'</span><br><span class="line">ac_id = '1'</span><br><span class="line">save_me = '0'</span><br><span class="line">ajax = '1'</span><br><span class="line">#user_ip = '127.131.1.1'</span><br><span class="line"></span><br><span class="line">post_data = &#123;</span><br><span class="line">   'action': action,</span><br><span class="line">   'username': username,</span><br><span class="line">   'password': password,</span><br><span class="line">#   'password': base64.b64encode(password.encode()).decode(),</span><br><span class="line">#   'password': base64.b64encode(password.encode()),</span><br><span class="line">   'ac_id': ac_id,</span><br><span class="line">#   'user_ip': user_ip,</span><br><span class="line">   'save_me': save_me,</span><br><span class="line">   'ajax': ajax</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>内容有方式、学号、密码还有其他，其中密码不是明文，这密码应该是加密的，在所有js文件中搜索password，发现有一处函数，验证了是base64加密方式。（<font color="red">注意：以下操作是在在Chrome浏览器中进行的</font>）<br>在chrome浏览器中，输入账号登录网址”<code>http://211.85.192.115/srun_portal_pc.php?ac_id=1&amp;</code>“，右键【审查元素】-【网络】，然后刷新<br><img src="/images/基于Python的校园网自动登录/img1-6.png" alt><br><img src="/images/基于Python的校园网自动登录/img1-7.png" alt><br>于是开始着手写代码了：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">def login_request():</span><br><span class="line">    if not is_net_ok():</span><br><span class="line">        print(&quot;[03]&#123;&#125; whpu-wlan is offline, request now...&quot;.format(datetime.datetime.now().strftime(&apos;%Y-%m-%d %H:%M:%S&apos;)))</span><br><span class="line">#        password = base64.b64encode(password.encode()).decode()    #加密</span><br><span class="line">        try:</span><br><span class="line">            # 发送post请求登录网页</span><br><span class="line">            result = requests.post(post_addr, data=post_data, headers=post_header)</span><br><span class="line"></span><br><span class="line">            # z.text为str类型的json数据因此先编码成byte类型再解码成unicode类型这样就可以正常输出中文</span><br><span class="line">            s = result.text.encode(&apos;utf-8&apos;).decode(&apos;unicode-escape&apos;)</span><br><span class="line">            print(s)</span><br><span class="line">            print(&quot;login success!&quot;)</span><br><span class="line">        except:</span><br><span class="line">            print(&quot;[00]&#123;&#125; request error, whpu-wlan isnto connected to WIFI...&quot;.format(datetime.datetime.now().strftime(&apos;%Y-%m-%d %H:%M:%S&apos;)))</span><br><span class="line">    else:</span><br><span class="line">        print(&quot;[02]&#123;&#125; whpu-wlan is online, login sucesss...&quot;.format(datetime.datetime.now().strftime(&apos;%Y-%m-%d %H:%M:%S&apos;)))</span><br><span class="line"></span><br><span class="line">login_request()</span><br></pre></td></tr></table></figure></p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><p><a href="https://blog.csdn.net/abitch/article/details/51939879" target="_blank" rel="noopener">(2016.7.18)python脚本实现自动登录校园网</a></p>
</li>
<li><p><a href="http://blog.csdn.net/shenhuaifeng/article/details/78333851" target="_blank" rel="noopener">(2017.10.24)python实现校园网自动登录</a></p>
</li>
<li><p><a href="https://blog.csdn.net/u012328159/article/details/81034763" target="_blank" rel="noopener">(2018.7.13)用python写服务器校园网上网认证脚本</a></p>
</li>
<li><p><a href="https://blog.csdn.net/kaspar1992/article/details/84172543" target="_blank" rel="noopener"><font color="red">(2018.11.24)基于python实现校园网自动登录</font></a></p>
</li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/zheng-jian-zhi-xing-ruan-jian-ge-ren-jia-mi-gou-wan-mei-po-jie-xin-de.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/zheng-jian-zhi-xing-ruan-jian-ge-ren-jia-mi-gou-wan-mei-po-jie-xin-de.html" class="post-title-link" itemprop="url">证件之星软件个人加密狗完美破解心得</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-20 18:49:08 / 修改时间：19:41:54" itemprop="dateCreated datePublished" datetime="2019-03-20T18:49:08+08:00">2019-03-20</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/电脑/" itemprop="url" rel="index"><span itemprop="name">电脑</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/电脑/破解心得/" itemprop="url" rel="index"><span itemprop="name">破解心得</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">1.1k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">1 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="破解过程"><a href="#破解过程" class="headerlink" title="破解过程"></a>破解过程</h1><p>由于此软件程序为Delphi 所编写，并且无壳，直接载入OD，发现有狗，第一次打狗，不容易，如下图<br><img src="/images/证件之星软件个人加密狗完美破解心得/img1-2.png" alt><br><img src="/images/证件之星软件个人加密狗完美破解心得/img1-1.png" alt><br>发现修改狗，轻松进入软件，但是通过使用软件后发现有以下四点问题：</p>
<ol>
<li>点击<code>&quot;一键完成&quot;</code>会出现错误信息弹窗，点击确定软件关闭，如下图：<br><img src="/images/证件之星软件个人加密狗完美破解心得/img1-3.png" alt></li>
</ol>
<p>程序载入OD,右键搜索中文字符“<font color="red">软件遇到异常错误，即将关闭</font>”，如下图，按图操作<br><img src="/images/证件之星软件个人加密狗完美破解心得/img1-4.png" alt><br><img src="/images/证件之星软件个人加密狗完美破解心得/img1-5.png" alt><br><strong>这个问题解决了，一键处理已经ok了</strong><br><strong>但是还有以下三个问题没有处理。</strong></p>
<p>由于此软件是Delphi编写的，利用其<code>特征码</code>给其<code>按钮事件</code>下断，载入OD，<font color="red">CTRL+G,转到00401000处,然后右键—-查找——-二进制字符串，输入我们的特征码740E8BD38B83????????FF93????????</font>，在特征码的下面都会有一个call，我们就在call处下断点，之后寻找下一个（CTRL+L），直到显示为没有。为什么要下那么多断点，因为我们也不知道那一个会用上。那如果特征码的情况比较多怎么办，我的建议是使用脚本（脚本百度），能快速的下断点，程序运行起来，结果发现，断下来了，但是这三个按钮点击依然闪退，找不到真正的按钮事件地址，怎么办了呢？</p>
<p>由于本菜鸟是新手，用了好多办法都不是很凑效，最后发现有这款软件，<font color="red">Delphi 事件到地址转换工具 v2.020</font> 汉化版——可以查看Delphi 程序软件的按钮事件真实地址，实在太好了，于是就将程序载入<font color="red">Delphi 事件到地址转换工具中</font>，终于找到了以<font color="red">OnClick</font> 显示的按钮事件真实地址。</p>
<p>如下图说明：以此处理三个问题，载入OD，Ctrl+G，输入地址，点击ok来到真是地址，然后找到图中关键跳修改即可。</p>
<ol>
<li><p>点击背景处理弹窗中的“处理”按钮，软件闪退，解决办法如下图。<br><img src="/images/证件之星软件个人加密狗完美破解心得/img1-6.jpg" alt><br><img src="/images/证件之星软件个人加密狗完美破解心得/img1-7.png" alt></p>
</li>
<li><p>点击照片保存弹窗中的“保存”按钮，软件闪退，解决办法如下图。<br><img src="/images/证件之星软件个人加密狗完美破解心得/img1-8.jpg" alt><br><img src="/images/证件之星软件个人加密狗完美破解心得/img1-9.png" alt></p>
</li>
<li><p>点击照片打印，软件闪退，解决办法如下图。<br><img src="/images/证件之星软件个人加密狗完美破解心得/img1-10.jpg" alt><br><img src="/images/证件之星软件个人加密狗完美破解心得/img1-11.png" alt><br>到此完美爆破，本菜鸟还需努力学习，谢谢大家！</p>
</li>
</ol>
<h1 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h1><h2 id="源程序下载"><a href="#源程序下载" class="headerlink" title="源程序下载"></a>源程序下载</h2><p><strong>原程序下载：</strong></p>
<ul>
<li><a href="http://xiazai.zhzzx.com/xiazai/zhengzhaozhixing-gerenban7.exe" target="_blank" rel="noopener">官网下载</a></li>
<li><a href="/images/证件之星软件个人加密狗完美破解心得/zhengzhaozhixing-gerenban7.exe">本地下载</a></li>
</ul>
<h2 id="爆破程序下载"><a href="#爆破程序下载" class="headerlink" title="爆破程序下载"></a>爆破程序下载</h2><p><strong>爆破程序下载：</strong></p>
<ul>
<li>百度网盘 链接:<a href="https://pan.baidu.com/s/1wOwV6tjtKZ5wI78dQJQKCA" target="_blank" rel="noopener">https://pan.baidu.com/s/1wOwV6tjtKZ5wI78dQJQKCA</a> 提取码: kpsg  </li>
<li><a href="/images/证件之星软件个人加密狗完美破解心得/之星个人加密狗版7.0.rar">本地下载</a></li>
</ul>
<h2 id="Delphi事件到地址转换工具-v2-020"><a href="#Delphi事件到地址转换工具-v2-020" class="headerlink" title="Delphi事件到地址转换工具 v2.020"></a>Delphi事件到地址转换工具 v2.020</h2><p>Delphi 事件到地址转换工具 v2.020 汉化版下载，<font color="red">解压密码：RCFF Team</font>：</p>
<ul>
<li>百度网盘 链接:<a href="https://pan.baidu.com/s/1Y_hgYvlcCjA_dObcrWSa4A" target="_blank" rel="noopener">https://pan.baidu.com/s/1Y_hgYvlcCjA_dObcrWSa4A</a> 密码:xihj</li>
<li><a href="/images/证件之星软件个人加密狗完美破解心得/Delphi 事件到地址转换工具 v2.020 汉化版.rar">本地下载</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/win10-xie-zai-huo-geng-gai-cheng-xu-zhong-bu-xian-shi-xiu-gai-ri-qi-he-lei-xing.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/win10-xie-zai-huo-geng-gai-cheng-xu-zhong-bu-xian-shi-xiu-gai-ri-qi-he-lei-xing.html" class="post-title-link" itemprop="url">win10卸载或更改程序中不显示修改日期和类型</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-19 21:50:06 / 修改时间：22:14:52" itemprop="dateCreated datePublished" datetime="2019-03-19T21:50:06+08:00">2019-03-19</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/电脑/" itemprop="url" rel="index"><span itemprop="name">电脑</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/电脑/常见故障/" itemprop="url" rel="index"><span itemprop="name">常见故障</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">216</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">1 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Windows7 卸载或更改程序 中不显示时间和大小<br>急求！win10控制面板的卸载软件，都不显示安装日期了<br>有个软件我安装了新版本，准备按安装日期卸旧版本。上次关机前都是正常显示安装日期的，打开就成这样了，混在一起（点击日期全都变成一天的了）</p>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p><img src="/images/win10卸载或更改程序中不显示修改日期和类型/img1-1.jpg" alt></p>
<h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><h2 id="方法1"><a href="#方法1" class="headerlink" title="方法1"></a>方法1</h2><p>在列表的空白处右键，在弹出的菜单中选择：“分组依据”，“更多”，勾选“安装时间”，最后点击“确定”即可。</p>
<h2 id="方法2"><a href="#方法2" class="headerlink" title="方法2"></a>方法2</h2><p>在名称栏上右击</p>
<p>将“安装时间”打勾即可</p>
<p>如下图所示：<br><img src="/images/win10卸载或更改程序中不显示修改日期和类型/img1-2.jpg" alt></p>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/baidupcs-go-de-an-zhuang-ji-shi-yong.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/baidupcs-go-de-an-zhuang-ji-shi-yong.html" class="post-title-link" itemprop="url">BaiduPCS-Go的安装及使用[CMD]</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-18 20:08:12 / 修改时间：21:31:09" itemprop="dateCreated datePublished" datetime="2019-03-18T20:08:12+08:00">2019-03-18</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/电脑/" itemprop="url" rel="index"><span itemprop="name">电脑</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/电脑/百度云下载/" itemprop="url" rel="index"><span itemprop="name">百度云下载</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/电脑/百度云下载/BaiduPCS-Go-CMD/" itemprop="url" rel="index"><span itemprop="name">BaiduPCS-Go[CMD]</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">4.1k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">4 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>你是否经常对百度网盘非VIP的几十K下载速度而痛恨不已？没错，百度就是无赖，VIP会员下载速度可以达到2MB/s，甚至更高，普通用户不加速也就算了，还限速！不能忍！其实，我个人对于百度的产品是十分抗拒的，因此平时基本不用百度的产品，但是也有例外的时候，比如百度网盘。因为对电影的画质要求比较高，所以一些1080P的电影动辄6、7个G，所以普通的网络下载是特别慢的，而且这些资源往往以种子的形式存在，于是经过摸索终于找到一个下载很快的方法，这里推荐给大家。当然，这个方法不仅适用于下载电影，任何保存于百度网盘的文件使用这种方法都可以达到不亚于VIP的速度，甚至顶速（具体情况取决于你使用的网络速度），关键是免费！</p>
<p>注：这个教程里会涉及到一些非常简单的命令行操作，但是非程序员请不要抵触或者害怕，毕竟带来的便利是可观的，来个效果图感受一下：</p>
<p><img src="/images/BaiduPCS-Go的安装及使用/img1-1.png" alt></p>
<p>BaiduPCS-Go是用Go语言写的一个开源的小工具，专门用于突破百度对于非VIP用户对百度网盘下载速度的限制。其项目源码地址如下：<a href="https://github.com/iikira/BaiduPCS-Go" target="_blank" rel="noopener">https://github.com/iikira/BaiduPCS-Go</a> 。在其readme文件中，对于软件的使用做了很详细的介绍，有兴趣的人可以阅读一下，我这里只介绍最基本的安装和使用方法。</p>
<h1 id="特色"><a href="#特色" class="headerlink" title="特色"></a>特色</h1><p> 这是一个仿Linux命令行的百度网盘客户端。（是的，不限速）</p>
<p>注意：<br>    文件名和目录名可用通配符<em>补全(使用</em>代替n个字符，n&gt;=0)。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 示例：</span><br><span class="line">d /a_directory/b_directory/c_file.txt =</span><br><span class="line">d /a*/b*/c*</span><br></pre></td></tr></table></figure></p>
<p>特点： </p>
<ul>
<li>跨平台（Windows，macOS，Android等） </li>
<li>支持多账户。 </li>
<li>网盘内列出文件和目录, 支持通配符匹配路径; </li>
<li>下载网盘内文件, 支持网盘内目录 (文件夹) 下载, 支持多个文件或目录下载, 支持断点续传和高并发高速下载。 </li>
<li>离线下载，支持http/https/ftp/电驴/磁力链协议。 </li>
<li>好玩，不过没有一点Linux基础，就不怎么好玩了。</li>
</ul>
<h1 id="软件下载及安装"><a href="#软件下载及安装" class="headerlink" title="软件下载及安装"></a>软件下载及安装</h1><p>项目地址: <a href="https://github.com/iikira/BaiduPCS-Go" target="_blank" rel="noopener">iikira/BaiduPCS-Go</a><br>下载地址: <a href="https://github.com/iikira/BaiduPCS-Go/releases" target="_blank" rel="noopener">iikira/BaiduPCS-Go releases</a></p>
<h2 id="a-Android-macOS"><a href="#a-Android-macOS" class="headerlink" title="a. Android/macOS"></a>a. Android/macOS</h2><p>Android：需要用到 Termux 或 NeoTerm 类软件。这里只提一下。<br>macOS：没有macOS的设备，这里属于凑字数。</p>
<h2 id="b-Windows"><a href="#b-Windows" class="headerlink" title="b. Windows"></a>b. Windows</h2><h3 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址:"></a>下载地址:</h3><ul>
<li>64位系统：<a href="https://github.com/iikira/BaiduPCS-Go/releases/download/v3.3.3/BaiduPCS-Go-v3.3.3-windows-x64.zip" target="_blank" rel="noopener">BaiduPCS-Go-v3.3.3-windows-x64.zip </a></li>
<li>32位系统：<a href="https://github.com/iikira/BaiduPCS-Go/releases/download/v3.3.3/BaiduPCS-Go-v3.3.3-windows-x86.zip" target="_blank" rel="noopener">BaiduPCS-Go-v3.3.3-windows-x86.zip</a></li>
<li>GitHub地址： <a href="https://github.com/iikira/BaiduPCS-Go/releases" target="_blank" rel="noopener">https://github.com/iikira/BaiduPCS-Go/releases</a></li>
</ul>
<h3 id="下载说明："><a href="#下载说明：" class="headerlink" title="下载说明："></a>下载说明：</h3><p><img src="/images/BaiduPCS-Go的安装及使用/img1-2.png" alt></p>
<p>请按照上述说明下载对应的版本，我只测试了windows和linux的机器，其他系统暂时没有测试。</p>
<p><code>对于windows系统，确认系统类型的方法：右键点击“我的电脑” -&gt; “属性” -&gt; “系统类型”</code></p>
<p><img src="/images/BaiduPCS-Go的安装及使用/img1-3.png" alt></p>
<p>该软件是绿色软件，下载完成后请直接解压到你的自己的软件目录即可。</p>
<h1 id="软件的使用"><a href="#软件的使用" class="headerlink" title="软件的使用"></a>软件的使用</h1><p>该软件的使用方法也很简单，在Linux下和Windows下的方法一模一样，只不过程序的名字有一点差异（Windows下，软件的名字叫做“BaiduPCS-Go.exe”，Linux下，软件的名字叫做“BaiduPCS-Go”）。以下以Windows系统为例讲解软件的使用。</p>
<h2 id="程序运行"><a href="#程序运行" class="headerlink" title="程序运行"></a>程序运行</h2><p>下载后解压缩，双击 BaiduPCS-Go.exe。<br>界面如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">----</span><br><span class="line">BaiduPCS-Go - 百度网盘客户端 for windows/amd64</span><br><span class="line">  .......</span><br><span class="line">  .......</span><br><span class="line">  .......</span><br><span class="line">BaiduPCS-Go &gt;</span><br></pre></td></tr></table></figure></p>
<p>界面很长，这里用省略号代替。</p>
<h2 id="登录-退出-切换"><a href="#登录-退出-切换" class="headerlink" title="登录/退出/切换"></a>登录/退出/切换</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">login     # 登录</span><br><span class="line">logout    # 退出当前账户</span><br><span class="line">su/chuser # 切换账户</span><br></pre></td></tr></table></figure>
<p>在命令行窗口中输入 login ，再根据提示输入账号和密码，即可登录百度账号。</p>
<p>还有其他登录方式，如 login -bduss=<bduss>。(获取bduss)</bduss></p>
<p>logout 和 su / chuser 的用法也比较简单。</p>
<p>在使用前，我们首先要登录百度账号，只要不手动退出账号，以后可以直接使用，而不必每次都登录。<br>首先，打开命令行，打开命令行的方式有两种：</p>
<ul>
<li><p>菜单打开<br>屏幕左下角“开始” -&gt; “所有程序” -&gt; “附件” -&gt; “命令提示符”</p>
</li>
<li><p>快捷键打开<br>按下键盘上的Win（显示微软图标的那个键）+R， 在弹出的窗口输入”cmd”，然后按下回车<br><img src="/images/BaiduPCS-Go的安装及使用/img1-4.png" alt></p>
</li>
</ul>
<p>接下来我们需要进入刚才解压好的软件目录，比如我的路径为：<code>C:\Users\User\Downloads\BaiduPCS-Go-v3.5.6-windows-x64</code>，那么在刚弹出的窗口中输入，并按下回车：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd C:\Users\User\Downloads\BaiduPCS-Go-v3.5.6-windows-x64</span><br></pre></td></tr></table></figure></p>
<p>然后开始输入命令登录百度账户，在窗口中输入：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BaiduPCS-Go.exe login</span><br></pre></td></tr></table></figure></p>
<p>然后按照下图操作即可登录：<br><img src="/images/BaiduPCS-Go的安装及使用/img1-5.png" alt></p>
<p>在显示成功登陆后，我们就可以关掉这个窗口了。然后双击BaiduPCS-Go.exe这个文件就可以进行下一步的操作了。<br>如果要退出账号，只需要在这个窗口中输入logout即可。</p>
<h3 id="切换目录"><a href="#切换目录" class="headerlink" title="切换目录"></a>切换目录</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd -l /Path/To/File</span><br><span class="line"></span><br><span class="line"># cd = change directory = 切换目录。</span><br><span class="line"># /Path/To/File = 文件路径，绝对路径或相对路径。</span><br><span class="line"># -l: 显示目标目录下的子文件及子目录。</span><br></pre></td></tr></table></figure>
<p>例：cd /a/b/c/d </p>
<h2 id="查看当前账户及已登录账户"><a href="#查看当前账户及已登录账户" class="headerlink" title="查看当前账户及已登录账户"></a>查看当前账户及已登录账户</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loglist</span><br></pre></td></tr></table></figure>
<h2 id="查看文件"><a href="#查看文件" class="headerlink" title="查看文件"></a>查看文件</h2><ul>
<li><p>查看文件命令ls (list)<br><img src="/images/BaiduPCS-Go的安装及使用/img1-6.png" alt></p>
</li>
<li><p>切换目录<br>默认情况下，打开之后执行ls看到的文件就是你百度网盘最顶层目录，如果想切换目录的话，执行以下命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd xxx</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>其中xxx是你想切换的文件夹名。</p>
<ul>
<li>切换到上一级目录<br>使用下面的命令可以切换到上一级目录：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd ..</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="下载文件"><a href="#下载文件" class="headerlink" title="下载文件"></a>下载文件</h2><p>下载文件的命令如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">download -p 1000 xxx</span><br></pre></td></tr></table></figure></p>
<p>其中xxx是你要下载的文件名，如下图所示:<br><img src="/images/BaiduPCS-Go的安装及使用/img1-7.png" alt></p>
<h2 id="上传文件"><a href="#上传文件" class="headerlink" title="上传文件"></a>上传文件</h2><p>上传文件时，需要打开命令行来操作。上传文件的命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BaiduPCS-Go upload xxx yyy</span><br></pre></td></tr></table></figure></p>
<p>其中xxx是你要上传的本地文件名，yyy是你百度网盘下的目录名，比如我要把我本地放在C:\Users\User\Downloads下的一个叫做Git-2.18.0-64-bit.exe的文件传到百度网盘的/Softwares/Tools目录下。命令如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BaiduPCS-Go.exe upload C:\Users\User\Downloads\Git-2.18.0-64-bit.exe /Softwares/Tools</span><br></pre></td></tr></table></figure>
<p>然后，我们就能看到如下的结果：<br><img src="/images/BaiduPCS-Go的安装及使用/img1-7.png" alt><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">这里要注意的是，windows系统下，本地文件的路径名书写要用\，而百度网盘路径名书写要用/.</span><br></pre></td></tr></table></figure></p>
<h2 id="web功能"><a href="#web功能" class="headerlink" title="web功能"></a>web功能</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">web #启用web功能</span><br></pre></td></tr></table></figure>
<p>输入上述命令后，在浏览器栏输入localhost:8080，就可以在本地查看你的网盘目录。</p>
<p>很不错的功能。</p>
<h1 id="帮助菜单"><a href="#帮助菜单" class="headerlink" title="帮助菜单"></a>帮助菜单</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">h</span><br></pre></td></tr></table></figure>
<p>输入 h ，可以看到帮助菜单。这里做成表格，以便观看<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">用法：输入 h ，可以看到帮助菜单。这里做成表格，以便观看</span><br></pre></td></tr></table></figure></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>COMMANDS</th>
<th style="text-align:left">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>tool</td>
<td style="text-align:left">工具箱</td>
</tr>
<tr>
<td>help / h</td>
<td style="text-align:left">Shows a list of commands or help for one command</td>
</tr>
<tr>
<td>其他：</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td>run</td>
<td style="text-align:left">执行系统命令</td>
</tr>
<tr>
<td>sumfile / sf</td>
<td style="text-align:left">获取文件的秒传信息</td>
</tr>
<tr>
<td>web</td>
<td style="text-align:left">启用 web 客户端 (测试中)</td>
</tr>
<tr>
<td>百度账号：</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td>login</td>
<td style="text-align:left">登录百度账号</td>
</tr>
<tr>
<td>loglist</td>
<td style="text-align:left">获取当前帐号, 和所有已登录的百度帐号</td>
</tr>
<tr>
<td>logout</td>
<td style="text-align:left">退出当前登录的百度帐号</td>
</tr>
<tr>
<td>su / chuser</td>
<td style="text-align:left">切换已登录的百度帐号</td>
</tr>
<tr>
<td>百度网盘：</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td>cd</td>
<td style="text-align:left">切换工作目录</td>
</tr>
<tr>
<td>cp</td>
<td style="text-align:left">拷贝(复制) 文件/目录</td>
</tr>
<tr>
<td>download / d</td>
<td style="text-align:left">下载文件或目录</td>
</tr>
<tr>
<td>ls / l / ll</td>
<td style="text-align:left">列出当前工作目录内的文件和目录 或 指定目录内的文件和目录</td>
</tr>
<tr>
<td>meta</td>
<td style="text-align:left">获取单个文件/目录的元信息 (详细信息)</td>
</tr>
<tr>
<td>mkdir</td>
<td style="text-align:left">创建目录</td>
</tr>
<tr>
<td>mv</td>
<td style="text-align:left">移动/重命名 文件/目录 </td>
</tr>
<tr>
<td>offlinedl/clouddl / od</td>
<td style="text-align:left">离线下载 </td>
</tr>
<tr>
<td>pwd</td>
<td style="text-align:left">输出当前所在目录 (工作目录) </td>
</tr>
<tr>
<td>quota</td>
<td style="text-align:left">获取配额, 即获取网盘的总储存空间, 和已使用的储存空间</td>
</tr>
<tr>
<td>rapidupload / ru</td>
<td style="text-align:left">手动秒传文件</td>
</tr>
<tr>
<td>rm</td>
<td style="text-align:left">删除 单个/多个 文件/目录 </td>
</tr>
<tr>
<td>upload / u</td>
<td style="text-align:left">上传文件或目录 </td>
</tr>
<tr>
<td>配置:</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td>config</td>
<td style="text-align:left">显示和修改程序配置项</td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th>GLOBAL OPTIONS:</th>
<th style="text-align:left">全局选项</th>
</tr>
</thead>
<tbody>
<tr>
<td>–verbose</td>
<td style="text-align:left">启用调试 [%BAIDUPCS_GO_VERBOSE%]</td>
</tr>
<tr>
<td>–help / -h</td>
<td style="text-align:left">查看帮助 </td>
</tr>
<tr>
<td>–version / -v</td>
<td style="text-align:left">查看版本号</td>
</tr>
</tbody>
</table>
</div>
<h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><ul>
<li>关于BaiduPCS-Go不能用问题解决，报错【获取目录下的文件列表 遇到错误, 远端服务器返回错误】<br>BaiduPCS-Go不能使用报错：获取目录下的文件列表 遇到错误, 远端服务器返回错误, 代码: 4, 消息: No permissionto do this operation, 路径: /<br>设置新的appid!：<br>目前已知可用APP id：266719</li>
</ul>
<p>在软件输入 config set -appid=266719。</p>
<ul>
<li>注意以下问题：错误代码403/31066  造成无法下载问题</li>
</ul>
<ol>
<li>下载路径和文件命名不带空格符号。</li>
<li>检查文件路径是否过于复杂(如果实在不行就直接下载整个文件夹)</li>
<li>如果还是不行，那就换别的账号登录吧</li>
</ol>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://blog.csdn.net/qq_39355782/article/details/80091071" target="_blank" rel="noopener">[教程]BaiduPCS-Go</a></li>
<li><a href="https://luomuxiaoxiao.com/?p=102" target="_blank" rel="noopener">BaiduPCS-Go的安装及使用</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/ji-yu-baidupcs-go-da-zao-de-web-jie-mian.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/ji-yu-baidupcs-go-da-zao-de-web-jie-mian.html" class="post-title-link" itemprop="url">基于BaiduPCS-Go打造的Web界面</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-18 19:27:56 / 修改时间：20:00:02" itemprop="dateCreated datePublished" datetime="2019-03-18T19:27:56+08:00">2019-03-18</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/电脑/" itemprop="url" rel="index"><span itemprop="name">电脑</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/电脑/百度云下载/" itemprop="url" rel="index"><span itemprop="name">百度云下载</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/电脑/百度云下载/BaiduPCS-Go/" itemprop="url" rel="index"><span itemprop="name">BaiduPCS-Go</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">1.1k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">1 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h1><p><strong>github地址:</strong> <a href="https://github.com/liuzhuoling2011/baidupcs-web" target="_blank" rel="noopener">https://github.com/liuzhuoling2011/baidupcs-web</a><br><img src="/images/基于BaiduPCS-Go打造的Web界面/img1-1.png" alt><br><img src="/images/基于BaiduPCS-Go打造的Web界面/img1-2.png" alt><br><img src="/images/基于BaiduPCS-Go打造的Web界面/img1-3.png" alt><br><img src="/images/基于BaiduPCS-Go打造的Web界面/img1-4.png" alt></p>
<p><strong>腾讯视频</strong>: <a href="https://v.qq.com/x/page/e0774xoeatv.html" target="_blank" rel="noopener">地址</a></p>
<iframe frameborder="0" src="https://v.qq.com/txp/iframe/player.html?vid=e0774xoeatv" width="100%" height="415" allowfullscreen="true"></iframe>

<p><strong>下载链接</strong>: <a href="https://github.com/liuzhuoling2011/baidupcs-web/releases" target="_blank" rel="noopener">https://github.com/liuzhuoling2011/baidupcs-web/releases</a></p>
<p>3.6.5 版本发布:  </p>
<ul>
<li>修复由于密码访问带来的安全隐患，强烈建议更新</li>
<li>增加只可以本地访问的模式</li>
<li>后台增加配置下载设置的API（页面暂时还没加入）</li>
<li>修复无法上传文件名含有 [ 字符的文件</li>
<li>新增公众号二维码， 更方便及时交流</li>
</ul>
<p>3.6.4 版本发布:  </p>
<ul>
<li>支持设置工作目录，之后可以规避错误 “无法下载 返回“遇到错误, 远端服务器返回错误, 代码: 31326, 消息: user is not authorized, hitcode:123”</li>
<li>参考链接 <a href="https://github.com/iikira/BaiduPCS-Go/issues/460" target="_blank" rel="noopener">https://github.com/iikira/BaiduPCS-Go/issues/460</a></li>
</ul>
<p>3.6.3 版本发布:  </p>
<ul>
<li>修复了移动端页面显示异常的bug</li>
</ul>
<p>3.6.2 版本发布:  </p>
<ul>
<li>页面针对包含大量文件的文件夹处理，上传下载列表进行优化，解决页面卡死问题，打开速度提升十倍左右</li>
<li>文件列表排序选项写入localstorage，长久有效</li>
<li>在Windows和Mac下程序打开时调用默认浏览器打开链接 <a href="http://localhost:5299" target="_blank" rel="noopener">http://localhost:5299</a></li>
</ul>
<p>3.6.1 版本发布:  </p>
<ul>
<li>添加移动端UI</li>
<li>新增支持BDUSS登录</li>
</ul>
<p>3.5.9 版本发布:  </p>
<ul>
<li>根据baidupcs-go的后台项目更新升级优化了下载, 上传</li>
<li>新增回收站操作(暂时回收站删除单个文件会出问题, 不过不影响)</li>
<li>新增重命名操作, 添加了列视图下文件删除和下载的快捷操作</li>
<li>修复下载文件夹时文件夹任务残留的bug</li>
<li>修复appid错误设置之后打开设置界面为空白的问题</li>
<li>修复了设置界面输入特殊符号无效的问题</li>
</ul>
<p><font color="red">附加说明：</font></p>
<ul>
<li><p>之前如果使用过BaiduPcs软件, 可能会出现登录后加载文件列表会卡死，或者遇到错误, 远端服务器返回错误, 代码: 4, 消息:<code>&quot;No permission to do this operation&quot;</code></p>
</li>
<li><p>可以试试, 在右上角的设置里面把<font color="red"> PCS应用ID </font>设置为<font color="red"> 266719 </font>就可以正常使用了</p>
</li>
</ul>
<ul>
<li><p><code>&quot;目前百度是针对账号进行限速，当一个非会员账号下载量达到一定阈值就会触发限速。账号被限速之后容易出现下载错误、掉连接数等问题，需要过几天或者开通会员才会恢复。&quot;</code></p>
</li>
<li><p>这个是需要百度云账号登陆的， 不用太担心安全什么的，相信开源的力量吧~</p>
</li>
</ul>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a href="https://www.52pojie.cn/thread-841306-1-1.html" target="_blank" rel="noopener">[WEB]基于BaiduPCS-Go打造的Web界面, 让你高效的使用百度云</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/ai-zi-mu-app-po-jie-vip-jiao-cheng.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/ai-zi-mu-app-po-jie-vip-jiao-cheng.html" class="post-title-link" itemprop="url">爱字幕app破解VIP教程</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-07 14:28:07 / 修改时间：15:15:45" itemprop="dateCreated datePublished" datetime="2019-03-07T14:28:07+08:00">2019-03-07</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Android/" itemprop="url" rel="index"><span itemprop="name">Android</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Android/逆向分析/" itemprop="url" rel="index"><span itemprop="name">逆向分析</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">303</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">1 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>这次是破解爱字母app的VIP教程<br>破解教程仅供研究参考，请勿用于商业用途</p>
<p>软件有360加固哦  自行脱壳<br>本次只会给出核心破解版</p>
<p>此次教程是用小米商店下载的最新版爱字幕1.5</p>
<ul>
<li>完美没水印</li>
<li>解锁VIP</li>
</ul>
<h1 id="破解前"><a href="#破解前" class="headerlink" title="破解前"></a>破解前</h1><iframe src="/images/爱字幕app破解VIP教程/crack_pre.gif" width="50%" height="720"></iframe>

<h1 id="破解后"><a href="#破解后" class="headerlink" title="破解后"></a>破解后</h1><iframe src="/images/爱字幕app破解VIP教程/crack_after.gif" width="50%" height="720"></iframe>
<iframe src="/images/爱字幕app破解VIP教程/crack_after2.gif" width="60%" height="800"></iframe>

<h1 id="破解步骤"><a href="#破解步骤" class="headerlink" title="破解步骤"></a>破解步骤</h1><ul>
<li>首先脱壳得到dex  把除了软件的类全部删除<br><img src="/images/爱字幕app破解VIP教程/img1-1.png" alt></li>
<li>搜索<code>isVip</code><br><img src="/images/爱字幕app破解VIP教程/img1-2.png" alt></li>
<li>全部赋值1<br><img src="/images/爱字幕app破解VIP教程/img1-3.jpg" alt><br><img src="/images/爱字幕app破解VIP教程/img1-4.jpg" alt></li>
</ul>
<p>重命名为classes2<br>添加进apk<br>保存返回安装看效果<br><img src="/images/爱字幕app破解VIP教程/crack_result.gif" alt></p>
<h1 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h1><p>成品下载地址：<a href="http://t.cn/EIu1EDR" target="_blank" rel="noopener">http://t.cn/EIu1EDR</a><br><a href="/images/爱字幕app破解VIP教程/爱字幕VIP版_需核心破解.apk">成品本地下载地址2 </a></p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>【简单】爱字幕app破解VIP教程<br><a href="https://www.52pojie.cn/thread-889438-1-1.html" target="_blank" rel="noopener">https://www.52pojie.cn/thread-889438-1-1.html</a><br>(出处: 吾爱破解论坛)</p>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://imjunjie.github.io/ai-qi-yi-wan-neng-bo-fang-qi-lu-se-xiu-gai-gao-su-bai-du-yun-xia-zai.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Junjie Jia">
      <meta itemprop="description" content="生命中的每一步都必须认真对待，把握今天，成就明天！">
      <meta itemprop="image" content="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Imjunjie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/ai-qi-yi-wan-neng-bo-fang-qi-lu-se-xiu-gai-gao-su-bai-du-yun-xia-zai.html" class="post-title-link" itemprop="url">爱奇艺万能播放器 绿色修改 & 高速百度云下载</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-07 12:55:30" itemprop="dateCreated datePublished" datetime="2019-03-07T12:55:30+08:00">2019-03-07</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-03-18 19:56:35" itemprop="dateModified" datetime="2019-03-18T19:56:35+08:00">2019-03-18</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/电脑/" itemprop="url" rel="index"><span itemprop="name">电脑</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/电脑/百度云下载/" itemprop="url" rel="index"><span itemprop="name">百度云下载</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/电脑/百度云下载/爱奇艺万能播放器/" itemprop="url" rel="index"><span itemprop="name">爱奇艺万能播放器</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">1.9k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">2 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>目前爱奇艺属于百度旗下，有细心的网友发现爱奇艺万能播放器竟然能不限速的下载百度网盘的资源！<br>启动播放器，右上角可以看见百度网盘的标志。<br><img src="/images/爱奇艺万能播放器-绿色修改-高速百度云下载/img2-1.jpg" alt><br>2018/11/18 17:00 之前下载的网友重新下载即可解决问题。<br>百度云高速下载速度不错：</p>
<h1 id="测试效果"><a href="#测试效果" class="headerlink" title="测试效果"></a>测试效果</h1><p>百度云下载功能可用，<code>2018/11/18 17:00</code>测试效果：</p>
<iframe src="/images/爱奇艺万能播放器-绿色修改-高速百度云下载/test_result.gif" width="70%" height="415"></iframe>

<h1 id="绿化步骤"><a href="#绿化步骤" class="headerlink" title="绿化步骤"></a>绿化步骤</h1><p>使用须知，绿化步骤：</p>
<p><img src="/images/爱奇艺万能播放器-绿色修改-高速百度云下载/img1-1.png" alt></p>
<h1 id="百度云功能启用"><a href="#百度云功能启用" class="headerlink" title="百度云功能启用"></a>百度云功能启用</h1><p>百度云功能启用：<br><img src="/images/爱奇艺万能播放器-绿色修改-高速百度云下载/img1-2.png" alt><br><img src="/images/爱奇艺万能播放器-绿色修改-高速百度云下载/img1-3.png" alt></p>
<h1 id="设置图片关联功能"><a href="#设置图片关联功能" class="headerlink" title="设置图片关联功能"></a>设置图片关联功能</h1><p>设置图片关联功能：（可设置为默认查看器，菜单里找）设置步骤:<br><img src="/images/爱奇艺万能播放器-绿色修改-高速百度云下载/img1-4.png" alt><br>修改特点：</p>
<p><font color="red"># 去除强制更新。</font><br></p>
<p><font color="red"># 去除多余菜单，界面搜索框。</font><br></p>
<p><font color="red"># 禁止生成无用文件及文件夹。</font><br></p>
<p><font color="red"># 批处理进行 绿化、卸载。</font><br></p>
<h1 id="使用指南"><a href="#使用指南" class="headerlink" title="使用指南"></a>使用指南</h1><p>目前爱奇艺属于百度旗下，有细心的网友发现爱奇艺万能播放器竟然能不限速的下载百度网盘的资源！<br>启动播放器，右上角可以看见百度网盘的标志。<br><img src="/images/爱奇艺万能播放器-绿色修改-高速百度云下载/img2-1.jpg" alt><br>然后登录你的百度网盘账号<br><img src="/images/爱奇艺万能播放器-绿色修改-高速百度云下载/img2-2.jpg" alt><br>找到你要下载的资源即可下载啦！<br><img src="/images/爱奇艺万能播放器-绿色修改-高速百度云下载/img2-3.jpg" alt><br>这个功能目前不支持同时下载多个任务，不支持下载文件夹；<br>如果界面右上角没出现百度网盘功能的按钮，请重启播放器！</p>
<p>更新日志：<br>5.1.55.4941 (2018.12.05)<br>更新日志:<br>1、新增暂停时逐帧快进功能<br>2、优化程序启动速度<br>3、优化播放器定时功能<br>4、优化看图模式图片缩放效率<br>5、其他各种问题修正及细节优化</p>
<h2 id="官方下载地址"><a href="#官方下载地址" class="headerlink" title="官方下载地址"></a>官方下载地址</h2><p>官方下载地址：<br>爱奇艺万能播放器 v5.1.55.4941<br><a href="http://mbdapp.iqiyi.com/j/ot/GeePlayerSetup_onlineupdate_201812051603.exe" target="_blank" rel="noopener">http://mbdapp.iqiyi.com/j/ot/GeePlayerSetup_onlineupdate_201812051603.exe</a></p>
<h1 id="更新介绍及下载"><a href="#更新介绍及下载" class="headerlink" title="更新介绍及下载"></a>更新介绍及下载</h1><p>2018/11/18 更新特点：<br><strong>没有集成 百度云下载浏览器 ，点击 百度云图标 会自动下载！！！</strong></p>
<p>2019/11/19 使用说明：<br>1、有网友反映，在线播放 打开URL 功能不能使用，经体验，官方版也不能使用。<br>2、百度云功能正常能用，不能使用的网友，确定下载的是18号更新的版本，首次打开需等待百度云加载完成。<br>3、看到有网友反馈限速，这个问题我解决不了。因为我这里的下载速度大家也看到了，网络是 电信网络。对于限速的网友，可以尝试换一下网络环境试试，或者 换一个 百度云账号看一下。另外，这款软件只能单个下载，无法批量下载。</p>
<p>2018/11/19 15:00 做最后更新：<br>1、修复由于之前修改过度，导致 点击 设置关联 的时候不能设置关联以及闪退问题。<br>2、精简一些更新有关的文件（软件已禁止更新）。</p>
<p>2018/11/23 14:00 完善批处理:<br>1、完善卸载批处理，卸载后几乎不留痕迹。</p>
<p>爱奇艺万能播放器 3.2.49.4280 下载链接：(2018/11/23 14:00 更新)<br>链接: <a href="https://pan.baidu.com/s/1pNt3Cr6WmZrukN8P-tbdpg" target="_blank" rel="noopener">https://pan.baidu.com/s/1pNt3Cr6WmZrukN8P-tbdpg</a> 提取码: pyev </p>
<p>2018/11/18 更新到最新版：<br>爱奇艺万能播放器 5.1.53.4745 下载链接：(2018/11/23 14:00 更新)<br>链接: <a href="https://pan.baidu.com/s/1WC5pCtnmTo8F8AouufNU1Q" target="_blank" rel="noopener">https://pan.baidu.com/s/1WC5pCtnmTo8F8AouufNU1Q</a> 提取码:dqv5 </p>
<p>两个版本比较：<br>1、从百度云下载来看没啥区别<br>2、新版貌似多着<font color="red">爱奇艺视频助手</font> 功能，但是这个功能开启后，安装体积100M多点。<br>3、没啥特殊需求的话，两个版本随意用。</p>
<p>当然，想必有网友问，有没有<font color="red">爱奇艺视频助手</font> 提取版，答案是：必须有。</p>
<h1 id="爱奇艺视频助手"><a href="#爱奇艺视频助手" class="headerlink" title="爱奇艺视频助手"></a>爱奇艺视频助手</h1><p>爱奇艺视频助手 7.5.3.15 修改特点：</p>
<ul>
<li>禁止检查更新</li>
<li>去除反馈等菜单</li>
</ul>
<h2 id="爱奇艺视频助手-软件特色："><a href="#爱奇艺视频助手-软件特色：" class="headerlink" title="爱奇艺视频助手 软件特色："></a>爱奇艺视频助手 软件特色：</h2><p>图片MV ，功能：<br><img src="/images/爱奇艺万能播放器-绿色修改-高速百度云下载/img1-5.png" alt></p>
<h2 id="转码功能"><a href="#转码功能" class="headerlink" title="转码功能"></a>转码功能</h2><p><strong>转码功能</strong>：支持各种视频转换为mp4\mkv\flv格式<br><img src="/images/爱奇艺万能播放器-绿色修改-高速百度云下载/img1-6.png" alt></p>
<p>2018/11/23 14:00 完善批处理:<br>1、完善卸载批处理，卸载后几乎不留痕迹。<br>爱奇艺视频助手 7.5.3.15 下载链接：(2018/11/23 14:00 更新)<br>链接:<a href="https://pan.baidu.com/s/1Cj37KNN_w-WqlG9vqpDbOw" target="_blank" rel="noopener">https://pan.baidu.com/s/1Cj37KNN_w-WqlG9vqpDbOw</a> 提取码: 8yki </p>
<h1 id="问答"><a href="#问答" class="headerlink" title="问答"></a>问答</h1><ul>
<li>对于不显示 百度云 图标的网友，尝试重新启动软件3次左右，每次在联网状态下停留1分钟左右。</li>
</ul>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li>参考1<br>11/23（完善批处理）修复百度云 爱奇艺万能播放器 绿色修改  &amp; 高速百度云下载<br><a href="https://www.52pojie.cn/thread-823826-1-1.html" target="_blank" rel="noopener">https://www.52pojie.cn/thread-823826-1-1.html</a></li>
<li>参考2<br>爱奇艺万能播放器 v5.1.55.4941 支持度盘高速下载<br><a href="https://www.52pojie.cn/thread-834449-1-1.html" target="_blank" rel="noopener">https://www.52pojie.cn/thread-834449-1-1.html</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    <div style="text-align:center;color: #ccc;font-size:14px;">------------------------ The End ------------------------</div>
    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="http://image.xcar.com.cn/attachments/a/day_130416/2013041610_b3e94dab51a2253bd17dxx64sn6s0q2H.gif" alt="Junjie Jia">
            
              <p class="site-author-name" itemprop="name">Junjie Jia</p>
              <p class="site-description motion-element" itemprop="description">生命中的每一步都必须认真对待，把握今天，成就明天！</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">45</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">23</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">26</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                  
                    
                  
                  <a href="https://github.com/imjunjie" title="GitHub &rarr; https://github.com/imjunjie" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i></a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                  
                    
                  
                  <a href="mailto:junjie017@gmail.com" title="E-Mail &rarr; mailto:junjie017@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i></a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Junjie Jia</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
    <span title="站点总字数">184k</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
    <span title="站点阅读时长">2:47</span>
  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.0.0</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=7.0.0"></script>

  <script src="/js/src/motion.js?v=7.0.0"></script>



  
  


  <script src="/js/src/affix.js?v=7.0.0"></script>

  <script src="/js/src/schemes/pisces.js?v=7.0.0"></script>




  

  


  <script src="/js/src/bootstrap.js?v=7.0.0"></script>


  
  



  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  


  

  

  

  

  

  

  

  

  

  


  <!-- 代码块复制功能 -->
<script type="text/javascript" src="/js/src/clipboard.min.js"></script>  
<script type="text/javascript" src="/js/src/clipboard-use.js"></script>

</body>
</html>
